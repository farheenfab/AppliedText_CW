{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/farheenfab/AppliedText_CW/blob/main/CW1-generate_dataset.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F20AA Coursework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyAWj_uzrhZL18X32S_P79pT1wnSYGpuA4k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/search/list#parameters\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/comments/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class api_handler:\n",
    "    def __init__(self, api_service_name, api_version, developer_key):\n",
    "        self.client = googleapiclient.discovery.build(api_service_name,\n",
    "                                                    api_version,\n",
    "                                                    developerKey=developer_key)\n",
    "        \n",
    "    # Search for videos details given id\n",
    "    def get_video_details(self, videoId, part=\"snippet\"):\n",
    "        request = self.client.videos().list(\n",
    "            part=part,\n",
    "            id=videoId\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        if 'items' in response:\n",
    "            video_details = response['items'][0]\n",
    "            snippet=video_details['snippet']\n",
    "            snippet['videoId']=videoId\n",
    "            snippet['id']=videoId\n",
    "            snippet['publishTime']=video_details.get('snippet', {}).get('publishedAt', {})\n",
    "            snippet['thumbnails']=video_details.get('snippet', {}).get('thumbnails', {}).get('default', {}).get('url', '')\n",
    "            return snippet\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Search for videos given query\n",
    "    def get_videos(self,query,maxResults=5,part=\"snippet\"):\n",
    "        request = self.client.search().list(\n",
    "            part=part,\n",
    "            maxResults=maxResults,\n",
    "            # higher view count is likely to be more relevent \n",
    "            order=\"viewCount\",\n",
    "            q=query,  \n",
    "            # american region videos \n",
    "            regionCode=\"US\",\n",
    "            # english videos\n",
    "            relevanceLanguage=\"en\",\n",
    "            type=\"video\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return response\n",
    "    \n",
    "    # Format Response from get_videos to dataframe\n",
    "    def get_video_df(response):\n",
    "        items=[]\n",
    "        for item in response['items']:\n",
    "            snippet=item.get('snippet', {})\n",
    "            items+=[{\n",
    "                'title':snippet.get('title', ''),\n",
    "                'videoId':item.get('id', {}).get('videoId', ''),\n",
    "                'channelTitle':snippet.get('channelTitle', ''),\n",
    "                'publishTime':snippet.get('publishTime', ''),\n",
    "                'description':snippet.get('description', ''),\n",
    "                'thumbnails':snippet.get('thumbnails', {}).get('default', {}).get('url', '')\n",
    "                }]\n",
    "        df=pd.DataFrame(items)\n",
    "        return df\n",
    "    \n",
    "    # Get comments from video\n",
    "    def get_comments(self,videoId,part=\"snippet\",maxResults=100,maxResultsDepth=100):\n",
    "        all_comments = []\n",
    "        nextPageToken = None\n",
    "        while maxResults > 0:\n",
    "            request = self.client.commentThreads().list(\n",
    "                part=part,\n",
    "                videoId=videoId,\n",
    "                maxResults=min(maxResults, 100),\n",
    "                order='relevance',\n",
    "                moderationStatus='published',\n",
    "                textFormat='plainText',\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "            response = request.execute()\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "            if 'items' in response:\n",
    "                all_comments+=[response]\n",
    "                for item in response['items']:\n",
    "                    # extract the comment ID to get replies\n",
    "                    comment_id = item.get('snippet',{}).get('topLevelComment',{}).get('id','')\n",
    "                    if item.get('snippet',{}).get('totalReplyCount',0)>2:\n",
    "                        print('getting replies:',item.get('snippet',{}).get('totalReplyCount',0))\n",
    "                        replies = self.get_comment_replies(comment_id, maxResults=maxResultsDepth)\n",
    "                        all_comments += replies\n",
    "\n",
    "            maxResults -= min(maxResults, 100)\n",
    "            if nextPageToken is None:\n",
    "                break;    \n",
    "        return all_comments\n",
    "    \n",
    "    # Get replies from comment \n",
    "    def get_comment_replies(self, commentId, part=\"snippet\", maxResults=100):\n",
    "        all_comments = []\n",
    "        nextPageToken = None\n",
    "        while maxResults > 0 and (nextPageToken != None or len(all_comments)==0):\n",
    "\n",
    "            request = self.client.comments().list(\n",
    "                part=part,\n",
    "                parentId=commentId,\n",
    "                maxResults=min(maxResults, 100),\n",
    "                textFormat='plainText',\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "\n",
    "            response = request.execute()\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "\n",
    "            if 'items' in response and len(response['items'])>0:\n",
    "                for item in response['items']:\n",
    "                    modified_response = {\n",
    "                        'items': [\n",
    "                            {\n",
    "                                'id':item.get('id'),\n",
    "                                'snippet': {\n",
    "                                    'topLevelComment': {\n",
    "                                        'snippet': item.get('snippet','')\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                    all_comments += [modified_response]\n",
    "            maxResults -= min(maxResults, 100)\n",
    "            if nextPageToken is None:\n",
    "                break;    \n",
    "        return all_comments\n",
    "\n",
    "    # Format response from get_comments to dataframe\n",
    "    def get_comments_df(response, video,product):\n",
    "        comments = []\n",
    "        for pages in response:\n",
    "            for item in pages['items']:\n",
    "                comment = item.get('snippet', {}).get('topLevelComment', {}).get('snippet', {})\n",
    "                comments.append([\n",
    "                        product,\n",
    "                        video.get('title', ''),\n",
    "                        video.get('videoId', ''),\n",
    "                        video.get('channelTitle', ''),\n",
    "                        video.get('publishTime', ''),\n",
    "                        video.get('description', ''),\n",
    "                        video.get('thumbnails', ''),\n",
    "                        item.get('id', ''),  \n",
    "                        comment.get('parentId', ''),  \n",
    "                        comment.get('authorDisplayName', '')[1:],  \n",
    "                        comment.get('publishedAt', ''),\n",
    "                        comment.get('updatedAt', ''),\n",
    "                        comment.get('likeCount', ''),\n",
    "                        comment.get('textDisplay', '')\n",
    "                    ])\n",
    "\n",
    "        df = pd.DataFrame(comments,\n",
    "            columns=['product', 'v_title', 'v_videoId',\n",
    "                    'v_channelTitle', 'v_publishTime',\n",
    "                    'v_description', 'v_thumbnail',\n",
    "                    'c_id','c_parentId',\n",
    "                    'c_author', 'c_published_at',\n",
    "                    'c_updated_at', 'c_like_count',\n",
    "                    'c_text'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Search for videos related to products iteratively\n",
    "    # Collect comments from each video and place it into an array\n",
    "    def create_video_df_from_search(self, products,\n",
    "                                    number_of_videos_per_product=5,\n",
    "                                    number_of_comments_per_video=100\n",
    "                                    ,number_of_replies_per_comment=100):\n",
    "        multiple_video_comments = pd.DataFrame()\n",
    "        for product in products:\n",
    "            # get 25 first videos with the highest viewer counts \n",
    "            response = self.get_videos(query=product, maxResults=number_of_videos_per_product)\n",
    "            # Convert results to df\n",
    "            videos_df = api_handler.get_video_df(response)\n",
    "            # For each video get a maximum of 100 comments\n",
    "            # and place comments into an array\n",
    "            for _, video in videos_df.iterrows():\n",
    "                try:\n",
    "                    response = self.get_comments(video['videoId'], maxResults=number_of_comments_per_video,maxResultsDepth=number_of_replies_per_comment)\n",
    "                    comments_df = api_handler.get_comments_df(response, video, product)\n",
    "                except:\n",
    "                    # Function fails as the API returns 403 if the channel has comments disabled\n",
    "                    # place an empty entry instead it can be deleted later\n",
    "                    comments_df = pd.DataFrame(np.zeros((1, 14)),\n",
    "                                                columns=['product', 'v_title', 'v_videoId',\n",
    "                                                        'v_channelTitle', 'v_publishTime',\n",
    "                                                        'v_description', 'v_thumbnail',\n",
    "                                                        'c_id','c_parentId',\n",
    "                                                        'c_author', 'c_published_at',\n",
    "                                                        'c_updated_at', 'c_like_count',\n",
    "                                                        'c_text'])\n",
    "                    print('Unable to retrieve comments:', video.get('title', ''))\n",
    "                multiple_video_comments = pd.concat([multiple_video_comments, comments_df], ignore_index=True)\n",
    "        return multiple_video_comments\n",
    "        \n",
    "    # alternative method by explicitely specifying videos\n",
    "    def create_video_df(self,products,videos,number_of_comments_per_video=100,number_of_replies_per_comment=100):\n",
    "        count=0\n",
    "        multiple_video_comments = pd.DataFrame()\n",
    "        for product in products:\n",
    "            for video in videos[count]:\n",
    "                response = self.get_comments(video,maxResults=number_of_comments_per_video,maxResultsDepth=number_of_replies_per_comment) \n",
    "                video=self.get_video_details(video)\n",
    "                comments_df = api_handler.get_comments_df(response, video, product)\n",
    "                multiple_video_comments = pd.concat([multiple_video_comments, comments_df], ignore_index=True)\n",
    "            count+=1\n",
    "        return multiple_video_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "products=[\"Strong Girl Nam-soon\"]\n",
    "\n",
    "# careful when adding videos index number should match between products and videos\n",
    "# index 0 should contain the videos used to get comments for video 0 and so on \n",
    "videos=[['LhCQ7lHEjU8','Yh7PNUGxihU','8sXTfzaLmiQ'],\n",
    "        ['c2xta7hcvXI','mkrrKGo1VEs','CL0wU3ss2uw','jPKm6kc9j5A','g0Oj4A2rslY']]\n",
    "\n",
    "youtube=api_handler(api_service_name, api_version, DEVELOPER_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting replies: 42\n",
      "getting replies: 13\n",
      "getting replies: 45\n",
      "getting replies: 3\n",
      "getting replies: 14\n",
      "getting replies: 30\n",
      "getting replies: 3\n",
      "getting replies: 42\n",
      "getting replies: 9\n",
      "getting replies: 62\n",
      "getting replies: 15\n",
      "getting replies: 23\n",
      "getting replies: 292\n",
      "getting replies: 14\n",
      "getting replies: 3\n",
      "getting replies: 10\n",
      "getting replies: 4\n",
      "getting replies: 77\n",
      "getting replies: 13\n",
      "getting replies: 35\n",
      "getting replies: 6\n",
      "getting replies: 15\n",
      "getting replies: 19\n",
      "getting replies: 7\n",
      "getting replies: 6\n",
      "getting replies: 4\n",
      "getting replies: 81\n",
      "getting replies: 22\n",
      "getting replies: 9\n",
      "getting replies: 3\n",
      "getting replies: 10\n",
      "getting replies: 4\n",
      "getting replies: 6\n",
      "getting replies: 16\n",
      "getting replies: 14\n",
      "getting replies: 100\n",
      "getting replies: 20\n",
      "getting replies: 3\n",
      "getting replies: 19\n",
      "getting replies: 13\n",
      "getting replies: 22\n",
      "getting replies: 4\n",
      "getting replies: 3\n",
      "getting replies: 9\n",
      "getting replies: 11\n",
      "getting replies: 3\n",
      "getting replies: 4\n",
      "getting replies: 10\n",
      "getting replies: 35\n",
      "getting replies: 8\n",
      "getting replies: 10\n",
      "getting replies: 33\n",
      "getting replies: 69\n",
      "getting replies: 73\n",
      "getting replies: 13\n",
      "getting replies: 75\n",
      "getting replies: 104\n",
      "getting replies: 7\n",
      "getting replies: 6\n",
      "getting replies: 38\n",
      "getting replies: 6\n",
      "getting replies: 4\n",
      "getting replies: 7\n",
      "getting replies: 55\n",
      "getting replies: 5\n",
      "getting replies: 20\n",
      "getting replies: 18\n",
      "getting replies: 51\n",
      "getting replies: 9\n",
      "getting replies: 27\n",
      "getting replies: 11\n",
      "getting replies: 59\n",
      "getting replies: 6\n",
      "getting replies: 15\n",
      "getting replies: 8\n",
      "getting replies: 18\n",
      "getting replies: 4\n",
      "getting replies: 3\n",
      "getting replies: 54\n",
      "getting replies: 3\n",
      "getting replies: 7\n",
      "getting replies: 3\n",
      "getting replies: 309\n",
      "getting replies: 11\n",
      "getting replies: 25\n",
      "getting replies: 27\n",
      "getting replies: 76\n",
      "getting replies: 7\n",
      "getting replies: 4\n",
      "getting replies: 73\n",
      "getting replies: 16\n",
      "getting replies: 55\n",
      "getting replies: 84\n",
      "getting replies: 4\n",
      "getting replies: 5\n",
      "getting replies: 17\n",
      "getting replies: 36\n",
      "getting replies: 10\n",
      "getting replies: 3\n",
      "getting replies: 26\n",
      "getting replies: 5\n",
      "getting replies: 48\n",
      "getting replies: 18\n",
      "getting replies: 6\n",
      "getting replies: 4\n",
      "getting replies: 8\n",
      "getting replies: 4\n",
      "getting replies: 6\n",
      "getting replies: 16\n",
      "getting replies: 10\n",
      "getting replies: 8\n",
      "getting replies: 10\n",
      "getting replies: 4\n",
      "getting replies: 4\n",
      "getting replies: 4\n",
      "getting replies: 7\n",
      "getting replies: 7\n",
      "getting replies: 3\n",
      "getting replies: 3\n",
      "getting replies: 39\n",
      "getting replies: 4\n",
      "getting replies: 18\n",
      "getting replies: 6\n",
      "getting replies: 16\n",
      "getting replies: 3\n",
      "getting replies: 7\n",
      "getting replies: 6\n",
      "getting replies: 5\n",
      "getting replies: 11\n",
      "getting replies: 4\n",
      "getting replies: 4\n",
      "getting replies: 21\n",
      "getting replies: 8\n",
      "getting replies: 13\n",
      "getting replies: 17\n",
      "getting replies: 4\n",
      "getting replies: 5\n",
      "getting replies: 4\n",
      "getting replies: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>Ugz_bUJfbcTKJvJtzTd4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>l_hate_snakeu</td>\n",
       "      <td>2023-10-15T12:49:31Z</td>\n",
       "      <td>2023-10-15T12:49:31Z</td>\n",
       "      <td>2855</td>\n",
       "      <td>Bless that girl who helped her she has a pure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>UgyjXTyosk6QNriMfL94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ergoproxy5773</td>\n",
       "      <td>2023-10-20T21:12:46Z</td>\n",
       "      <td>2023-10-20T21:12:46Z</td>\n",
       "      <td>884</td>\n",
       "      <td>Moral lesson: Don’t drink too much and stay ae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>UgzH84Y5rQTurk09B8d4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>gimmiedashasha</td>\n",
       "      <td>2023-10-16T08:46:54Z</td>\n",
       "      <td>2023-10-16T08:46:54Z</td>\n",
       "      <td>1616</td>\n",
       "      <td>\"Great performance guys don't forget to take d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>Ugy9uQL1F0XvPHBoqQ54AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>3AHoles</td>\n",
       "      <td>2023-11-20T18:14:11Z</td>\n",
       "      <td>2023-11-20T18:14:34Z</td>\n",
       "      <td>105</td>\n",
       "      <td>Obviously reenactment but this happens all the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>Ugxsqn7lMbyrJAUHyxp4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>kevinshelley2803</td>\n",
       "      <td>2023-10-20T16:08:40Z</td>\n",
       "      <td>2023-10-20T16:08:40Z</td>\n",
       "      <td>474</td>\n",
       "      <td>Awesome. So fortunate that camera was there to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>Ugx-S5IV213pnOSz21h4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>irinislam4155</td>\n",
       "      <td>2024-02-10T06:45:28Z</td>\n",
       "      <td>2024-02-10T06:45:28Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama name is        only for love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>UgzFoWDJHiMg9ZpFj6Z4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>vlexus</td>\n",
       "      <td>2023-12-07T15:57:17Z</td>\n",
       "      <td>2023-12-07T15:57:17Z</td>\n",
       "      <td>2</td>\n",
       "      <td>that is just awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>Ugx8YNn-UXGQBwjv-QR4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>tjsantiago0578</td>\n",
       "      <td>2023-12-06T21:36:08Z</td>\n",
       "      <td>2023-12-06T21:36:08Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Best part..... ducha fria 😂😂😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>Ugz67MpKN98yO95KJkJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-pu1mi6hc3l</td>\n",
       "      <td>2023-12-30T18:21:01Z</td>\n",
       "      <td>2023-12-30T18:21:01Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Я люблю эту дораму❤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>UgzuE3650P7vACv1q3J4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>autumnevsearthdestroyer</td>\n",
       "      <td>2023-12-02T13:43:58Z</td>\n",
       "      <td>2023-12-02T13:43:58Z</td>\n",
       "      <td>4</td>\n",
       "      <td>what episode is this?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product                                            v_title  \\\n",
       "0    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "1    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "2    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "3    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "4    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "..                    ...                                                ...   \n",
       "494  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "495  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "496  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "497  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "498  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "\n",
       "       v_videoId v_channelTitle         v_publishTime  \\\n",
       "0    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "1    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "2    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "3    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "4    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "..           ...            ...                   ...   \n",
       "494  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "495  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "496  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "497  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "498  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "\n",
       "                                         v_description  \\\n",
       "0    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "1    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "2    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "3    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "4    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "..                                                 ...   \n",
       "494                                                      \n",
       "495                                                      \n",
       "496                                                      \n",
       "497                                                      \n",
       "498                                                      \n",
       "\n",
       "                                        v_thumbnail  \\\n",
       "0    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "1    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "2    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "3    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "4    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "..                                              ...   \n",
       "494  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "495  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "496  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "497  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "498  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "\n",
       "                           c_id c_parentId                 c_author  \\\n",
       "0    Ugz_bUJfbcTKJvJtzTd4AaABAg                       l_hate_snakeu   \n",
       "1    UgyjXTyosk6QNriMfL94AaABAg                       ergoproxy5773   \n",
       "2    UgzH84Y5rQTurk09B8d4AaABAg                      gimmiedashasha   \n",
       "3    Ugy9uQL1F0XvPHBoqQ54AaABAg                             3AHoles   \n",
       "4    Ugxsqn7lMbyrJAUHyxp4AaABAg                    kevinshelley2803   \n",
       "..                          ...        ...                      ...   \n",
       "494  Ugx-S5IV213pnOSz21h4AaABAg                       irinislam4155   \n",
       "495  UgzFoWDJHiMg9ZpFj6Z4AaABAg                              vlexus   \n",
       "496  Ugx8YNn-UXGQBwjv-QR4AaABAg                      tjsantiago0578   \n",
       "497  Ugz67MpKN98yO95KJkJ4AaABAg                     user-pu1mi6hc3l   \n",
       "498  UgzuE3650P7vACv1q3J4AaABAg             autumnevsearthdestroyer   \n",
       "\n",
       "           c_published_at          c_updated_at  c_like_count  \\\n",
       "0    2023-10-15T12:49:31Z  2023-10-15T12:49:31Z          2855   \n",
       "1    2023-10-20T21:12:46Z  2023-10-20T21:12:46Z           884   \n",
       "2    2023-10-16T08:46:54Z  2023-10-16T08:46:54Z          1616   \n",
       "3    2023-11-20T18:14:11Z  2023-11-20T18:14:34Z           105   \n",
       "4    2023-10-20T16:08:40Z  2023-10-20T16:08:40Z           474   \n",
       "..                    ...                   ...           ...   \n",
       "494  2024-02-10T06:45:28Z  2024-02-10T06:45:28Z             0   \n",
       "495  2023-12-07T15:57:17Z  2023-12-07T15:57:17Z             2   \n",
       "496  2023-12-06T21:36:08Z  2023-12-06T21:36:08Z             2   \n",
       "497  2023-12-30T18:21:01Z  2023-12-30T18:21:01Z             0   \n",
       "498  2023-12-02T13:43:58Z  2023-12-02T13:43:58Z             4   \n",
       "\n",
       "                                                c_text  \n",
       "0    Bless that girl who helped her she has a pure ...  \n",
       "1    Moral lesson: Don’t drink too much and stay ae...  \n",
       "2    \"Great performance guys don't forget to take d...  \n",
       "3    Obviously reenactment but this happens all the...  \n",
       "4    Awesome. So fortunate that camera was there to...  \n",
       "..                                                 ...  \n",
       "494                 Drama name is        only for love  \n",
       "495                               that is just awesome  \n",
       "496                     Best part..... ducha fria 😂😂😂😂  \n",
       "497                                Я люблю эту дораму❤  \n",
       "498                              what episode is this?  \n",
       "\n",
       "[499 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_video_comments=youtube.create_video_df_from_search(products,number_of_videos_per_product=10,number_of_comments_per_video=50,number_of_replies_per_comment=00)\n",
    "# multiple_video_comments=youtube.create_video_df(products,videos,number_of_comments_per_video=20000,number_of_replies_per_comment=20000)\n",
    "multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from:\n",
    "\n",
    "https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_emojis(data):\n",
    "    if isinstance(data, str):\n",
    "        # Remove html tags\n",
    "        data = BeautifulSoup(data, \"html.parser\").get_text()\n",
    "        # Remove emote, etc\n",
    "        emoj = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "                        \"]+\", re.UNICODE)\n",
    "        # english_words = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "\n",
    "        return re.sub(emoj, '', data)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_video_comments.dropna(subset=['c_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Length Before: 499\n",
      "DataFrame Length After: 498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/j8_w4qrs1yg_9xkb16m_16nr0000gp/T/ipykernel_70378/1711868485.py:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  data = BeautifulSoup(data, \"html.parser\").get_text()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>Ugz_bUJfbcTKJvJtzTd4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>l_hate_snakeu</td>\n",
       "      <td>2023-10-15T12:49:31Z</td>\n",
       "      <td>2023-10-15T12:49:31Z</td>\n",
       "      <td>2855</td>\n",
       "      <td>Bless that girl who helped her she has a pure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>UgyjXTyosk6QNriMfL94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ergoproxy5773</td>\n",
       "      <td>2023-10-20T21:12:46Z</td>\n",
       "      <td>2023-10-20T21:12:46Z</td>\n",
       "      <td>884</td>\n",
       "      <td>Moral lesson: Don’t drink too much and stay ae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>UgzH84Y5rQTurk09B8d4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>gimmiedashasha</td>\n",
       "      <td>2023-10-16T08:46:54Z</td>\n",
       "      <td>2023-10-16T08:46:54Z</td>\n",
       "      <td>1616</td>\n",
       "      <td>\"Great performance guys don't forget to take d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>Ugy9uQL1F0XvPHBoqQ54AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>3AHoles</td>\n",
       "      <td>2023-11-20T18:14:11Z</td>\n",
       "      <td>2023-11-20T18:14:34Z</td>\n",
       "      <td>105</td>\n",
       "      <td>Obviously reenactment but this happens all the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>Ugxsqn7lMbyrJAUHyxp4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>kevinshelley2803</td>\n",
       "      <td>2023-10-20T16:08:40Z</td>\n",
       "      <td>2023-10-20T16:08:40Z</td>\n",
       "      <td>474</td>\n",
       "      <td>Awesome. So fortunate that camera was there to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>Ugx-S5IV213pnOSz21h4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>irinislam4155</td>\n",
       "      <td>2024-02-10T06:45:28Z</td>\n",
       "      <td>2024-02-10T06:45:28Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama name is        only for love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>UgzFoWDJHiMg9ZpFj6Z4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>vlexus</td>\n",
       "      <td>2023-12-07T15:57:17Z</td>\n",
       "      <td>2023-12-07T15:57:17Z</td>\n",
       "      <td>2</td>\n",
       "      <td>that is just awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>Ugx8YNn-UXGQBwjv-QR4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>tjsantiago0578</td>\n",
       "      <td>2023-12-06T21:36:08Z</td>\n",
       "      <td>2023-12-06T21:36:08Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Best part..... ducha fria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>Ugz67MpKN98yO95KJkJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-pu1mi6hc3l</td>\n",
       "      <td>2023-12-30T18:21:01Z</td>\n",
       "      <td>2023-12-30T18:21:01Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Я люблю эту дораму</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>UgzuE3650P7vACv1q3J4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>autumnevsearthdestroyer</td>\n",
       "      <td>2023-12-02T13:43:58Z</td>\n",
       "      <td>2023-12-02T13:43:58Z</td>\n",
       "      <td>4</td>\n",
       "      <td>what episode is this?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product                                            v_title  \\\n",
       "0    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "1    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "2    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "3    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "4    Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "..                    ...                                                ...   \n",
       "494  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "495  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "496  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "497  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "498  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "\n",
       "       v_videoId v_channelTitle         v_publishTime  \\\n",
       "0    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "1    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "2    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "3    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "4    aNV59aHbM0o       Goubtube  2021-07-19T19:00:00Z   \n",
       "..           ...            ...                   ...   \n",
       "494  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "495  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "496  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "497  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "498  1WMRUKjOle0         VeeDaa  2023-11-23T21:44:22Z   \n",
       "\n",
       "                                         v_description  \\\n",
       "0    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "1    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "2    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "3    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "4    SUBSCRIBE FOR MORE! --------------------------...   \n",
       "..                                                 ...   \n",
       "494                                                      \n",
       "495                                                      \n",
       "496                                                      \n",
       "497                                                      \n",
       "498                                                      \n",
       "\n",
       "                                        v_thumbnail  \\\n",
       "0    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "1    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "2    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "3    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "4    https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "..                                              ...   \n",
       "494  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "495  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "496  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "497  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "498  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "\n",
       "                           c_id c_parentId                 c_author  \\\n",
       "0    Ugz_bUJfbcTKJvJtzTd4AaABAg                       l_hate_snakeu   \n",
       "1    UgyjXTyosk6QNriMfL94AaABAg                       ergoproxy5773   \n",
       "2    UgzH84Y5rQTurk09B8d4AaABAg                      gimmiedashasha   \n",
       "3    Ugy9uQL1F0XvPHBoqQ54AaABAg                             3AHoles   \n",
       "4    Ugxsqn7lMbyrJAUHyxp4AaABAg                    kevinshelley2803   \n",
       "..                          ...        ...                      ...   \n",
       "494  Ugx-S5IV213pnOSz21h4AaABAg                       irinislam4155   \n",
       "495  UgzFoWDJHiMg9ZpFj6Z4AaABAg                              vlexus   \n",
       "496  Ugx8YNn-UXGQBwjv-QR4AaABAg                      tjsantiago0578   \n",
       "497  Ugz67MpKN98yO95KJkJ4AaABAg                     user-pu1mi6hc3l   \n",
       "498  UgzuE3650P7vACv1q3J4AaABAg             autumnevsearthdestroyer   \n",
       "\n",
       "           c_published_at          c_updated_at  c_like_count  \\\n",
       "0    2023-10-15T12:49:31Z  2023-10-15T12:49:31Z          2855   \n",
       "1    2023-10-20T21:12:46Z  2023-10-20T21:12:46Z           884   \n",
       "2    2023-10-16T08:46:54Z  2023-10-16T08:46:54Z          1616   \n",
       "3    2023-11-20T18:14:11Z  2023-11-20T18:14:34Z           105   \n",
       "4    2023-10-20T16:08:40Z  2023-10-20T16:08:40Z           474   \n",
       "..                    ...                   ...           ...   \n",
       "494  2024-02-10T06:45:28Z  2024-02-10T06:45:28Z             0   \n",
       "495  2023-12-07T15:57:17Z  2023-12-07T15:57:17Z             2   \n",
       "496  2023-12-06T21:36:08Z  2023-12-06T21:36:08Z             2   \n",
       "497  2023-12-30T18:21:01Z  2023-12-30T18:21:01Z             0   \n",
       "498  2023-12-02T13:43:58Z  2023-12-02T13:43:58Z             4   \n",
       "\n",
       "                                                c_text  \n",
       "0    Bless that girl who helped her she has a pure ...  \n",
       "1    Moral lesson: Don’t drink too much and stay ae...  \n",
       "2    \"Great performance guys don't forget to take d...  \n",
       "3    Obviously reenactment but this happens all the...  \n",
       "4    Awesome. So fortunate that camera was there to...  \n",
       "..                                                 ...  \n",
       "494                 Drama name is        only for love  \n",
       "495                               that is just awesome  \n",
       "496                         Best part..... ducha fria   \n",
       "497                                 Я люблю эту дораму  \n",
       "498                              what episode is this?  \n",
       "\n",
       "[498 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove emotes from the text to be analyzed c_text = comment text\n",
    "multiple_video_comments['c_text']=multiple_video_comments['c_text'].apply(remove_emojis)\n",
    "\n",
    "df_length_before = len(multiple_video_comments)\n",
    "print(\"DataFrame Length Before:\", df_length_before)\n",
    "\n",
    "# drop duplicates\n",
    "multiple_video_comments.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop rows with empty or text length <= 2 comments\n",
    "multiple_video_comments = multiple_video_comments[multiple_video_comments['c_text'].apply(lambda x: len(x) > 2)]\n",
    "\n",
    "df_length_after = len(multiple_video_comments)\n",
    "print(\"DataFrame Length After:\", df_length_after)\n",
    "\n",
    "multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://stackoverflow.com/questions/40375366/pandas-to-csv-checking-for-overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def filter_comments(df):\n",
    "    c = 0\n",
    "    comments = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            if detect(row['c_text']) == 'en':\n",
    "                comments.append(row)\n",
    "                c += 1\n",
    "        except Exception as e:  # Catch any exception\n",
    "            pass\n",
    "    print(\"Number of English Comments: \", c)\n",
    "    new_df = pd.DataFrame(comments, \n",
    "                columns=['product', 'v_title', 'v_videoId',\n",
    "                    'v_channelTitle', 'v_publishTime',\n",
    "                    'v_description', 'v_thumbnail',\n",
    "                    'c_id','c_parentId',\n",
    "                    'c_author', 'c_published_at',\n",
    "                    'c_updated_at', 'c_like_count',\n",
    "                    'c_text'])  # Create a new DataFrame from the list of rows\n",
    "    new_df = new_df.sort_values(by = ['c_like_count'], ascending = False)\n",
    "    new_df = new_df[:200]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English Comments:  405\n"
     ]
    }
   ],
   "source": [
    "new_df = filter_comments(multiple_video_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>Park hyung sik kissed but it was not scripted</td>\n",
       "      <td>qzNIrbZkXCM</td>\n",
       "      <td>KdramaPink</td>\n",
       "      <td>2021-11-14T12:49:29Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg</td>\n",
       "      <td>UgxWJ86QFbnxB-Oz0EF4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>baPBapBaM</td>\n",
       "      <td>2021-12-24T10:09:35Z</td>\n",
       "      <td>2021-12-24T10:09:35Z</td>\n",
       "      <td>67514</td>\n",
       "      <td>he actually admitted that he fell for her but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>Park hyung sik kissed but it was not scripted</td>\n",
       "      <td>qzNIrbZkXCM</td>\n",
       "      <td>KdramaPink</td>\n",
       "      <td>2021-11-14T12:49:29Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg</td>\n",
       "      <td>Ugyk65Vr1FOCmveq6oB4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>sAkUrA6309</td>\n",
       "      <td>2021-12-20T03:03:14Z</td>\n",
       "      <td>2021-12-20T03:03:59Z</td>\n",
       "      <td>47747</td>\n",
       "      <td>usually in any drama especially romcom, actors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>Park hyung sik kissed but it was not scripted</td>\n",
       "      <td>qzNIrbZkXCM</td>\n",
       "      <td>KdramaPink</td>\n",
       "      <td>2021-11-14T12:49:29Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg</td>\n",
       "      <td>UgyswTPxdPEkWuYepK94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>paulina9134</td>\n",
       "      <td>2021-12-21T22:40:15Z</td>\n",
       "      <td>2021-12-21T22:40:15Z</td>\n",
       "      <td>35975</td>\n",
       "      <td>She: living a real kdrama moment while acting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>Park hyung sik kissed but it was not scripted</td>\n",
       "      <td>qzNIrbZkXCM</td>\n",
       "      <td>KdramaPink</td>\n",
       "      <td>2021-11-14T12:49:29Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg</td>\n",
       "      <td>UgxCZ2y-BBBoISQWEvl4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>jungnikahoseok</td>\n",
       "      <td>2021-12-22T17:31:08Z</td>\n",
       "      <td>2021-12-22T17:32:45Z</td>\n",
       "      <td>20616</td>\n",
       "      <td>This hits different when you know the fact tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>Park hyung sik kissed but it was not scripted</td>\n",
       "      <td>qzNIrbZkXCM</td>\n",
       "      <td>KdramaPink</td>\n",
       "      <td>2021-11-14T12:49:29Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg</td>\n",
       "      <td>UgzOIIA-v4FwrlcFBnt4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>raraminaj1251</td>\n",
       "      <td>2022-04-30T13:05:56Z</td>\n",
       "      <td>2022-04-30T13:05:56Z</td>\n",
       "      <td>19679</td>\n",
       "      <td>He fell for her she rejected him and when he w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>behind the scenes of strong woman do bong soon...</td>\n",
       "      <td>3CW87x2bji0</td>\n",
       "      <td>thatkdramaholic</td>\n",
       "      <td>2022-02-17T16:05:16Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/3CW87x2bji0/default.jpg</td>\n",
       "      <td>Ugz9g_hacswZHJeRpyl4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ThatsMeRajvi...</td>\n",
       "      <td>2023-01-06T14:04:44Z</td>\n",
       "      <td>2023-01-06T14:04:44Z</td>\n",
       "      <td>20</td>\n",
       "      <td>Ok now i got the vibe why he is V's friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>Girl Attitude Status 🔥 Ft.Little Mix - Power ✨...</td>\n",
       "      <td>qohGpbw5t2E</td>\n",
       "      <td>aspro editz</td>\n",
       "      <td>2023-10-14T00:30:33Z</td>\n",
       "      <td>shorts.</td>\n",
       "      <td>https://i.ytimg.com/vi/qohGpbw5t2E/default.jpg</td>\n",
       "      <td>Ugz-mMm9y6q6ZzCJ7ll4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>Shyshy_9411</td>\n",
       "      <td>2024-01-18T17:39:51Z</td>\n",
       "      <td>2024-01-18T17:39:51Z</td>\n",
       "      <td>19</td>\n",
       "      <td>This girl l show in all of us are dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>Eun-ji transformation 😨 into zombie 🧟‍♀ All of...</td>\n",
       "      <td>WoXt1vxnE1k</td>\n",
       "      <td>its Blue Drama 💙</td>\n",
       "      <td>2023-06-28T11:23:30Z</td>\n",
       "      <td>Eun-ji transformation into zombie ‍♀ All of us...</td>\n",
       "      <td>https://i.ytimg.com/vi/WoXt1vxnE1k/default.jpg</td>\n",
       "      <td>UgwhsqAUaU2PbLZI8X94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-lo1bp7pe1i</td>\n",
       "      <td>2023-07-03T05:37:28Z</td>\n",
       "      <td>2023-07-03T05:37:28Z</td>\n",
       "      <td>19</td>\n",
       "      <td>Name the film:All of us are dead is very cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>SHE SAVED HER LIFE ❤️ #Shorts</td>\n",
       "      <td>aNV59aHbM0o</td>\n",
       "      <td>Goubtube</td>\n",
       "      <td>2021-07-19T19:00:00Z</td>\n",
       "      <td>SUBSCRIBE FOR MORE! --------------------------...</td>\n",
       "      <td>https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg</td>\n",
       "      <td>UgwJysTTGDp5bLzMrSF4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>jeremylanier4743</td>\n",
       "      <td>2023-10-23T10:44:57Z</td>\n",
       "      <td>2023-10-23T10:44:57Z</td>\n",
       "      <td>19</td>\n",
       "      <td>What I see is this is what men look like when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Strong Girl Nam-soon</td>\n",
       "      <td>He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...</td>\n",
       "      <td>1WMRUKjOle0</td>\n",
       "      <td>VeeDaa</td>\n",
       "      <td>2023-11-23T21:44:22Z</td>\n",
       "      <td></td>\n",
       "      <td>https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg</td>\n",
       "      <td>UgxvhDrdGzmuFEiz85N4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-od9eg4ys2n</td>\n",
       "      <td>2023-12-06T18:11:10Z</td>\n",
       "      <td>2023-12-06T18:11:10Z</td>\n",
       "      <td>18</td>\n",
       "      <td>The chimesty between them is just crazy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product                                            v_title  \\\n",
       "250  Strong Girl Nam-soon      Park hyung sik kissed but it was not scripted   \n",
       "268  Strong Girl Nam-soon      Park hyung sik kissed but it was not scripted   \n",
       "259  Strong Girl Nam-soon      Park hyung sik kissed but it was not scripted   \n",
       "265  Strong Girl Nam-soon      Park hyung sik kissed but it was not scripted   \n",
       "256  Strong Girl Nam-soon      Park hyung sik kissed but it was not scripted   \n",
       "..                    ...                                                ...   \n",
       "312  Strong Girl Nam-soon  behind the scenes of strong woman do bong soon...   \n",
       "156  Strong Girl Nam-soon  Girl Attitude Status 🔥 Ft.Little Mix - Power ✨...   \n",
       "230  Strong Girl Nam-soon  Eun-ji transformation 😨 into zombie 🧟‍♀ All of...   \n",
       "22   Strong Girl Nam-soon                      SHE SAVED HER LIFE ❤️ #Shorts   \n",
       "463  Strong Girl Nam-soon  He can’t sleep, needs cold shower🤣❤️🦋#onlyforl...   \n",
       "\n",
       "       v_videoId    v_channelTitle         v_publishTime  \\\n",
       "250  qzNIrbZkXCM        KdramaPink  2021-11-14T12:49:29Z   \n",
       "268  qzNIrbZkXCM        KdramaPink  2021-11-14T12:49:29Z   \n",
       "259  qzNIrbZkXCM        KdramaPink  2021-11-14T12:49:29Z   \n",
       "265  qzNIrbZkXCM        KdramaPink  2021-11-14T12:49:29Z   \n",
       "256  qzNIrbZkXCM        KdramaPink  2021-11-14T12:49:29Z   \n",
       "..           ...               ...                   ...   \n",
       "312  3CW87x2bji0   thatkdramaholic  2022-02-17T16:05:16Z   \n",
       "156  qohGpbw5t2E       aspro editz  2023-10-14T00:30:33Z   \n",
       "230  WoXt1vxnE1k  its Blue Drama 💙  2023-06-28T11:23:30Z   \n",
       "22   aNV59aHbM0o          Goubtube  2021-07-19T19:00:00Z   \n",
       "463  1WMRUKjOle0            VeeDaa  2023-11-23T21:44:22Z   \n",
       "\n",
       "                                         v_description  \\\n",
       "250                                                      \n",
       "268                                                      \n",
       "259                                                      \n",
       "265                                                      \n",
       "256                                                      \n",
       "..                                                 ...   \n",
       "312                                                      \n",
       "156                                            shorts.   \n",
       "230  Eun-ji transformation into zombie ‍♀ All of us...   \n",
       "22   SUBSCRIBE FOR MORE! --------------------------...   \n",
       "463                                                      \n",
       "\n",
       "                                        v_thumbnail  \\\n",
       "250  https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg   \n",
       "268  https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg   \n",
       "259  https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg   \n",
       "265  https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg   \n",
       "256  https://i.ytimg.com/vi/qzNIrbZkXCM/default.jpg   \n",
       "..                                              ...   \n",
       "312  https://i.ytimg.com/vi/3CW87x2bji0/default.jpg   \n",
       "156  https://i.ytimg.com/vi/qohGpbw5t2E/default.jpg   \n",
       "230  https://i.ytimg.com/vi/WoXt1vxnE1k/default.jpg   \n",
       "22   https://i.ytimg.com/vi/aNV59aHbM0o/default.jpg   \n",
       "463  https://i.ytimg.com/vi/1WMRUKjOle0/default.jpg   \n",
       "\n",
       "                           c_id c_parentId          c_author  \\\n",
       "250  UgxWJ86QFbnxB-Oz0EF4AaABAg                    baPBapBaM   \n",
       "268  Ugyk65Vr1FOCmveq6oB4AaABAg                   sAkUrA6309   \n",
       "259  UgyswTPxdPEkWuYepK94AaABAg                  paulina9134   \n",
       "265  UgxCZ2y-BBBoISQWEvl4AaABAg               jungnikahoseok   \n",
       "256  UgzOIIA-v4FwrlcFBnt4AaABAg                raraminaj1251   \n",
       "..                          ...        ...               ...   \n",
       "312  Ugz9g_hacswZHJeRpyl4AaABAg              ThatsMeRajvi...   \n",
       "156  Ugz-mMm9y6q6ZzCJ7ll4AaABAg                  Shyshy_9411   \n",
       "230  UgwhsqAUaU2PbLZI8X94AaABAg              user-lo1bp7pe1i   \n",
       "22   UgwJysTTGDp5bLzMrSF4AaABAg             jeremylanier4743   \n",
       "463  UgxvhDrdGzmuFEiz85N4AaABAg              user-od9eg4ys2n   \n",
       "\n",
       "           c_published_at          c_updated_at  c_like_count  \\\n",
       "250  2021-12-24T10:09:35Z  2021-12-24T10:09:35Z         67514   \n",
       "268  2021-12-20T03:03:14Z  2021-12-20T03:03:59Z         47747   \n",
       "259  2021-12-21T22:40:15Z  2021-12-21T22:40:15Z         35975   \n",
       "265  2021-12-22T17:31:08Z  2021-12-22T17:32:45Z         20616   \n",
       "256  2022-04-30T13:05:56Z  2022-04-30T13:05:56Z         19679   \n",
       "..                    ...                   ...           ...   \n",
       "312  2023-01-06T14:04:44Z  2023-01-06T14:04:44Z            20   \n",
       "156  2024-01-18T17:39:51Z  2024-01-18T17:39:51Z            19   \n",
       "230  2023-07-03T05:37:28Z  2023-07-03T05:37:28Z            19   \n",
       "22   2023-10-23T10:44:57Z  2023-10-23T10:44:57Z            19   \n",
       "463  2023-12-06T18:11:10Z  2023-12-06T18:11:10Z            18   \n",
       "\n",
       "                                                c_text  \n",
       "250  he actually admitted that he fell for her but ...  \n",
       "268  usually in any drama especially romcom, actors...  \n",
       "259  She: living a real kdrama moment while acting ...  \n",
       "265  This hits different when you know the fact tha...  \n",
       "256  He fell for her she rejected him and when he w...  \n",
       "..                                                 ...  \n",
       "312         Ok now i got the vibe why he is V's friend  \n",
       "156            This girl l show in all of us are dead   \n",
       "230      Name the film:All of us are dead is very cool  \n",
       "22   What I see is this is what men look like when ...  \n",
       "463            The chimesty between them is just crazy  \n",
       "\n",
       "[200 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Creating a folder for the comments\n",
    "# directory = 'comments'\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "\n",
    "# for index, row in new_df.iterrows():\n",
    "#     # Different file path for each of the comments\n",
    "#     file_path = os.path.join(directory, f'comment_{index}.txt')\n",
    "    \n",
    "#     # Write the comment content to the text file\n",
    "#     with open(file_path, 'w', encoding='utf-8') as file:\n",
    "#         file.write(row['c_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "filename = 'final_comments_df.csv'\n",
    "files_present = glob.glob(filename)\n",
    "# will only write to disk if file doesnt exist\n",
    "if not files_present:\n",
    "    new_df.to_csv(filename, index=False)\n",
    "    new_df\n",
    "else:\n",
    "    print (f'File Already Exists. Delete {filename}' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
