{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/farheenfab/AppliedText_CW/blob/main/CW1-generate_dataset.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F20AA Coursework 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ishaq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk \n",
    "import os\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from langdetect import detect\n",
    "import shutil\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "from tabulate import tabulate\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Collection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the api service name, version and developer key for the api call.\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyAWj_uzrhZL18X32S_P79pT1wnSYGpuA4k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/search/list#parameters\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/comments/list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a class called api_handler which contains functions such as `get_video_details()`, `get_videos()`, `get_video_df()`, `get_comments()`, `get_comment_replies()`, `get_comments_df()`, `create_video_df_from_search()`, `create_video_df()`. These functions help us by either manually retrieving the videos and comments or by automatically curating the videos and comments using the product given to the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class api_handler:\n",
    "    def __init__(self, api_service_name, api_version, developer_key):\n",
    "        self.client = googleapiclient.discovery.build(api_service_name,\n",
    "                                                    api_version,\n",
    "                                                    developerKey=developer_key)\n",
    "        \n",
    "    # Search for videos details given id\n",
    "    def get_video_details(self, videoId, part=\"snippet\"):\n",
    "        request = self.client.videos().list(\n",
    "            part=part,\n",
    "            id=videoId\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        if 'items' in response:\n",
    "            video_details = response['items'][0]\n",
    "            snippet=video_details['snippet']\n",
    "            snippet['videoId']=videoId\n",
    "            snippet['id']=videoId\n",
    "            snippet['publishTime']=video_details.get('snippet', {}).get('publishedAt', {})\n",
    "            snippet['thumbnails']=video_details.get('snippet', {}).get('thumbnails', {}).get('default', {}).get('url', '')\n",
    "            return snippet\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Search for videos given query\n",
    "    def get_videos(self,query,maxResults=5,part=\"snippet\"):\n",
    "        request = self.client.search().list(\n",
    "            part=part,\n",
    "            maxResults=maxResults,\n",
    "            # higher view count is likely to be more relevent \n",
    "            order=\"viewCount\",\n",
    "            q=query,  \n",
    "            # american region videos \n",
    "            regionCode=\"US\",\n",
    "            # english videos\n",
    "            relevanceLanguage=\"en\",\n",
    "            type=\"video\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return response\n",
    "    \n",
    "    # Format Response from get_videos to dataframe\n",
    "    def get_video_df(response):\n",
    "        items=[]\n",
    "        for item in response['items']:\n",
    "            snippet=item.get('snippet', {})\n",
    "            items+=[{\n",
    "                'title':snippet.get('title', ''),\n",
    "                'videoId':item.get('id', {}).get('videoId', ''),\n",
    "                'channelTitle':snippet.get('channelTitle', ''),\n",
    "                'publishTime':snippet.get('publishTime', ''),\n",
    "                'description':snippet.get('description', ''),\n",
    "                'thumbnails':snippet.get('thumbnails', {}).get('default', {}).get('url', '')\n",
    "                }]\n",
    "        df=pd.DataFrame(items)\n",
    "        return df\n",
    "    \n",
    "    # Get comments from video\n",
    "    def get_comments(self,videoId,part=\"snippet\",maxResults=100,maxResultsDepth=100):\n",
    "        all_comments = []\n",
    "        f = 0\n",
    "        nextPageToken = None\n",
    "        while maxResults > 0:\n",
    "            request = self.client.commentThreads().list(\n",
    "                part=part,\n",
    "                videoId=videoId,\n",
    "                maxResults=min(maxResults, 100),\n",
    "                order='relevance',\n",
    "                moderationStatus='published',\n",
    "                textFormat='plainText',\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "            response = request.execute()\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "            if 'items' in response:\n",
    "                all_comments+=[response]\n",
    "                for item in response['items']:\n",
    "                    # extract the comment ID to get replies\n",
    "                    comment_id = item.get('snippet',{}).get('topLevelComment',{}).get('id','')\n",
    "                    if item.get('snippet',{}).get('totalReplyCount',0)>2:\n",
    "                        if f == 0:\n",
    "                            print('getting replies:',item.get('snippet',{}).get('totalReplyCount',0))\n",
    "                            f = 1\n",
    "                        replies = self.get_comment_replies(comment_id, maxResults=maxResultsDepth)\n",
    "                        all_comments += replies\n",
    "\n",
    "            maxResults -= min(maxResults, 100)\n",
    "            if nextPageToken is None:\n",
    "                break;    \n",
    "        return all_comments\n",
    "    \n",
    "    # Get replies from comment \n",
    "    def get_comment_replies(self, commentId, part=\"snippet\", maxResults=100):\n",
    "        all_comments = []\n",
    "        nextPageToken = None\n",
    "        while maxResults > 0 and (nextPageToken != None or len(all_comments)==0):\n",
    "\n",
    "            request = self.client.comments().list(\n",
    "                part=part,\n",
    "                parentId=commentId,\n",
    "                maxResults=min(maxResults, 100),\n",
    "                textFormat='plainText',\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "\n",
    "            response = request.execute()\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "\n",
    "            if 'items' in response and len(response['items'])>0:\n",
    "                for item in response['items']:\n",
    "                    modified_response = {\n",
    "                        'items': [\n",
    "                            {\n",
    "                                'id':item.get('id'),\n",
    "                                'snippet': {\n",
    "                                    'topLevelComment': {\n",
    "                                        'snippet': item.get('snippet','')\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                    all_comments += [modified_response]\n",
    "            maxResults -= min(maxResults, 100)\n",
    "            if nextPageToken is None:\n",
    "                break;    \n",
    "        return all_comments\n",
    "\n",
    "    # Format response from get_comments to dataframe\n",
    "    def get_comments_df(response, video,product):\n",
    "        comments = []\n",
    "        for pages in response:\n",
    "            for item in pages['items']:\n",
    "                comment = item.get('snippet', {}).get('topLevelComment', {}).get('snippet', {})\n",
    "                comments.append([\n",
    "                        product,\n",
    "                        video.get('title', ''),\n",
    "                        video.get('videoId', ''),\n",
    "                        video.get('channelTitle', ''),\n",
    "                        video.get('publishTime', ''),\n",
    "                        video.get('description', ''),\n",
    "                        video.get('thumbnails', ''),\n",
    "                        item.get('id', ''),  \n",
    "                        comment.get('parentId', ''),  \n",
    "                        comment.get('authorDisplayName', '')[1:],  \n",
    "                        comment.get('publishedAt', ''),\n",
    "                        comment.get('updatedAt', ''),\n",
    "                        comment.get('likeCount', ''),\n",
    "                        comment.get('textDisplay', '')\n",
    "                    ])\n",
    "\n",
    "        df = pd.DataFrame(comments,\n",
    "            columns=['product', 'v_title', 'v_videoId',\n",
    "                    'v_channelTitle', 'v_publishTime',\n",
    "                    'v_description', 'v_thumbnail',\n",
    "                    'c_id','c_parentId',\n",
    "                    'c_author', 'c_published_at',\n",
    "                    'c_updated_at', 'c_like_count',\n",
    "                    'c_text'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Search for videos related to products iteratively\n",
    "    # Collect comments from each video and place it into an array\n",
    "    def create_video_df_from_search(self, products,\n",
    "                                    number_of_videos_per_product=5,\n",
    "                                    number_of_comments_per_video=100\n",
    "                                    ,number_of_replies_per_comment=100):\n",
    "        multiple_video_comments = pd.DataFrame()\n",
    "        for product in products:\n",
    "            # get 25 first videos with the highest viewer counts \n",
    "            response = self.get_videos(query=product, maxResults=number_of_videos_per_product)\n",
    "            # Convert results to df\n",
    "            videos_df = api_handler.get_video_df(response)\n",
    "            # For each video get a maximum of 100 comments\n",
    "            # and place comments into an array\n",
    "            for _, video in videos_df.iterrows():\n",
    "                try:\n",
    "                    response = self.get_comments(video['videoId'], maxResults=number_of_comments_per_video,maxResultsDepth=number_of_replies_per_comment)\n",
    "                    comments_df = api_handler.get_comments_df(response, video, product)\n",
    "                except:\n",
    "                    # Function fails as the API returns 403 if the channel has comments disabled\n",
    "                    # place an empty entry instead it can be deleted later\n",
    "                    comments_df = pd.DataFrame(np.zeros((1, 14)),\n",
    "                                                columns=['product', 'v_title', 'v_videoId',\n",
    "                                                        'v_channelTitle', 'v_publishTime',\n",
    "                                                        'v_description', 'v_thumbnail',\n",
    "                                                        'c_id','c_parentId',\n",
    "                                                        'c_author', 'c_published_at',\n",
    "                                                        'c_updated_at', 'c_like_count',\n",
    "                                                        'c_text'])\n",
    "                    print('Unable to retrieve comments:', video.get('title', ''))\n",
    "                multiple_video_comments = pd.concat([multiple_video_comments, comments_df], ignore_index=True)\n",
    "        return multiple_video_comments\n",
    "        \n",
    "    # alternative method by explicitely specifying videos\n",
    "    def create_video_df(self,products,videos,number_of_comments_per_video=100,number_of_replies_per_comment=100):\n",
    "        count=0\n",
    "        multiple_video_comments = pd.DataFrame()\n",
    "        for product in products:\n",
    "            for video in videos[count]:\n",
    "                response = self.get_comments(video,maxResults=number_of_comments_per_video,maxResultsDepth=number_of_replies_per_comment) \n",
    "                video=self.get_video_details(video)\n",
    "                comments_df = api_handler.get_comments_df(response, video, product)\n",
    "                multiple_video_comments = pd.concat([multiple_video_comments, comments_df], ignore_index=True)\n",
    "            count+=1\n",
    "        return multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen the Korean Drama called Squid Game to perform the sentiment analysis on. We specify the product in the products list, create a `api_handler` class object, use the `create_video_df_from_search()` function to automatically curate comments using the YouTube api call, and get a pandas Dataframe in return containing details about the videos and the comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "products=[\"Squid Game Korean Drama (2021)\"]\n",
    "\n",
    "youtube=api_handler(api_service_name, api_version, DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting replies: 750\n",
      "getting replies: 520\n",
      "getting replies: 5\n",
      "getting replies: 61\n",
      "getting replies: 64\n",
      "getting replies: 129\n",
      "getting replies: 14\n",
      "getting replies: 101\n",
      "getting replies: 350\n",
      "getting replies: 16\n",
      "getting replies: 5\n",
      "getting replies: 14\n",
      "getting replies: 317\n",
      "getting replies: 25\n",
      "getting replies: 230\n",
      "getting replies: 390\n",
      "getting replies: 4\n",
      "getting replies: 154\n",
      "getting replies: 461\n",
      "getting replies: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzH8vliQSJKHQMGZjx4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>1007679</td>\n",
       "      <td>Like I said in the video, subscribe if you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgwDhFNTCbfck5apuUJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>DoodleChaos</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>513976</td>\n",
       "      <td>Huge props to the set designers, everything wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzVlS_nKI4aXISU_ep4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>mukul_editz</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>157</td>\n",
       "      <td>Your videos are so interesting ❤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgxykcUWbPcLhlL-Gy14AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>SpamR1_2013</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>1428</td>\n",
       "      <td>that guy who sacrificed himself on purpose for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>Ugxu5B8dQ9-mZpfW-UV4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-cs9zv3gh1k</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>185</td>\n",
       "      <td>This version of the game is pretty much what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17848</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgyA6Pcie4eYrtQD-7x4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-yl2jg9bj4b</td>\n",
       "      <td>2021-11-24T15:03:41Z</td>\n",
       "      <td>2021-11-24T15:03:41Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Юю</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17849</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgwszBOmRx0V_hkKE4t4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>rgcsedtfst9555</td>\n",
       "      <td>2021-11-12T15:24:16Z</td>\n",
       "      <td>2021-11-12T15:24:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>د</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17850</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgzI931NcP5kf17mT914AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>amirelbennari3308</td>\n",
       "      <td>2022-02-19T19:23:30Z</td>\n",
       "      <td>2022-02-19T19:23:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17851</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgzXAxey1VTJorM-ikV4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>iateacookielol4730</td>\n",
       "      <td>2021-11-26T01:44:32Z</td>\n",
       "      <td>2021-11-26T01:44:32Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Who watches squid game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17852</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgyGmtt8dsz15b0juf14AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>dkdarklimule6536</td>\n",
       "      <td>2022-03-15T19:45:10Z</td>\n",
       "      <td>2022-03-15T19:45:10Z</td>\n",
       "      <td>0</td>\n",
       "      <td>👎👎👎👎👎</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17853 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product                              v_title  \\\n",
       "0      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "1      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "2      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "3      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "4      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "...                               ...                                  ...   \n",
       "17848  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "17849  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "17850  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "17851  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "17852  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "\n",
       "         v_videoId v_channelTitle         v_publishTime  \\\n",
       "0      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "1      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "2      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "3      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "4      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "...            ...            ...                   ...   \n",
       "17848  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "17849  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "17850  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "17851  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "17852  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "0      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "1      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "2      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "3      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "4      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "...                                                  ...   \n",
       "17848  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17849  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17850  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17851  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17852  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "0      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "1      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "2      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "3      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "4      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "...                                               ...   \n",
       "17848  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "17849  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "17850  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "17851  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "17852  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "\n",
       "                             c_id c_parentId            c_author  \\\n",
       "0      UgzH8vliQSJKHQMGZjx4AaABAg                        MrBeast   \n",
       "1      UgwDhFNTCbfck5apuUJ4AaABAg                    DoodleChaos   \n",
       "2      UgzVlS_nKI4aXISU_ep4AaABAg                    mukul_editz   \n",
       "3      UgxykcUWbPcLhlL-Gy14AaABAg                    SpamR1_2013   \n",
       "4      Ugxu5B8dQ9-mZpfW-UV4AaABAg                user-cs9zv3gh1k   \n",
       "...                           ...        ...                 ...   \n",
       "17848  UgyA6Pcie4eYrtQD-7x4AaABAg                user-yl2jg9bj4b   \n",
       "17849  UgwszBOmRx0V_hkKE4t4AaABAg                 rgcsedtfst9555   \n",
       "17850  UgzI931NcP5kf17mT914AaABAg              amirelbennari3308   \n",
       "17851  UgzXAxey1VTJorM-ikV4AaABAg             iateacookielol4730   \n",
       "17852  UgyGmtt8dsz15b0juf14AaABAg               dkdarklimule6536   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "0      2021-11-24T21:02:45Z  2021-11-24T21:02:45Z       1007679   \n",
       "1      2021-11-24T22:07:54Z  2021-11-24T22:07:54Z        513976   \n",
       "2      2023-12-30T01:55:59Z  2023-12-30T01:55:59Z           157   \n",
       "3      2023-11-27T00:57:21Z  2023-11-27T00:57:21Z          1428   \n",
       "4      2024-01-30T20:17:02Z  2024-01-30T20:17:02Z           185   \n",
       "...                     ...                   ...           ...   \n",
       "17848  2021-11-24T15:03:41Z  2021-11-24T15:03:41Z             0   \n",
       "17849  2021-11-12T15:24:16Z  2021-11-12T15:24:16Z             0   \n",
       "17850  2022-02-19T19:23:30Z  2022-02-19T19:23:30Z             0   \n",
       "17851  2021-11-26T01:44:32Z  2021-11-26T01:44:32Z             0   \n",
       "17852  2022-03-15T19:45:10Z  2022-03-15T19:45:10Z             0   \n",
       "\n",
       "                                                  c_text  \n",
       "0      Like I said in the video, subscribe if you hav...  \n",
       "1      Huge props to the set designers, everything wa...  \n",
       "2                       Your videos are so interesting ❤  \n",
       "3      that guy who sacrificed himself on purpose for...  \n",
       "4      This version of the game is pretty much what t...  \n",
       "...                                                  ...  \n",
       "17848                                                 Юю  \n",
       "17849                                                  د  \n",
       "17850                                               Null  \n",
       "17851                             Who watches squid game  \n",
       "17852                                              👎👎👎👎👎  \n",
       "\n",
       "[17853 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_video_comments=youtube.create_video_df_from_search(products,number_of_videos_per_product=20,number_of_comments_per_video=1000,number_of_replies_per_comment=0)\n",
    "multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Analysis, Selection and Labeling:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from:\n",
    "\n",
    "https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove emojis : As emojis do not provide any helpful information they should be removed from the text strings.\n",
    "def remove_emojis(data):\n",
    "    if isinstance(data, str):\n",
    "        # Remove html tags\n",
    "        data = BeautifulSoup(data, \"html.parser\").get_text()\n",
    "        # Remove emote, etc\n",
    "        emoj = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "                        \"]+\", re.UNICODE)\n",
    "        # english_words = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "\n",
    "        return re.sub(emoj, '', data)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row containing NA values.\n",
    "multiple_video_comments.dropna(subset=['c_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaq\\AppData\\Local\\Temp\\ipykernel_20228\\2754946649.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  data = BeautifulSoup(data, \"html.parser\").get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Length Before: 17853\n",
      "DataFrame Length After: 15298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzH8vliQSJKHQMGZjx4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>1007679</td>\n",
       "      <td>Like I said in the video, subscribe if you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgwDhFNTCbfck5apuUJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>DoodleChaos</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>513976</td>\n",
       "      <td>Huge props to the set designers, everything wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzVlS_nKI4aXISU_ep4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>mukul_editz</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>157</td>\n",
       "      <td>Your videos are so interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgxykcUWbPcLhlL-Gy14AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>SpamR1_2013</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>1428</td>\n",
       "      <td>that guy who sacrificed himself on purpose for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>Ugxu5B8dQ9-mZpfW-UV4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-cs9zv3gh1k</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>185</td>\n",
       "      <td>This version of the game is pretty much what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17845</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgwIdpawuPIvk0XGpr94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>raileyholtgranil4179</td>\n",
       "      <td>2021-12-15T13:31:21Z</td>\n",
       "      <td>2021-12-15T13:31:21Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Ughufhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17846</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgyzsQx15miO47Fuiot4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>sahanaj6311</td>\n",
       "      <td>2022-01-22T05:43:15Z</td>\n",
       "      <td>2022-01-22T05:43:15Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Sseommets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17847</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgyCxb3_EpN8rUzNtsB4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>isaccperaltamontecino2801</td>\n",
       "      <td>2022-01-18T16:51:07Z</td>\n",
       "      <td>2022-01-18T16:51:07Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Lllllll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17850</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgzI931NcP5kf17mT914AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>amirelbennari3308</td>\n",
       "      <td>2022-02-19T19:23:30Z</td>\n",
       "      <td>2022-02-19T19:23:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17851</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>UgzXAxey1VTJorM-ikV4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>iateacookielol4730</td>\n",
       "      <td>2021-11-26T01:44:32Z</td>\n",
       "      <td>2021-11-26T01:44:32Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Who watches squid game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15298 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product                              v_title  \\\n",
       "0      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "1      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "2      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "3      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "4      Squid Game Korean Drama (2021)    $456,000 Squid Game In Real Life!   \n",
       "...                               ...                                  ...   \n",
       "17845  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "17846  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "17847  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "17850  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "17851  Squid Game Korean Drama (2021)  SQUID GAME | SUGAR HONEYCOMBS SCENE   \n",
       "\n",
       "         v_videoId v_channelTitle         v_publishTime  \\\n",
       "0      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "1      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "2      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "3      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "4      0e3GPea1Tyg        MrBeast  2021-11-24T21:00:01Z   \n",
       "...            ...            ...                   ...   \n",
       "17845  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "17846  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "17847  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "17850  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "17851  yJ0Pfldt8jw     memebappe   2021-10-21T10:45:31Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "0      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "1      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "2      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "3      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "4      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "...                                                  ...   \n",
       "17845  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17846  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17847  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17850  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17851  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "0      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "1      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "2      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "3      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "4      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "...                                               ...   \n",
       "17845  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "17846  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "17847  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "17850  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "17851  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "\n",
       "                             c_id c_parentId                   c_author  \\\n",
       "0      UgzH8vliQSJKHQMGZjx4AaABAg                               MrBeast   \n",
       "1      UgwDhFNTCbfck5apuUJ4AaABAg                           DoodleChaos   \n",
       "2      UgzVlS_nKI4aXISU_ep4AaABAg                           mukul_editz   \n",
       "3      UgxykcUWbPcLhlL-Gy14AaABAg                           SpamR1_2013   \n",
       "4      Ugxu5B8dQ9-mZpfW-UV4AaABAg                       user-cs9zv3gh1k   \n",
       "...                           ...        ...                        ...   \n",
       "17845  UgwIdpawuPIvk0XGpr94AaABAg                  raileyholtgranil4179   \n",
       "17846  UgyzsQx15miO47Fuiot4AaABAg                           sahanaj6311   \n",
       "17847  UgyCxb3_EpN8rUzNtsB4AaABAg             isaccperaltamontecino2801   \n",
       "17850  UgzI931NcP5kf17mT914AaABAg                     amirelbennari3308   \n",
       "17851  UgzXAxey1VTJorM-ikV4AaABAg                    iateacookielol4730   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "0      2021-11-24T21:02:45Z  2021-11-24T21:02:45Z       1007679   \n",
       "1      2021-11-24T22:07:54Z  2021-11-24T22:07:54Z        513976   \n",
       "2      2023-12-30T01:55:59Z  2023-12-30T01:55:59Z           157   \n",
       "3      2023-11-27T00:57:21Z  2023-11-27T00:57:21Z          1428   \n",
       "4      2024-01-30T20:17:02Z  2024-01-30T20:17:02Z           185   \n",
       "...                     ...                   ...           ...   \n",
       "17845  2021-12-15T13:31:21Z  2021-12-15T13:31:21Z             0   \n",
       "17846  2022-01-22T05:43:15Z  2022-01-22T05:43:15Z             1   \n",
       "17847  2022-01-18T16:51:07Z  2022-01-18T16:51:07Z             0   \n",
       "17850  2022-02-19T19:23:30Z  2022-02-19T19:23:30Z             0   \n",
       "17851  2021-11-26T01:44:32Z  2021-11-26T01:44:32Z             0   \n",
       "\n",
       "                                                  c_text  \n",
       "0      Like I said in the video, subscribe if you hav...  \n",
       "1      Huge props to the set designers, everything wa...  \n",
       "2                        Your videos are so interesting   \n",
       "3      that guy who sacrificed himself on purpose for...  \n",
       "4      This version of the game is pretty much what t...  \n",
       "...                                                  ...  \n",
       "17845                                            Ughufhh  \n",
       "17846                                          Sseommets  \n",
       "17847                                            Lllllll  \n",
       "17850                                               Null  \n",
       "17851                             Who watches squid game  \n",
       "\n",
       "[15298 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove emojis from the text to be analyzed\n",
    "multiple_video_comments['c_text']=multiple_video_comments['c_text'].apply(remove_emojis)\n",
    "\n",
    "df_length_before = len(multiple_video_comments)\n",
    "print(\"DataFrame Length Before:\", df_length_before)\n",
    "\n",
    "# Drop duplicates\n",
    "multiple_video_comments.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop rows with empty or text length <= 2 comments\n",
    "multiple_video_comments = multiple_video_comments[multiple_video_comments['c_text'].apply(lambda x: len(x) > 2)]\n",
    "\n",
    "df_length_after = len(multiple_video_comments)\n",
    "print(\"DataFrame Length After:\", df_length_after)\n",
    "\n",
    "multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://stackoverflow.com/questions/40375366/pandas-to-csv-checking-for-overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing:\n",
    "    def __init__(self):\n",
    "        # Define keywords related to the TV show\n",
    "        self.tv_show_keywords = ['Squid Game', 'Gi-hun', 'Sang-woo', 'Player', 'Red light, green light', 'Honeycomb',\n",
    "                            'Tug of war', 'Marbles', 'Front man', 'VIPs', 'Doll', 'Coffin', 'Square', 'Triangle', \n",
    "                            'Circle', 'Death game', 'death', 'Survival game', 'Money', 'prize', 'Il-nam', 'Hwang Jun-ho'\n",
    "                            'director', 'Cho Sang-woo', 'Masked man', 'Childhood', 'game', 'Pink soldier', 'Betrayal',\n",
    "                            'Seong Gi-hun', 'Survival', 'Games', 'Competition', 'Squid', 'Masks', 'ali', ]\n",
    "        # Setting threshold value for validating the relevance of the comment\n",
    "        self.threshold = 1\n",
    "\n",
    "    # Tokenize text and remove stop words\n",
    "    def preprocess_text(self, text):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "        return filtered_tokens\n",
    "\n",
    "    # Matching function to check relevance of the comments\n",
    "    def match_keywords(self, tokens):\n",
    "        return [token for token in tokens if token in self.tv_show_keywords]\n",
    "\n",
    "    # Scoring function to calculate how many tokens matched\n",
    "    def calculate_score(self, tokens):\n",
    "        return len(tokens)\n",
    "\n",
    "    # Validate function to validate the relevance based on threshold\n",
    "    def validate_relevance(self, score):\n",
    "        return score >= self.threshold\n",
    "\n",
    "    def filter_comments(self, df):\n",
    "        c = 0\n",
    "        comments = []\n",
    "        irrelevant_keywords = ['HYVE', 'crypto', 'promotion', 'ad', 'spam', 'advertisement', 'spoiler', 'leak', 'promo', 'off-topic', 'clickbait',\n",
    "                            'self-promotion', '0:', '1:', '2:', '3:', '4:', '5:', '6:', '7:',\n",
    "                            '8:', '9:', '10:', '11:', '12:', '13:', '14:', '15:']\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                if detect(row['c_text']) == 'en' and not any(keyword in row['c_text'] for keyword in irrelevant_keywords):\n",
    "                    comments.append(row)\n",
    "                    c += 1\n",
    "            except Exception as e:  # Catch any exception\n",
    "                pass\n",
    "        print(\"Number of Filtered Comments: \", c)\n",
    "        new_df = pd.DataFrame(comments, \n",
    "                    columns=['product', 'v_title', 'v_videoId',\n",
    "                        'v_channelTitle', 'v_publishTime',\n",
    "                        'v_description', 'v_thumbnail',\n",
    "                        'c_id','c_parentId',\n",
    "                        'c_author', 'c_published_at',\n",
    "                        'c_updated_at', 'c_like_count',\n",
    "                        'c_text'])  # Create a new DataFrame from the list of rows\n",
    "        new_df = new_df.sort_values(by = ['c_like_count'], ascending = False)\n",
    "        new_df.drop_duplicates(inplace=True)\n",
    "        new_df = new_df[:500]\n",
    "        return new_df\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        c = 0\n",
    "        comments = []\n",
    "        for index, row in df.iterrows():\n",
    "            processed_text = self.preprocess_text(row['c_text'])\n",
    "            matched_keywords = self.match_keywords(processed_text)\n",
    "            score = self.calculate_score(matched_keywords)\n",
    "            is_relevant = self.validate_relevance(score)\n",
    "            if is_relevant == 1:\n",
    "                comments.append(row)\n",
    "                c += 1\n",
    "\n",
    "        new_df = pd.DataFrame(comments, \n",
    "                    columns=['product', 'v_title', 'v_videoId',\n",
    "                        'v_channelTitle', 'v_publishTime',\n",
    "                        'v_description', 'v_thumbnail',\n",
    "                        'c_id','c_parentId',\n",
    "                        'c_author', 'c_published_at',\n",
    "                        'c_updated_at', 'c_like_count',\n",
    "                        'c_text'])\n",
    "        print(\"Number of Processed Comments: \", c)\n",
    "        new_df = self.filter_comments(new_df)\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Processed Comments:  1800\n",
      "Number of Filtered Comments:  1078\n"
     ]
    }
   ],
   "source": [
    "p = preprocessing()\n",
    "new_df = p.preprocess(multiple_video_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16431</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugy5u7EHRR6IRod2vxN4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>MaisieTheUnicorn</td>\n",
       "      <td>2021-09-27T15:53:33Z</td>\n",
       "      <td>2021-09-27T15:53:33Z</td>\n",
       "      <td>33375</td>\n",
       "      <td>Hoyeon in Squid Game:\\nHoyeon in RL:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16401</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgxlkxXiNXjyjJcOcel4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>esophagus3319</td>\n",
       "      <td>2021-09-25T02:58:15Z</td>\n",
       "      <td>2021-09-25T02:58:15Z</td>\n",
       "      <td>21226</td>\n",
       "      <td>the way her real personality is totally differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16407</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugy5Vw4Hlzj-ZHpMgjN4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>Jk-bp4nu</td>\n",
       "      <td>2021-09-25T18:37:02Z</td>\n",
       "      <td>2021-09-25T18:37:02Z</td>\n",
       "      <td>17519</td>\n",
       "      <td>Even if Squid Game was Ho Yeon's first drama, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16737</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgxtKW6yi_uSmDXvAzt4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ChristineWang19</td>\n",
       "      <td>2021-09-25T01:02:12Z</td>\n",
       "      <td>2021-09-25T01:52:09Z</td>\n",
       "      <td>14897</td>\n",
       "      <td>OMG I CLICKED SO FAST!!\\nLITERALLY THIRSTY FOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16379</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgyMnV8PjtgP5-d2RfF4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>brooke4608</td>\n",
       "      <td>2021-10-09T00:22:59Z</td>\n",
       "      <td>2021-10-09T00:22:59Z</td>\n",
       "      <td>14599</td>\n",
       "      <td>It’s so nice seeing them play a game that won’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17441</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | SUGAR HONEYCOMBS SCENE</td>\n",
       "      <td>yJ0Pfldt8jw</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-21T10:45:31Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg</td>\n",
       "      <td>Ugz1oW4SvBYORryAJt94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>JayJay-xb3xs</td>\n",
       "      <td>2022-07-20T23:20:51Z</td>\n",
       "      <td>2022-07-20T23:20:51Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Squid game is so awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14452</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Red Light Green Light No Blood - Squid Game 1</td>\n",
       "      <td>Ww9HCin8ORs</td>\n",
       "      <td>PopMov</td>\n",
       "      <td>2021-10-06T20:56:52Z</td>\n",
       "      <td>I did this for a special person who wanted to ...</td>\n",
       "      <td>https://i.ytimg.com/vi/Ww9HCin8ORs/default.jpg</td>\n",
       "      <td>UgxAa4jX2Xmu2s64A1h4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>kimsutton4814</td>\n",
       "      <td>2021-10-22T10:34:54Z</td>\n",
       "      <td>2021-10-22T10:34:54Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Poor 118 about to become friends with 456 but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game | Official Trailer | Netflix</td>\n",
       "      <td>oqxAJKy0ii4</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>2021-09-02T00:00:02Z</td>\n",
       "      <td>A Netflix Series | Squid Game Survive or die W...</td>\n",
       "      <td>https://i.ytimg.com/vi/oqxAJKy0ii4/default.jpg</td>\n",
       "      <td>UgzLBpLI-3i8k2pOYUd4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>pauldevaraj4271</td>\n",
       "      <td>2021-12-17T03:43:16Z</td>\n",
       "      <td>2021-12-17T03:43:16Z</td>\n",
       "      <td>2</td>\n",
       "      <td>This squid game series was so sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game | Official Trailer | Netflix</td>\n",
       "      <td>oqxAJKy0ii4</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>2021-09-02T00:00:02Z</td>\n",
       "      <td>A Netflix Series | Squid Game Survive or die W...</td>\n",
       "      <td>https://i.ytimg.com/vi/oqxAJKy0ii4/default.jpg</td>\n",
       "      <td>UgznDbWb9XHq1mINk3F4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>XtraLuminouz</td>\n",
       "      <td>2022-07-30T09:56:53Z</td>\n",
       "      <td>2022-07-30T09:56:53Z</td>\n",
       "      <td>2</td>\n",
       "      <td>the fact that this has less views than the vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8490</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Red light green light 🤯 the death game ☠️ | Sq...</td>\n",
       "      <td>gibkl8yTBN0</td>\n",
       "      <td>its Blue Drama 💙</td>\n",
       "      <td>2023-06-30T11:10:13Z</td>\n",
       "      <td>Red light green light the death game ☠️ | Squi...</td>\n",
       "      <td>https://i.ytimg.com/vi/gibkl8yTBN0/default.jpg</td>\n",
       "      <td>Ugx1mFewZRvAzhSOBfB4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>veternalsmoves8590</td>\n",
       "      <td>2023-10-15T12:46:11Z</td>\n",
       "      <td>2023-10-15T12:46:11Z</td>\n",
       "      <td>2</td>\n",
       "      <td>I just played this game in roblox but I closed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product  \\\n",
       "16431  Squid Game Korean Drama (2021)   \n",
       "16401  Squid Game Korean Drama (2021)   \n",
       "16407  Squid Game Korean Drama (2021)   \n",
       "16737  Squid Game Korean Drama (2021)   \n",
       "16379  Squid Game Korean Drama (2021)   \n",
       "...                               ...   \n",
       "17441  Squid Game Korean Drama (2021)   \n",
       "14452  Squid Game Korean Drama (2021)   \n",
       "7842   Squid Game Korean Drama (2021)   \n",
       "7840   Squid Game Korean Drama (2021)   \n",
       "8490   Squid Game Korean Drama (2021)   \n",
       "\n",
       "                                                 v_title    v_videoId  \\\n",
       "16431  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "16401  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "16407  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "16737  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "16379  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "...                                                  ...          ...   \n",
       "17441                SQUID GAME | SUGAR HONEYCOMBS SCENE  yJ0Pfldt8jw   \n",
       "14452      Red Light Green Light No Blood - Squid Game 1  Ww9HCin8ORs   \n",
       "7842             Squid Game | Official Trailer | Netflix  oqxAJKy0ii4   \n",
       "7840             Squid Game | Official Trailer | Netflix  oqxAJKy0ii4   \n",
       "8490   Red light green light 🤯 the death game ☠️ | Sq...  gibkl8yTBN0   \n",
       "\n",
       "          v_channelTitle         v_publishTime  \\\n",
       "16431  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "16401  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "16407  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "16737  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "16379  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "...                  ...                   ...   \n",
       "17441         memebappe   2021-10-21T10:45:31Z   \n",
       "14452             PopMov  2021-10-06T20:56:52Z   \n",
       "7842             Netflix  2021-09-02T00:00:02Z   \n",
       "7840             Netflix  2021-09-02T00:00:02Z   \n",
       "8490    its Blue Drama 💙  2023-06-30T11:10:13Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "16431  The stars of SQUID GAME are faced with yet ano...   \n",
       "16401  The stars of SQUID GAME are faced with yet ano...   \n",
       "16407  The stars of SQUID GAME are faced with yet ano...   \n",
       "16737  The stars of SQUID GAME are faced with yet ano...   \n",
       "16379  The stars of SQUID GAME are faced with yet ano...   \n",
       "...                                                  ...   \n",
       "17441  BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "14452  I did this for a special person who wanted to ...   \n",
       "7842   A Netflix Series | Squid Game Survive or die W...   \n",
       "7840   A Netflix Series | Squid Game Survive or die W...   \n",
       "8490   Red light green light the death game ☠️ | Squi...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "16431  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "16401  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "16407  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "16737  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "16379  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "...                                               ...   \n",
       "17441  https://i.ytimg.com/vi/yJ0Pfldt8jw/default.jpg   \n",
       "14452  https://i.ytimg.com/vi/Ww9HCin8ORs/default.jpg   \n",
       "7842   https://i.ytimg.com/vi/oqxAJKy0ii4/default.jpg   \n",
       "7840   https://i.ytimg.com/vi/oqxAJKy0ii4/default.jpg   \n",
       "8490   https://i.ytimg.com/vi/gibkl8yTBN0/default.jpg   \n",
       "\n",
       "                             c_id c_parentId            c_author  \\\n",
       "16431  Ugy5u7EHRR6IRod2vxN4AaABAg               MaisieTheUnicorn   \n",
       "16401  UgxlkxXiNXjyjJcOcel4AaABAg                  esophagus3319   \n",
       "16407  Ugy5Vw4Hlzj-ZHpMgjN4AaABAg                       Jk-bp4nu   \n",
       "16737  UgxtKW6yi_uSmDXvAzt4AaABAg                ChristineWang19   \n",
       "16379  UgyMnV8PjtgP5-d2RfF4AaABAg                     brooke4608   \n",
       "...                           ...        ...                 ...   \n",
       "17441  Ugz1oW4SvBYORryAJt94AaABAg                   JayJay-xb3xs   \n",
       "14452  UgxAa4jX2Xmu2s64A1h4AaABAg                  kimsutton4814   \n",
       "7842   UgzLBpLI-3i8k2pOYUd4AaABAg                pauldevaraj4271   \n",
       "7840   UgznDbWb9XHq1mINk3F4AaABAg                   XtraLuminouz   \n",
       "8490   Ugx1mFewZRvAzhSOBfB4AaABAg             veternalsmoves8590   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "16431  2021-09-27T15:53:33Z  2021-09-27T15:53:33Z         33375   \n",
       "16401  2021-09-25T02:58:15Z  2021-09-25T02:58:15Z         21226   \n",
       "16407  2021-09-25T18:37:02Z  2021-09-25T18:37:02Z         17519   \n",
       "16737  2021-09-25T01:02:12Z  2021-09-25T01:52:09Z         14897   \n",
       "16379  2021-10-09T00:22:59Z  2021-10-09T00:22:59Z         14599   \n",
       "...                     ...                   ...           ...   \n",
       "17441  2022-07-20T23:20:51Z  2022-07-20T23:20:51Z             2   \n",
       "14452  2021-10-22T10:34:54Z  2021-10-22T10:34:54Z             2   \n",
       "7842   2021-12-17T03:43:16Z  2021-12-17T03:43:16Z             2   \n",
       "7840   2022-07-30T09:56:53Z  2022-07-30T09:56:53Z             2   \n",
       "8490   2023-10-15T12:46:11Z  2023-10-15T12:46:11Z             2   \n",
       "\n",
       "                                                  c_text  \n",
       "16431               Hoyeon in Squid Game:\\nHoyeon in RL:  \n",
       "16401  the way her real personality is totally differ...  \n",
       "16407  Even if Squid Game was Ho Yeon's first drama, ...  \n",
       "16737  OMG I CLICKED SO FAST!!\\nLITERALLY THIRSTY FOR...  \n",
       "16379  It’s so nice seeing them play a game that won’...  \n",
       "...                                                  ...  \n",
       "17441                          Squid game is so awesome   \n",
       "14452  Poor 118 about to become friends with 456 but ...  \n",
       "7842                  This squid game series was so sick  \n",
       "7840   the fact that this has less views than the vid...  \n",
       "8490   I just played this game in roblox but I closed...  \n",
       "\n",
       "[500 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling comments using Sentiment Lexicon - VADER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lexicon = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(c_text):\n",
    "    sentiment_Score = sentiment_lexicon.polarity_scores(c_text)\n",
    "    return sentiment_Score['compound']\n",
    "\n",
    "def check_sentiment(sentiment_score):\n",
    "    if sentiment_score > 0.00:\n",
    "        return \"Positive\"\n",
    "    elif sentiment_score < 0.00:\n",
    "        return \"Negative\"\n",
    "    elif sentiment_score == 0:\n",
    "        return \"Neutral \"\n",
    "\n",
    "new_df['sentiment_score'] = new_df['c_text'].apply(get_sentiment_score)\n",
    "new_df['sentiment'] = new_df['sentiment_score'].apply(check_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Comments for each polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  Sentiment Score    Comment\n",
      "-----------  -----------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "    -0.0258  Negative           This scene is the perfect introduction to how the games are a matter of life and death. The slow build up, the sudden reveal that the dude was really shot, and the ensuing chaos make this the perfect introduction to these games.\n",
      "    -0.0258  Negative           Lol my two Squid Game crushes, Lee Jung-Jae and Park Hae Soo.\n",
      "    -0.0258  Negative           If player 1 was the boss then who started the game after his death?\n",
      "                                You explanation  is amazing\n",
      "    -0.0258  Negative           *Obviously our hero will play the game again to find out who is behind it after the old man's death and to stop it forever ...*\n",
      "    -0.1027  Negative           Squid game cast and crew working hard for years making season 1\n",
      "\n",
      "                                Us:- Finishing it in 1 day and expecting a season 2 to come soon\n",
      "    -0.1027  Negative           An American squid game with the right Director and cast would go hard\n",
      "    -0.1513  Negative           After watching the whole series I felt really sorry for Ali\n",
      "    -0.1531  Negative           Hunters Should Be Forced To Play Squid Game.\n",
      "    -0.1761  Negative           This game / series is hitting really hard this year shout out to Koreans for making this\n",
      "    -0.188   Negative           when i say the cast of squid game is a walking representation of a “bi panic” .. i’m genuinely so serious.\n",
      "     0       Neutral            Hoyeon in Squid Game:\n",
      "                                Hoyeon in RL:\n",
      "     0       Neutral            i can see blood on the walls when those guys tryna get out of this game\n",
      "     0       Neutral            Squid game season 2 coming soon\n",
      "     0       Neutral            The old man is the one who runs the game\n",
      "     0       Neutral            Squid game changed a lot in 1 year\n",
      "     0       Neutral            I remember the hype of squid game\n",
      "     0       Neutral            This has more views than the actual squid game. Let that sink in.\n",
      "     0       Neutral            Mirip game benteng takeshi \"blueberry hill\"\n",
      "     0       Neutral            Really squid game beginning is red paper blue paper\n",
      "     0       Neutral            Squid game but kids are able to see it (no blood squid game)\n",
      "     0.9878  Positive           After watching Squid Game, Idk how to explain if I like that ending but overall the drama is my type and I'm super in love with this concept survival game. The cast acting were brilliant, the filming set and filmography were excellent. And CAMEO(s), YES chef kiss!\n",
      "     0.9736  Positive           park haesoo is so good at acting that it feels weird seeing his character in squid game and his character in prison playbook  they're completely opposites lol he's awesome and cool i'm so proud of him\n",
      "\n",
      "                                edit: yo thanks for the 1.3k likes everyone! happy that a lot of people shares the same sentiment\n",
      "     0.9726  Positive           Wi Hajoon is finally getting the recognition he deserves  He is such a versatile actor and highly underrated but I'm soo happy to see him being famous from Squid Game. He's done many supporting roles and main roles as well. His recently released thriller movie Midnight is amazing, I hope y'all can watch it.\n",
      "     0.9721  Positive           My cousin has a Roblox and I played squid game it’s very true I swear it’s very true it’s very true OK OK OK OK\n",
      "     0.9681  Positive           I didn’t expect this series to be this good, the acting was so outstanding, Every game every situation I felt so connected to every character. The picture, the colors, the acting…I mean it was just so amazing. And seeing them all together like this is so wholesome, such an awesome cast.\n",
      "     0.9667  Positive           nobody talking about queen kim joo ryoung but she is so humble, so pretty it’s totally different from what you see from her in squid game. what a great actress she deserves everyone’s love.\n",
      "     0.9575  Positive           Thought this was going to be your average survival film I could just have on the in background. What I got was a 9 episode cult classic contender. Extremely well developed characters and some of the best acting I've seen in a long time. For this genre, I was not expecting to hate characters or care for others so deeply.... some scenes really hit deep. Like damn... and that's where the magic lies for Squid Game, this isn't your average Hollywood production where the spectacle is in the plot or overdramatic twists. Here the real entertainment is in watching the host's cynical world view play out on a very human level through the relationships that are created and destroyed between the characters. Make sure you watch it with subtitles, the native acting is too good to substitute.\n",
      "     0.9555  Positive           No but 102 who sacrificed himself for his best friend to continue the game is so kind\n",
      "     0.9543  Positive           I absolutely love Lee Yoomi (she’s so giggly and fun) and HoYeon Jung. Their friendship in and out of Squid Game is so stable- I also love the moment in Squid Game when Ji-yeong dropped her marble..\n",
      "     0.9337  Positive           Just finished this series last end of December and honestly speaking I just watched this trailer when I sent this comment. til now this series still hooked me with superb and excellent story. Kudos to Squid game team\n"
     ]
    }
   ],
   "source": [
    "def select_top_comments(df, top_n=10):\n",
    "    top_comments = []\n",
    "    grouped = df.groupby('sentiment')\n",
    "\n",
    "    # iterate over each polarity group\n",
    "    for sentiment, group in grouped:\n",
    "        # sort comments by sentiment score pick top 10\n",
    "        top_group_comments = group.sort_values(by='sentiment_score', ascending=False).head(top_n)[['sentiment_score', 'sentiment', 'c_text']].values.tolist()\n",
    "        top_comments.extend([(sentiment_score, sentiment, comment) for sentiment_score, sentiment, comment in top_group_comments])\n",
    "\n",
    "    return top_comments\n",
    "\n",
    "top_comments = select_top_comments(new_df, top_n=10)\n",
    "\n",
    "# # top 10 comments for each polarity\n",
    "# for sentiment_score, sentiment, comment in top_comments:\n",
    "#     print(f\"Sentiment: {sentiment}, Sentiment Score: {sentiment_score}, Comment: {comment}\")\n",
    "\n",
    "# making it pretty~~~\n",
    "headers = [\"Sentiment\", \"Sentiment Score\", \"Comment\"]\n",
    "print(tabulate(top_comments, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Lexicon using TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  Sentiment Score    Comment\n",
      "-----------  -----------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "    -0.0258  Negative           This scene is the perfect introduction to how the games are a matter of life and death. The slow build up, the sudden reveal that the dude was really shot, and the ensuing chaos make this the perfect introduction to these games.\n",
      "    -0.0258  Negative           Lol my two Squid Game crushes, Lee Jung-Jae and Park Hae Soo.\n",
      "    -0.0258  Negative           If player 1 was the boss then who started the game after his death?\n",
      "                                You explanation  is amazing\n",
      "    -0.0258  Negative           *Obviously our hero will play the game again to find out who is behind it after the old man's death and to stop it forever ...*\n",
      "    -0.1027  Negative           Squid game cast and crew working hard for years making season 1\n",
      "\n",
      "                                Us:- Finishing it in 1 day and expecting a season 2 to come soon\n",
      "    -0.1027  Negative           An American squid game with the right Director and cast would go hard\n",
      "    -0.1513  Negative           After watching the whole series I felt really sorry for Ali\n",
      "    -0.1531  Negative           Hunters Should Be Forced To Play Squid Game.\n",
      "    -0.1761  Negative           This game / series is hitting really hard this year shout out to Koreans for making this\n",
      "    -0.188   Negative           when i say the cast of squid game is a walking representation of a “bi panic” .. i’m genuinely so serious.\n",
      "     0       Neutral            Hoyeon in Squid Game:\n",
      "                                Hoyeon in RL:\n",
      "     0       Neutral            i can see blood on the walls when those guys tryna get out of this game\n",
      "     0       Neutral            Squid game season 2 coming soon\n",
      "     0       Neutral            The old man is the one who runs the game\n",
      "     0       Neutral            Squid game changed a lot in 1 year\n",
      "     0       Neutral            I remember the hype of squid game\n",
      "     0       Neutral            This has more views than the actual squid game. Let that sink in.\n",
      "     0       Neutral            Mirip game benteng takeshi \"blueberry hill\"\n",
      "     0       Neutral            Really squid game beginning is red paper blue paper\n",
      "     0       Neutral            Squid game but kids are able to see it (no blood squid game)\n",
      "     0.9878  Positive           After watching Squid Game, Idk how to explain if I like that ending but overall the drama is my type and I'm super in love with this concept survival game. The cast acting were brilliant, the filming set and filmography were excellent. And CAMEO(s), YES chef kiss!\n",
      "     0.9736  Positive           park haesoo is so good at acting that it feels weird seeing his character in squid game and his character in prison playbook  they're completely opposites lol he's awesome and cool i'm so proud of him\n",
      "\n",
      "                                edit: yo thanks for the 1.3k likes everyone! happy that a lot of people shares the same sentiment\n",
      "     0.9726  Positive           Wi Hajoon is finally getting the recognition he deserves  He is such a versatile actor and highly underrated but I'm soo happy to see him being famous from Squid Game. He's done many supporting roles and main roles as well. His recently released thriller movie Midnight is amazing, I hope y'all can watch it.\n",
      "     0.9721  Positive           My cousin has a Roblox and I played squid game it’s very true I swear it’s very true it’s very true OK OK OK OK\n",
      "     0.9681  Positive           I didn’t expect this series to be this good, the acting was so outstanding, Every game every situation I felt so connected to every character. The picture, the colors, the acting…I mean it was just so amazing. And seeing them all together like this is so wholesome, such an awesome cast.\n",
      "     0.9667  Positive           nobody talking about queen kim joo ryoung but she is so humble, so pretty it’s totally different from what you see from her in squid game. what a great actress she deserves everyone’s love.\n",
      "     0.9575  Positive           Thought this was going to be your average survival film I could just have on the in background. What I got was a 9 episode cult classic contender. Extremely well developed characters and some of the best acting I've seen in a long time. For this genre, I was not expecting to hate characters or care for others so deeply.... some scenes really hit deep. Like damn... and that's where the magic lies for Squid Game, this isn't your average Hollywood production where the spectacle is in the plot or overdramatic twists. Here the real entertainment is in watching the host's cynical world view play out on a very human level through the relationships that are created and destroyed between the characters. Make sure you watch it with subtitles, the native acting is too good to substitute.\n",
      "     0.9555  Positive           No but 102 who sacrificed himself for his best friend to continue the game is so kind\n",
      "     0.9543  Positive           I absolutely love Lee Yoomi (she’s so giggly and fun) and HoYeon Jung. Their friendship in and out of Squid Game is so stable- I also love the moment in Squid Game when Ji-yeong dropped her marble..\n",
      "     0.9337  Positive           Just finished this series last end of December and honestly speaking I just watched this trailer when I sent this comment. til now this series still hooked me with superb and excellent story. Kudos to Squid game team\n"
     ]
    }
   ],
   "source": [
    "def text_blob_sentiment_score(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def texblob_check_sentiment(score):\n",
    "    if score == 0:\n",
    "        return 'Neutral'\n",
    "    elif score < 0.00:\n",
    "        return 'Negative'\n",
    "    elif score > 0.00:\n",
    "        return 'Positive'\n",
    "\n",
    "new_df['textblob_score'] = new_df['c_text'].apply(text_blob_sentiment_score)\n",
    "new_df['textblob_sentiment'] = new_df['textblob_score'].apply(texblob_check_sentiment)\n",
    "\n",
    "def textblob_select_top_comments(df, top_n=10):\n",
    "    top_comments = []\n",
    "    grouped = df.groupby('textblob_sentiment')\n",
    "\n",
    "    for sentiment, group in grouped:\n",
    "        top_group_comments = group.sort_values(by='textblob_score', ascending=False).head(top_n)[['textblob_score', 'textblob_sentiment', 'c_text']].values.tolist()\n",
    "        top_comments.extend([(sentiment_score, sentiment, comment) for sentiment_score, sentiment, comment in top_group_comments])\n",
    "\n",
    "    return top_comments\n",
    "\n",
    "textblob_top_comments = select_top_comments(new_df, top_n=10)\n",
    "\n",
    "headers = [\"Sentiment\", \"Sentiment Score\", \"Comment\"]\n",
    "print(tabulate(textblob_top_comments, headers=headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16431    None\n",
       "16401    None\n",
       "16407    None\n",
       "16737    None\n",
       "16379    None\n",
       "         ... \n",
       "17441    None\n",
       "14452    None\n",
       "7842     None\n",
       "7840     None\n",
       "8490     None\n",
       "Length: 500, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = ['positive', 'negative', 'neutral']\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def col_to_txt(row):\n",
    "    sentiment = row['sentiment']  \n",
    "    c_text = row['c_text']\n",
    "    file_name = f\"{sentiment}_{row.name}.txt\"  \n",
    "    folder = f\"{sentiment.strip()}\"  \n",
    "    file_path = os.path.join(folder, file_name)\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(c_text)\n",
    "\n",
    "new_df.apply(col_to_txt, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Already Exists. Delete final_comments_df.csv\n"
     ]
    }
   ],
   "source": [
    "filename = 'final_comments_df.csv'\n",
    "files_present = glob.glob(filename)\n",
    "# will only write to disk if file doesnt exist\n",
    "if not files_present:\n",
    "    new_df.to_csv(filename, index=False)\n",
    "    new_df\n",
    "else:\n",
    "    print (f'File Already Exists. Delete {filename}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory containing the positive, negative, and neutral folders\n",
    "root_dir = ''\n",
    "\n",
    "# Define the directories for train and test sets\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "# Define the ratio for train-test split\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Iterate through each sentiment folder\n",
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    # Get the list of file paths in the current sentiment folder\n",
    "    files = os.listdir(os.path.join(root_dir, sentiment))\n",
    "    # Shuffle the file paths\n",
    "    random.shuffle(files)\n",
    "    # Calculate the split index based on the split ratio\n",
    "    split_index = int(len(files) * split_ratio)\n",
    "    # Split the files into train and test sets\n",
    "    train_files = files[:split_index]\n",
    "    test_files = files[split_index:]\n",
    "    \n",
    "    # Move train files to train directory\n",
    "    for file in train_files:\n",
    "        src = os.path.join(root_dir, sentiment, file)\n",
    "        dst = os.path.join(train_dir, sentiment, file)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.move(src, dst)\n",
    "    \n",
    "    # Move test files to test directory\n",
    "    for file in test_files:\n",
    "        src = os.path.join(root_dir, sentiment, file)\n",
    "        dst = os.path.join(test_dir, sentiment, file)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Text Analytics Pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(train_dir)\n",
    "reviews_test = load_files(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Even the camera man is playing squid game ' 2\n",
      "b'question : Do you watch squid game without captions ?' 1\n",
      "b'When were dating, my wife (Seoul native) used to do \"kali-bali-bu\" (rock paper scissors) and the punishment for losing was a slap on the inside soft part of the wrist. However,  you could only use index and middle finger. After a while, it really hurts. This was my first Korean \"Squid Game\".' 0\n"
     ]
    }
   ],
   "source": [
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(text_train[1],y_train[1])\n",
    "print(text_train[2],y_train[2])\n",
    "print(text_train[3],y_train[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<5x5 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect = CountVectorizer().fit(reviews_train)\n",
    "X_train = vect.transform(reviews_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tokens = ['drama', 'film', 'cinema', 'actor', 'actress', 'director', 'plot',\n",
    "                         'scene', 'genre', 'subtitles', 'k-drama', 'kdrama', 'k-movie', 'television',\n",
    "                         'episode', 'screenplay', 'script', 'cinematography', 'soundtrack',\n",
    "                         'OST', 'character', 'plot twist', 'review', 'ratings', 'premiere',\n",
    "                         'streaming', 'watchlist', 'subbed', 'dubbed', 'sequel', 'game', 'song',\n",
    "                         'season', 'trailer', 'casting', 'fanbase', 'recommendation', 'goblin',\n",
    "                         'viewer', 'critic', 'Korean', 'entertainment', 'watched', 'guardian',\n",
    "                         'show', 'squid', 'watch', 'watching', 'acting', 'netflix', 'show',\n",
    "                         'end',\n",
    "                          'squid game', 'gi-hun', 'Sang-woo', 'Player', 'Red light', 'green light', 'Honeycomb',\n",
    "                            'Tug of war', 'Marbles', 'Front man', 'VIPs', 'Doll', 'Coffin', 'Square', 'Triangle', \n",
    "                            'Circle', 'Death game', 'death', 'Survival game', 'Money', 'prize', 'Il-nam', 'Hwang Jun-ho'\n",
    "                            'director', 'Cho Sang-woo', 'Masked man', 'Childhood', 'game', 'Pink soldier', 'Betrayal',\n",
    "                            'Seong Gi-hun', 'Survival', 'Games', 'Competition', 'Squid', 'Masks', 'ali', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # Define the pattern to match punctuation\n",
    "    punctuation_pattern = r'[^\\w\\s]'\n",
    "    # Replace punctuation with an empty string\n",
    "    text_without_punctuation = re.sub(punctuation_pattern, '', text)\n",
    "    return text_without_punctuation\n",
    "\n",
    "# Text Processing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # stopwords punctuation etc\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    # stemmer = PorterStemmer()\n",
    "    # split into tokens\n",
    "    tokens = word_tokenize(text)\n",
    "    # removes stopwords and numbers and stems from tokens makes sure its all lowercase too\n",
    "    tokens = [stemmer.stem(remove_punctuation(token)) for token in tokens if token.isalnum() and token.lower() not in product_tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ishaq\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78        72\n",
      "           1       0.65      0.91      0.76        55\n",
      "           2       0.97      0.84      0.90       259\n",
      "\n",
      "    accuracy                           0.85       386\n",
      "   macro avg       0.78      0.87      0.81       386\n",
      "weighted avg       0.88      0.85      0.86       386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('preprocess', \n",
    "    TfidfVectorizer(\n",
    "                    encoding=\"utf-8\",\n",
    "                    strip_accents='ascii',\n",
    "                    lowercase=True,\n",
    "                    preprocessor=preprocess_text,\n",
    "                    # tokenizer=,\n",
    "                    # analyzer=,\n",
    "                    stop_words='english',\n",
    "                    norm='l2',\n",
    "                    ngram_range=(1, 1),\n",
    "                    max_df=0.09,\n",
    "                    min_df=0.003,\n",
    "                    max_features=500,\n",
    "                    binary=True,\n",
    "                    use_idf=True,\n",
    "                    smooth_idf=True,\n",
    "                    sublinear_tf=True\n",
    "                    )\n",
    "    # CountVectorizer(preprocessor=preprocess_text,ngram_range=(1, 1))\n",
    "     ), \n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "text_clf.fit(text_train, y_train)\n",
    "y_pred = text_clf.predict(text_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ishaq\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 3), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000018FCC736CA0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.93        86\n",
      "           1       0.94      0.88      0.91        77\n",
      "           2       0.94      0.99      0.96       223\n",
      "\n",
      "    accuracy                           0.95       386\n",
      "   macro avg       0.95      0.92      0.93       386\n",
      "weighted avg       0.95      0.95      0.94       386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vectorizer': [TfidfVectorizer()],\n",
    "    'classifier': [\n",
    "        MultinomialNB(),\n",
    "        SVC(),\n",
    "        LogisticRegression()\n",
    "    ],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vectorizer__preprocessor': [preprocess_text],\n",
    "    'vectorizer__encoding': ['utf-8'],\n",
    "    'vectorizer__binary': [False, True],\n",
    "    'vectorizer__lowercase': [False, True],\n",
    "    'vectorizer__encoding': [\"utf-8\"],\n",
    "    'vectorizer__strip_accents': ['ascii'],\n",
    "    'vectorizer__stop_words': ['english'],\n",
    "    'vectorizer__norm': ['l2','l1'],\n",
    "    'vectorizer__max_df': [0.1,0.09,0.08,0.07],\n",
    "    'vectorizer__min_df': [0.004,0.003,0.002],\n",
    "    # 'vectorizer__max_features': [500],\n",
    "    'vectorizer__use_idf': [True,False],\n",
    "    'vectorizer__smooth_idf': [True],\n",
    "    # 'vectorizer__sublinear_tf': [True,False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "grid_search.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(text_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method-wrapper' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m params \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m top_models_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scores)), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m i: scores[i], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_models_indices:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: Mean Test Score - \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, Parameters - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, scores[i], params[i]))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method-wrapper' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "results = grid_search.cv_results_\n",
    " \n",
    "scores = results['mean_test_score']\n",
    "\n",
    "params = results['params']\n",
    "\n",
    "top_models_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:10]\n",
    " \n",
    "for i in top_models_indices:\n",
    "    print(\"Model {}: Mean Test Score - {:.4f}, Parameters - {}\".format(i+1, scores[i], params[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1728"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Visualization and Insights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Discussion and conclusion from experiments:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
