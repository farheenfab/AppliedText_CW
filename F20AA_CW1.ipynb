{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/farheenfab/AppliedText_CW/blob/main/CW1-generate_dataset.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F20AA Coursework 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/fayazbadubhai/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fayazbadubhai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk \n",
    "import os\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from langdetect import detect\n",
    "import shutil\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Collection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the api service name, version and developer key for the api call.\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyAWj_uzrhZL18X32S_P79pT1wnSYGpuA4k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/search/list#parameters\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/comments/list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a class called api_handler which contains functions such as `get_video_details()`, `get_videos()`, `get_video_df()`, `get_comments()`, `get_comment_replies()`, `get_comments_df()`, `create_video_df_from_search()`, `create_video_df()`. These functions help us by either manually retrieving the videos and comments or by automatically curating the videos and comments using the product given to the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class api_handler:\n",
    "    def __init__(self, api_service_name, api_version, developer_key):\n",
    "        self.client = googleapiclient.discovery.build(api_service_name,\n",
    "                                                    api_version,\n",
    "                                                    developerKey=developer_key)\n",
    "        \n",
    "    # Search for videos details given id\n",
    "    def get_video_details(self, videoId, part=\"snippet\"):\n",
    "        request = self.client.videos().list(\n",
    "            part=part,\n",
    "            id=videoId\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        if 'items' in response:\n",
    "            video_details = response['items'][0]\n",
    "            snippet=video_details['snippet']\n",
    "            snippet['videoId']=videoId\n",
    "            snippet['id']=videoId\n",
    "            snippet['publishTime']=video_details.get('snippet', {}).get('publishedAt', {})\n",
    "            snippet['thumbnails']=video_details.get('snippet', {}).get('thumbnails', {}).get('default', {}).get('url', '')\n",
    "            return snippet\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Search for videos given query\n",
    "    def get_videos(self,query,maxResults=5,part=\"snippet\"):\n",
    "        request = self.client.search().list(\n",
    "            part=part,\n",
    "            maxResults=maxResults,\n",
    "            # higher view count is likely to be more relevent \n",
    "            order=\"viewCount\",\n",
    "            q=query,  \n",
    "            # american region videos \n",
    "            regionCode=\"US\",\n",
    "            # english videos\n",
    "            relevanceLanguage=\"en\",\n",
    "            type=\"video\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return response\n",
    "    \n",
    "    # Format Response from get_videos to dataframe\n",
    "    def get_video_df(response):\n",
    "        items=[]\n",
    "        for item in response['items']:\n",
    "            snippet=item.get('snippet', {})\n",
    "            items+=[{\n",
    "                'title':snippet.get('title', ''),\n",
    "                'videoId':item.get('id', {}).get('videoId', ''),\n",
    "                'channelTitle':snippet.get('channelTitle', ''),\n",
    "                'publishTime':snippet.get('publishTime', ''),\n",
    "                'description':snippet.get('description', ''),\n",
    "                'thumbnails':snippet.get('thumbnails', {}).get('default', {}).get('url', '')\n",
    "                }]\n",
    "        df=pd.DataFrame(items)\n",
    "        return df\n",
    "    \n",
    "    # Get comments from video\n",
    "    def get_comments(self,videoId,part=\"snippet\",maxResults=100,maxResultsDepth=100):\n",
    "        all_comments = []\n",
    "        f = 0\n",
    "        nextPageToken = None\n",
    "        while maxResults > 0:\n",
    "            request = self.client.commentThreads().list(\n",
    "                part=part,\n",
    "                videoId=videoId,\n",
    "                maxResults=min(maxResults, 100),\n",
    "                order='relevance',\n",
    "                moderationStatus='published',\n",
    "                textFormat='plainText',\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "            response = request.execute()\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "            if 'items' in response:\n",
    "                all_comments+=[response]\n",
    "                for item in response['items']:\n",
    "                    # extract the comment ID to get replies\n",
    "                    comment_id = item.get('snippet',{}).get('topLevelComment',{}).get('id','')\n",
    "                    if item.get('snippet',{}).get('totalReplyCount',0)>2:\n",
    "                        if f == 0:\n",
    "                            print('getting replies:',item.get('snippet',{}).get('totalReplyCount',0))\n",
    "                            f = 1\n",
    "                        replies = self.get_comment_replies(comment_id, maxResults=maxResultsDepth)\n",
    "                        all_comments += replies\n",
    "\n",
    "            maxResults -= min(maxResults, 100)\n",
    "            if nextPageToken is None:\n",
    "                break;    \n",
    "        return all_comments\n",
    "    \n",
    "    # Get replies from comment \n",
    "    def get_comment_replies(self, commentId, part=\"snippet\", maxResults=100):\n",
    "        all_comments = []\n",
    "        nextPageToken = None\n",
    "        while maxResults > 0 and (nextPageToken != None or len(all_comments)==0):\n",
    "\n",
    "            request = self.client.comments().list(\n",
    "                part=part,\n",
    "                parentId=commentId,\n",
    "                maxResults=min(maxResults, 100),\n",
    "                textFormat='plainText',\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "\n",
    "            response = request.execute()\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "\n",
    "            if 'items' in response and len(response['items'])>0:\n",
    "                for item in response['items']:\n",
    "                    modified_response = {\n",
    "                        'items': [\n",
    "                            {\n",
    "                                'id':item.get('id'),\n",
    "                                'snippet': {\n",
    "                                    'topLevelComment': {\n",
    "                                        'snippet': item.get('snippet','')\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                    all_comments += [modified_response]\n",
    "            maxResults -= min(maxResults, 100)\n",
    "            if nextPageToken is None:\n",
    "                break;    \n",
    "        return all_comments\n",
    "\n",
    "    # Format response from get_comments to dataframe\n",
    "    def get_comments_df(response, video,product):\n",
    "        comments = []\n",
    "        for pages in response:\n",
    "            for item in pages['items']:\n",
    "                comment = item.get('snippet', {}).get('topLevelComment', {}).get('snippet', {})\n",
    "                comments.append([\n",
    "                        product,\n",
    "                        video.get('title', ''),\n",
    "                        video.get('videoId', ''),\n",
    "                        video.get('channelTitle', ''),\n",
    "                        video.get('publishTime', ''),\n",
    "                        video.get('description', ''),\n",
    "                        video.get('thumbnails', ''),\n",
    "                        item.get('id', ''),  \n",
    "                        comment.get('parentId', ''),  \n",
    "                        comment.get('authorDisplayName', '')[1:],  \n",
    "                        comment.get('publishedAt', ''),\n",
    "                        comment.get('updatedAt', ''),\n",
    "                        comment.get('likeCount', ''),\n",
    "                        comment.get('textDisplay', '')\n",
    "                    ])\n",
    "\n",
    "        df = pd.DataFrame(comments,\n",
    "            columns=['product', 'v_title', 'v_videoId',\n",
    "                    'v_channelTitle', 'v_publishTime',\n",
    "                    'v_description', 'v_thumbnail',\n",
    "                    'c_id','c_parentId',\n",
    "                    'c_author', 'c_published_at',\n",
    "                    'c_updated_at', 'c_like_count',\n",
    "                    'c_text'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Search for videos related to products iteratively\n",
    "    # Collect comments from each video and place it into an array\n",
    "    def create_video_df_from_search(self, products,\n",
    "                                    number_of_videos_per_product=5,\n",
    "                                    number_of_comments_per_video=100\n",
    "                                    ,number_of_replies_per_comment=100):\n",
    "        multiple_video_comments = pd.DataFrame()\n",
    "        for product in products:\n",
    "            # get 25 first videos with the highest viewer counts \n",
    "            response = self.get_videos(query=product, maxResults=number_of_videos_per_product)\n",
    "            # Convert results to df\n",
    "            videos_df = api_handler.get_video_df(response)\n",
    "            # For each video get a maximum of 100 comments\n",
    "            # and place comments into an array\n",
    "            for _, video in videos_df.iterrows():\n",
    "                try:\n",
    "                    response = self.get_comments(video['videoId'], maxResults=number_of_comments_per_video,maxResultsDepth=number_of_replies_per_comment)\n",
    "                    comments_df = api_handler.get_comments_df(response, video, product)\n",
    "                except:\n",
    "                    # Function fails as the API returns 403 if the channel has comments disabled\n",
    "                    # place an empty entry instead it can be deleted later\n",
    "                    comments_df = pd.DataFrame(np.zeros((1, 14)),\n",
    "                                                columns=['product', 'v_title', 'v_videoId',\n",
    "                                                        'v_channelTitle', 'v_publishTime',\n",
    "                                                        'v_description', 'v_thumbnail',\n",
    "                                                        'c_id','c_parentId',\n",
    "                                                        'c_author', 'c_published_at',\n",
    "                                                        'c_updated_at', 'c_like_count',\n",
    "                                                        'c_text'])\n",
    "                    print('Unable to retrieve comments:', video.get('title', ''))\n",
    "                multiple_video_comments = pd.concat([multiple_video_comments, comments_df], ignore_index=True)\n",
    "        return multiple_video_comments\n",
    "        \n",
    "    # alternative method by explicitely specifying videos\n",
    "    def create_video_df(self,products,videos,number_of_comments_per_video=100,number_of_replies_per_comment=100):\n",
    "        count=0\n",
    "        multiple_video_comments = pd.DataFrame()\n",
    "        for product in products:\n",
    "            for video in videos[count]:\n",
    "                response = self.get_comments(video,maxResults=number_of_comments_per_video,maxResultsDepth=number_of_replies_per_comment) \n",
    "                video=self.get_video_details(video)\n",
    "                comments_df = api_handler.get_comments_df(response, video, product)\n",
    "                multiple_video_comments = pd.concat([multiple_video_comments, comments_df], ignore_index=True)\n",
    "            count+=1\n",
    "        return multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen the Korean Drama called Squid Game to perform the sentiment analysis on. We specify the product in the products list, create a `api_handler` class object, use the `create_video_df_from_search()` function to automatically curate comments using the YouTube api call, and get a pandas Dataframe in return containing details about the videos and the comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "products=[\"Squid Game Korean Drama (2021)\"]\n",
    "\n",
    "youtube=api_handler(api_service_name, api_version, DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting replies: 750\n",
      "getting replies: 520\n",
      "getting replies: 497\n",
      "getting replies: 5\n",
      "getting replies: 62\n",
      "getting replies: 64\n",
      "getting replies: 129\n",
      "getting replies: 14\n",
      "getting replies: 504\n",
      "getting replies: 101\n",
      "getting replies: 350\n",
      "getting replies: 16\n",
      "getting replies: 5\n",
      "getting replies: 3\n",
      "getting replies: 318\n",
      "getting replies: 25\n",
      "getting replies: 230\n",
      "getting replies: 390\n",
      "getting replies: 7\n",
      "getting replies: 154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzH8vliQSJKHQMGZjx4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>1008162</td>\n",
       "      <td>Like I said in the video, subscribe if you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgwDhFNTCbfck5apuUJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>DoodleChaos</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>514335</td>\n",
       "      <td>Huge props to the set designers, everything wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzVlS_nKI4aXISU_ep4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>mukul_editz</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>317</td>\n",
       "      <td>Your videos are so interesting ‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgxykcUWbPcLhlL-Gy14AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>SpamR1_2013</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>1599</td>\n",
       "      <td>that guy who sacrificed himself on purpose for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>Ugxu5B8dQ9-mZpfW-UV4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-cs9zv3gh1k</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>226</td>\n",
       "      <td>This version of the game is pretty much what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18373</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgzFVtcXyyfUkfC95gd4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ashokkumarreal4003</td>\n",
       "      <td>2021-12-02T12:28:24Z</td>\n",
       "      <td>2021-12-02T12:28:24Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Our indian guy was there Ali üòÅüòÅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>Ugz_eDhu-fp50nhui9Z4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>HoDoBoDo</td>\n",
       "      <td>2021-10-11T06:34:56Z</td>\n",
       "      <td>2021-10-14T17:48:06Z</td>\n",
       "      <td>443</td>\n",
       "      <td>Is nobody seriously gonna talk about how adora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18375</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgwD4FVzsxt_aLH8XXx4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>manoharlal5240</td>\n",
       "      <td>2022-06-07T19:34:39Z</td>\n",
       "      <td>2022-06-07T19:34:47Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Anupam's(Ali) smile ü§£ü§£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18376</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgwnuFDqTEqfWivr1md4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>linraihana8438</td>\n",
       "      <td>2022-01-04T08:30:06Z</td>\n",
       "      <td>2022-01-04T08:30:06Z</td>\n",
       "      <td>1</td>\n",
       "      <td>relly cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18377</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgxvBSfSmPjKpZd6sRJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>itsamadworld2711</td>\n",
       "      <td>2021-10-12T15:35:55Z</td>\n",
       "      <td>2021-10-12T15:35:55Z</td>\n",
       "      <td>324</td>\n",
       "      <td>When she dropped the marble so that Sae-byeok ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18378 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product  \\\n",
       "0      Squid Game Korean Drama (2021)   \n",
       "1      Squid Game Korean Drama (2021)   \n",
       "2      Squid Game Korean Drama (2021)   \n",
       "3      Squid Game Korean Drama (2021)   \n",
       "4      Squid Game Korean Drama (2021)   \n",
       "...                               ...   \n",
       "18373  Squid Game Korean Drama (2021)   \n",
       "18374  Squid Game Korean Drama (2021)   \n",
       "18375  Squid Game Korean Drama (2021)   \n",
       "18376  Squid Game Korean Drama (2021)   \n",
       "18377  Squid Game Korean Drama (2021)   \n",
       "\n",
       "                                                 v_title    v_videoId  \\\n",
       "0                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "1                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "2                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "3                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "4                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "...                                                  ...          ...   \n",
       "18373  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "18374  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "18375  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "18376  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "18377  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "\n",
       "          v_channelTitle         v_publishTime  \\\n",
       "0                MrBeast  2021-11-24T21:00:01Z   \n",
       "1                MrBeast  2021-11-24T21:00:01Z   \n",
       "2                MrBeast  2021-11-24T21:00:01Z   \n",
       "3                MrBeast  2021-11-24T21:00:01Z   \n",
       "4                MrBeast  2021-11-24T21:00:01Z   \n",
       "...                  ...                   ...   \n",
       "18373  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "18374  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "18375  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "18376  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "18377  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "0      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "1      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "2      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "3      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "4      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "...                                                  ...   \n",
       "18373  They may have survived the dalgona challenge i...   \n",
       "18374  They may have survived the dalgona challenge i...   \n",
       "18375  They may have survived the dalgona challenge i...   \n",
       "18376  They may have survived the dalgona challenge i...   \n",
       "18377  They may have survived the dalgona challenge i...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "0      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "1      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "2      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "3      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "4      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "...                                               ...   \n",
       "18373  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "18374  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "18375  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "18376  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "18377  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "\n",
       "                             c_id c_parentId            c_author  \\\n",
       "0      UgzH8vliQSJKHQMGZjx4AaABAg                        MrBeast   \n",
       "1      UgwDhFNTCbfck5apuUJ4AaABAg                    DoodleChaos   \n",
       "2      UgzVlS_nKI4aXISU_ep4AaABAg                    mukul_editz   \n",
       "3      UgxykcUWbPcLhlL-Gy14AaABAg                    SpamR1_2013   \n",
       "4      Ugxu5B8dQ9-mZpfW-UV4AaABAg                user-cs9zv3gh1k   \n",
       "...                           ...        ...                 ...   \n",
       "18373  UgzFVtcXyyfUkfC95gd4AaABAg             ashokkumarreal4003   \n",
       "18374  Ugz_eDhu-fp50nhui9Z4AaABAg                       HoDoBoDo   \n",
       "18375  UgwD4FVzsxt_aLH8XXx4AaABAg                 manoharlal5240   \n",
       "18376  UgwnuFDqTEqfWivr1md4AaABAg                 linraihana8438   \n",
       "18377  UgxvBSfSmPjKpZd6sRJ4AaABAg               itsamadworld2711   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "0      2021-11-24T21:02:45Z  2021-11-24T21:02:45Z       1008162   \n",
       "1      2021-11-24T22:07:54Z  2021-11-24T22:07:54Z        514335   \n",
       "2      2023-12-30T01:55:59Z  2023-12-30T01:55:59Z           317   \n",
       "3      2023-11-27T00:57:21Z  2023-11-27T00:57:21Z          1599   \n",
       "4      2024-01-30T20:17:02Z  2024-01-30T20:17:02Z           226   \n",
       "...                     ...                   ...           ...   \n",
       "18373  2021-12-02T12:28:24Z  2021-12-02T12:28:24Z             0   \n",
       "18374  2021-10-11T06:34:56Z  2021-10-14T17:48:06Z           443   \n",
       "18375  2022-06-07T19:34:39Z  2022-06-07T19:34:47Z             0   \n",
       "18376  2022-01-04T08:30:06Z  2022-01-04T08:30:06Z             1   \n",
       "18377  2021-10-12T15:35:55Z  2021-10-12T15:35:55Z           324   \n",
       "\n",
       "                                                  c_text  \n",
       "0      Like I said in the video, subscribe if you hav...  \n",
       "1      Huge props to the set designers, everything wa...  \n",
       "2                       Your videos are so interesting ‚ù§  \n",
       "3      that guy who sacrificed himself on purpose for...  \n",
       "4      This version of the game is pretty much what t...  \n",
       "...                                                  ...  \n",
       "18373                    Our indian guy was there Ali üòÅüòÅ  \n",
       "18374  Is nobody seriously gonna talk about how adora...  \n",
       "18375                             Anupam's(Ali) smile ü§£ü§£  \n",
       "18376                                         relly cute  \n",
       "18377  When she dropped the marble so that Sae-byeok ...  \n",
       "\n",
       "[18378 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_video_comments=youtube.create_video_df_from_search(products,number_of_videos_per_product=20,number_of_comments_per_video=1000,number_of_replies_per_comment=0)\n",
    "multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Analysis, Selection and Labeling:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from:\n",
    "\n",
    "https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove emojis : As emojis do not provide any helpful information they should be removed from the text strings.\n",
    "def remove_emojis(data):\n",
    "    if isinstance(data, str):\n",
    "        # Remove html tags\n",
    "        data = BeautifulSoup(data, \"html.parser\").get_text()\n",
    "        # Remove emote, etc\n",
    "        emoj = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "                        \"]+\", re.UNICODE)\n",
    "        # english_words = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "\n",
    "        return re.sub(emoj, '', data)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row containing NA values.\n",
    "multiple_video_comments.dropna(subset=['c_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/j8_w4qrs1yg_9xkb16m_16nr0000gp/T/ipykernel_88309/2754946649.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  data = BeautifulSoup(data, \"html.parser\").get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Length Before: 18378\n",
      "DataFrame Length After: 15757\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzH8vliQSJKHQMGZjx4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>1008162</td>\n",
       "      <td>Like I said in the video, subscribe if you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgwDhFNTCbfck5apuUJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>DoodleChaos</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>514335</td>\n",
       "      <td>Huge props to the set designers, everything wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzVlS_nKI4aXISU_ep4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>mukul_editz</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>317</td>\n",
       "      <td>Your videos are so interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgxykcUWbPcLhlL-Gy14AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>SpamR1_2013</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>1599</td>\n",
       "      <td>that guy who sacrificed himself on purpose for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>Ugxu5B8dQ9-mZpfW-UV4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-cs9zv3gh1k</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>226</td>\n",
       "      <td>This version of the game is pretty much what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18373</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgzFVtcXyyfUkfC95gd4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ashokkumarreal4003</td>\n",
       "      <td>2021-12-02T12:28:24Z</td>\n",
       "      <td>2021-12-02T12:28:24Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Our indian guy was there Ali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>Ugz_eDhu-fp50nhui9Z4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>HoDoBoDo</td>\n",
       "      <td>2021-10-11T06:34:56Z</td>\n",
       "      <td>2021-10-14T17:48:06Z</td>\n",
       "      <td>443</td>\n",
       "      <td>Is nobody seriously gonna talk about how adora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18375</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgwD4FVzsxt_aLH8XXx4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>manoharlal5240</td>\n",
       "      <td>2022-06-07T19:34:39Z</td>\n",
       "      <td>2022-06-07T19:34:47Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Anupam's(Ali) smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18376</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgwnuFDqTEqfWivr1md4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>linraihana8438</td>\n",
       "      <td>2022-01-04T08:30:06Z</td>\n",
       "      <td>2022-01-04T08:30:06Z</td>\n",
       "      <td>1</td>\n",
       "      <td>relly cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18377</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgxvBSfSmPjKpZd6sRJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>itsamadworld2711</td>\n",
       "      <td>2021-10-12T15:35:55Z</td>\n",
       "      <td>2021-10-12T15:35:55Z</td>\n",
       "      <td>324</td>\n",
       "      <td>When she dropped the marble so that Sae-byeok ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15757 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product  \\\n",
       "0      Squid Game Korean Drama (2021)   \n",
       "1      Squid Game Korean Drama (2021)   \n",
       "2      Squid Game Korean Drama (2021)   \n",
       "3      Squid Game Korean Drama (2021)   \n",
       "4      Squid Game Korean Drama (2021)   \n",
       "...                               ...   \n",
       "18373  Squid Game Korean Drama (2021)   \n",
       "18374  Squid Game Korean Drama (2021)   \n",
       "18375  Squid Game Korean Drama (2021)   \n",
       "18376  Squid Game Korean Drama (2021)   \n",
       "18377  Squid Game Korean Drama (2021)   \n",
       "\n",
       "                                                 v_title    v_videoId  \\\n",
       "0                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "1                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "2                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "3                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "4                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "...                                                  ...          ...   \n",
       "18373  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "18374  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "18375  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "18376  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "18377  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "\n",
       "          v_channelTitle         v_publishTime  \\\n",
       "0                MrBeast  2021-11-24T21:00:01Z   \n",
       "1                MrBeast  2021-11-24T21:00:01Z   \n",
       "2                MrBeast  2021-11-24T21:00:01Z   \n",
       "3                MrBeast  2021-11-24T21:00:01Z   \n",
       "4                MrBeast  2021-11-24T21:00:01Z   \n",
       "...                  ...                   ...   \n",
       "18373  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "18374  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "18375  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "18376  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "18377  Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "0      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "1      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "2      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "3      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "4      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "...                                                  ...   \n",
       "18373  They may have survived the dalgona challenge i...   \n",
       "18374  They may have survived the dalgona challenge i...   \n",
       "18375  They may have survived the dalgona challenge i...   \n",
       "18376  They may have survived the dalgona challenge i...   \n",
       "18377  They may have survived the dalgona challenge i...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "0      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "1      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "2      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "3      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "4      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "...                                               ...   \n",
       "18373  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "18374  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "18375  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "18376  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "18377  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "\n",
       "                             c_id c_parentId            c_author  \\\n",
       "0      UgzH8vliQSJKHQMGZjx4AaABAg                        MrBeast   \n",
       "1      UgwDhFNTCbfck5apuUJ4AaABAg                    DoodleChaos   \n",
       "2      UgzVlS_nKI4aXISU_ep4AaABAg                    mukul_editz   \n",
       "3      UgxykcUWbPcLhlL-Gy14AaABAg                    SpamR1_2013   \n",
       "4      Ugxu5B8dQ9-mZpfW-UV4AaABAg                user-cs9zv3gh1k   \n",
       "...                           ...        ...                 ...   \n",
       "18373  UgzFVtcXyyfUkfC95gd4AaABAg             ashokkumarreal4003   \n",
       "18374  Ugz_eDhu-fp50nhui9Z4AaABAg                       HoDoBoDo   \n",
       "18375  UgwD4FVzsxt_aLH8XXx4AaABAg                 manoharlal5240   \n",
       "18376  UgwnuFDqTEqfWivr1md4AaABAg                 linraihana8438   \n",
       "18377  UgxvBSfSmPjKpZd6sRJ4AaABAg               itsamadworld2711   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "0      2021-11-24T21:02:45Z  2021-11-24T21:02:45Z       1008162   \n",
       "1      2021-11-24T22:07:54Z  2021-11-24T22:07:54Z        514335   \n",
       "2      2023-12-30T01:55:59Z  2023-12-30T01:55:59Z           317   \n",
       "3      2023-11-27T00:57:21Z  2023-11-27T00:57:21Z          1599   \n",
       "4      2024-01-30T20:17:02Z  2024-01-30T20:17:02Z           226   \n",
       "...                     ...                   ...           ...   \n",
       "18373  2021-12-02T12:28:24Z  2021-12-02T12:28:24Z             0   \n",
       "18374  2021-10-11T06:34:56Z  2021-10-14T17:48:06Z           443   \n",
       "18375  2022-06-07T19:34:39Z  2022-06-07T19:34:47Z             0   \n",
       "18376  2022-01-04T08:30:06Z  2022-01-04T08:30:06Z             1   \n",
       "18377  2021-10-12T15:35:55Z  2021-10-12T15:35:55Z           324   \n",
       "\n",
       "                                                  c_text  \n",
       "0      Like I said in the video, subscribe if you hav...  \n",
       "1      Huge props to the set designers, everything wa...  \n",
       "2                        Your videos are so interesting   \n",
       "3      that guy who sacrificed himself on purpose for...  \n",
       "4      This version of the game is pretty much what t...  \n",
       "...                                                  ...  \n",
       "18373                      Our indian guy was there Ali   \n",
       "18374  Is nobody seriously gonna talk about how adora...  \n",
       "18375                               Anupam's(Ali) smile   \n",
       "18376                                         relly cute  \n",
       "18377  When she dropped the marble so that Sae-byeok ...  \n",
       "\n",
       "[15757 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove emojis from the text to be analyzed\n",
    "multiple_video_comments['c_text']=multiple_video_comments['c_text'].apply(remove_emojis)\n",
    "\n",
    "df_length_before = len(multiple_video_comments)\n",
    "print(\"DataFrame Length Before:\", df_length_before)\n",
    "\n",
    "# Drop duplicates\n",
    "multiple_video_comments.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop rows with empty or text length <= 2 comments\n",
    "multiple_video_comments = multiple_video_comments[multiple_video_comments['c_text'].apply(lambda x: len(x) > 2)]\n",
    "\n",
    "df_length_after = len(multiple_video_comments)\n",
    "print(\"DataFrame Length After:\", df_length_after)\n",
    "\n",
    "multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://stackoverflow.com/questions/40375366/pandas-to-csv-checking-for-overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing:\n",
    "    def __init__(self):\n",
    "        # Define keywords related to the TV show\n",
    "        self.tv_show_keywords = ['Squid Game', 'Gi-hun', 'Sang-woo', 'Player', 'Red light, green light', 'Honeycomb',\n",
    "                            'Tug of war', 'Marbles', 'Front man', 'VIPs', 'Doll', 'Coffin', 'Square', 'Triangle', \n",
    "                            'Circle', 'Death game', 'death', 'Survival game', 'Money', 'prize', 'Il-nam', 'Hwang Jun-ho'\n",
    "                            'director', 'Cho Sang-woo', 'Masked man', 'Childhood', 'game', 'Pink soldier', 'Betrayal',\n",
    "                            'Seong Gi-hun', 'Survival', 'Games', 'Competition', 'Squid', 'Masks', 'ali', ]\n",
    "        # Setting threshold value for validating the relevance of the comment\n",
    "        self.threshold = 1\n",
    "\n",
    "    # Tokenize text and remove stop words\n",
    "    def preprocess_text(self, text):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "        return filtered_tokens\n",
    "\n",
    "    # Matching function to check relevance of the comments\n",
    "    def match_keywords(self, tokens):\n",
    "        return [token for token in tokens if token in self.tv_show_keywords]\n",
    "\n",
    "    # Scoring function to calculate how many tokens matched\n",
    "    def calculate_score(self, tokens):\n",
    "        return len(tokens)\n",
    "\n",
    "    # Validate function to validate the relevance based on threshold\n",
    "    def validate_relevance(self, score):\n",
    "        return score >= self.threshold\n",
    "\n",
    "    def filter_comments(self, df):\n",
    "        c = 0\n",
    "        comments = []\n",
    "        irrelevant_keywords = ['HYVE', 'crypto', 'promotion', 'ad', 'spam', 'advertisement', 'spoiler', 'leak', 'promo', 'off-topic', 'clickbait',\n",
    "                            'self-promotion', '0:', '1:', '2:', '3:', '4:', '5:', '6:', '7:',\n",
    "                            '8:', '9:', '10:', '11:', '12:', '13:', '14:', '15:']\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                if detect(row['c_text']) == 'en' and not any(keyword in row['c_text'] for keyword in irrelevant_keywords):\n",
    "                    comments.append(row)\n",
    "                    c += 1\n",
    "            except Exception as e:  # Catch any exception\n",
    "                pass\n",
    "        print(\"Number of Filtered Comments: \", c)\n",
    "        new_df = pd.DataFrame(comments, \n",
    "                    columns=['product', 'v_title', 'v_videoId',\n",
    "                        'v_channelTitle', 'v_publishTime',\n",
    "                        'v_description', 'v_thumbnail',\n",
    "                        'c_id','c_parentId',\n",
    "                        'c_author', 'c_published_at',\n",
    "                        'c_updated_at', 'c_like_count',\n",
    "                        'c_text'])  # Create a new DataFrame from the list of rows\n",
    "        new_df = new_df.sort_values(by = ['c_like_count'], ascending = False)\n",
    "        new_df.drop_duplicates(inplace=True)\n",
    "        new_df = new_df[:500]\n",
    "        return new_df\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        c = 0\n",
    "        comments = []\n",
    "        for index, row in df.iterrows():\n",
    "            processed_text = self.preprocess_text(row['c_text'])\n",
    "            matched_keywords = self.match_keywords(processed_text)\n",
    "            score = self.calculate_score(matched_keywords)\n",
    "            is_relevant = self.validate_relevance(score)\n",
    "            if is_relevant == 1:\n",
    "                comments.append(row)\n",
    "                c += 1\n",
    "\n",
    "        new_df = pd.DataFrame(comments, \n",
    "                    columns=['product', 'v_title', 'v_videoId',\n",
    "                        'v_channelTitle', 'v_publishTime',\n",
    "                        'v_description', 'v_thumbnail',\n",
    "                        'c_id','c_parentId',\n",
    "                        'c_author', 'c_published_at',\n",
    "                        'c_updated_at', 'c_like_count',\n",
    "                        'c_text'])\n",
    "        print(\"Number of Processed Comments: \", c)\n",
    "        new_df = self.filter_comments(new_df)\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Processed Comments:  1791\n",
      "Number of Filtered Comments:  1107\n"
     ]
    }
   ],
   "source": [
    "p = preprocessing()\n",
    "new_df = p.preprocess(multiple_video_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game (Behind The Scenes) #Shorts</td>\n",
       "      <td>4vb085gEgPc</td>\n",
       "      <td>Behind The Scenes</td>\n",
       "      <td>2022-03-20T16:43:54Z</td>\n",
       "      <td>This video gives you a chance to look BEHIND T...</td>\n",
       "      <td>https://i.ytimg.com/vi/4vb085gEgPc/default.jpg</td>\n",
       "      <td>UgxEeZvLDwVE2jcneuJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>_Taylo_</td>\n",
       "      <td>2022-06-09T00:13:48Z</td>\n",
       "      <td>2022-06-09T00:13:48Z</td>\n",
       "      <td>10273</td>\n",
       "      <td>Oh so the camera-man plays squid game too?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAME | RED LIGHT GREEN LIGHT SCENE</td>\n",
       "      <td>sH4Y450PSVM</td>\n",
       "      <td>memebappe</td>\n",
       "      <td>2021-10-14T18:52:37Z</td>\n",
       "      <td>BUY THE PERFECT CHRISTMAS GIFT    : https://am...</td>\n",
       "      <td>https://i.ytimg.com/vi/sH4Y450PSVM/default.jpg</td>\n",
       "      <td>UgyXDA0Vdld5b5SMG2Z4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>silver-eyedfox7713</td>\n",
       "      <td>2022-01-16T01:30:47Z</td>\n",
       "      <td>2022-01-16T01:30:47Z</td>\n",
       "      <td>8209</td>\n",
       "      <td>This scene is the perfect introduction to how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17479</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgyBW8hKpZ3Tcxf0rJt4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>jeng6786</td>\n",
       "      <td>2021-10-12T02:08:48Z</td>\n",
       "      <td>2021-10-12T02:08:48Z</td>\n",
       "      <td>6886</td>\n",
       "      <td>Most memorable character : Ali. The marble sce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>Ugzvskgmdrku401Z3hF4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ballinklong</td>\n",
       "      <td>2021-10-11T14:38:58Z</td>\n",
       "      <td>2021-10-11T14:38:58Z</td>\n",
       "      <td>6671</td>\n",
       "      <td>You realize Ali's personality is the only one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17497</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>Ugwyddf9lv0uoE5z15t4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>LittleCart</td>\n",
       "      <td>2021-10-12T11:58:45Z</td>\n",
       "      <td>2021-10-12T11:58:45Z</td>\n",
       "      <td>6274</td>\n",
       "      <td>Considering how popular Squid Game got, it's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8334</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>SQUID GAMES In Real Life | KAYCEE &amp;amp; RACHEL...</td>\n",
       "      <td>gVQ-3luYckY</td>\n",
       "      <td>KAYCEE &amp; RACHEL in WONDERLAND FAMILY</td>\n",
       "      <td>2021-12-05T10:00:31Z</td>\n",
       "      <td>SQUID GAMES In Real Life with the WONDERLAND F...</td>\n",
       "      <td>https://i.ytimg.com/vi/gVQ-3luYckY/default.jpg</td>\n",
       "      <td>Ugw54W4XX6KJQrO2ZiJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>soup8322</td>\n",
       "      <td>2022-01-13T12:11:07Z</td>\n",
       "      <td>2022-01-13T12:11:07Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Rachel dressing up as the Squid Game doll is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Sugar Honeycomb No Blood - Squid Game 2</td>\n",
       "      <td>qE3TiUVd1Qc</td>\n",
       "      <td>PopMov</td>\n",
       "      <td>2021-10-07T18:44:36Z</td>\n",
       "      <td>Dont miss our new FRONTMAN song! See the music...</td>\n",
       "      <td>https://i.ytimg.com/vi/qE3TiUVd1Qc/default.jpg</td>\n",
       "      <td>Ugz2K8o12k26_csGpZl4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>aaravmishra3238</td>\n",
       "      <td>2021-11-05T11:09:05Z</td>\n",
       "      <td>2021-11-05T11:09:05Z</td>\n",
       "      <td>2</td>\n",
       "      <td>SPOILER!!!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17109</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Red Light Green Light No Blood - Squid Game 1</td>\n",
       "      <td>Ww9HCin8ORs</td>\n",
       "      <td>PopMov</td>\n",
       "      <td>2021-10-06T20:56:52Z</td>\n",
       "      <td>I did this for a special person who wanted to ...</td>\n",
       "      <td>https://i.ytimg.com/vi/Ww9HCin8ORs/default.jpg</td>\n",
       "      <td>UgwFnHY3AISE6BWNAG94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>therealprotosplaat319</td>\n",
       "      <td>2021-12-02T21:08:49Z</td>\n",
       "      <td>2021-12-02T21:08:49Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Squid game finally has no blood finally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game stars take on the Dalgona Challenge...</td>\n",
       "      <td>TYd_pT9hZrM</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-10-09T09:00:10Z</td>\n",
       "      <td>They may have survived the dalgona challenge i...</td>\n",
       "      <td>https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg</td>\n",
       "      <td>UgxBOCMyahbYTMZYdf94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>dawntotanes786</td>\n",
       "      <td>2022-06-24T15:02:10Z</td>\n",
       "      <td>2022-06-24T15:02:50Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Ali's Smile Tho For The Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14265</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Sugar Honeycomb No Blood - Squid Game 2</td>\n",
       "      <td>qE3TiUVd1Qc</td>\n",
       "      <td>PopMov</td>\n",
       "      <td>2021-10-07T18:44:36Z</td>\n",
       "      <td>Dont miss our new FRONTMAN song! See the music...</td>\n",
       "      <td>https://i.ytimg.com/vi/qE3TiUVd1Qc/default.jpg</td>\n",
       "      <td>UgzjAWVlGD17b-3cpuR4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>Your._.Sea.Tsireya</td>\n",
       "      <td>2021-11-08T13:43:24Z</td>\n",
       "      <td>2021-11-08T13:43:24Z</td>\n",
       "      <td>1</td>\n",
       "      <td>I know how to win if i am in squid game i will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product  \\\n",
       "4998   Squid Game Korean Drama (2021)   \n",
       "3995   Squid Game Korean Drama (2021)   \n",
       "17479  Squid Game Korean Drama (2021)   \n",
       "17437  Squid Game Korean Drama (2021)   \n",
       "17497  Squid Game Korean Drama (2021)   \n",
       "...                               ...   \n",
       "8334   Squid Game Korean Drama (2021)   \n",
       "14354  Squid Game Korean Drama (2021)   \n",
       "17109  Squid Game Korean Drama (2021)   \n",
       "17734  Squid Game Korean Drama (2021)   \n",
       "14265  Squid Game Korean Drama (2021)   \n",
       "\n",
       "                                                 v_title    v_videoId  \\\n",
       "4998              Squid Game (Behind The Scenes) #Shorts  4vb085gEgPc   \n",
       "3995            SQUID GAME | RED LIGHT GREEN LIGHT SCENE  sH4Y450PSVM   \n",
       "17479  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "17437  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "17497  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "...                                                  ...          ...   \n",
       "8334   SQUID GAMES In Real Life | KAYCEE &amp; RACHEL...  gVQ-3luYckY   \n",
       "14354            Sugar Honeycomb No Blood - Squid Game 2  qE3TiUVd1Qc   \n",
       "17109      Red Light Green Light No Blood - Squid Game 1  Ww9HCin8ORs   \n",
       "17734  Squid Game stars take on the Dalgona Challenge...  TYd_pT9hZrM   \n",
       "14265            Sugar Honeycomb No Blood - Squid Game 2  qE3TiUVd1Qc   \n",
       "\n",
       "                             v_channelTitle         v_publishTime  \\\n",
       "4998                      Behind The Scenes  2022-03-20T16:43:54Z   \n",
       "3995                             memebappe   2021-10-14T18:52:37Z   \n",
       "17479                     Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "17437                     Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "17497                     Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "...                                     ...                   ...   \n",
       "8334   KAYCEE & RACHEL in WONDERLAND FAMILY  2021-12-05T10:00:31Z   \n",
       "14354                                PopMov  2021-10-07T18:44:36Z   \n",
       "17109                                PopMov  2021-10-06T20:56:52Z   \n",
       "17734                     Netflix K-Content  2021-10-09T09:00:10Z   \n",
       "14265                                PopMov  2021-10-07T18:44:36Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "4998   This video gives you a chance to look BEHIND T...   \n",
       "3995   BUY THE PERFECT CHRISTMAS GIFT    : https://am...   \n",
       "17479  They may have survived the dalgona challenge i...   \n",
       "17437  They may have survived the dalgona challenge i...   \n",
       "17497  They may have survived the dalgona challenge i...   \n",
       "...                                                  ...   \n",
       "8334   SQUID GAMES In Real Life with the WONDERLAND F...   \n",
       "14354  Dont miss our new FRONTMAN song! See the music...   \n",
       "17109  I did this for a special person who wanted to ...   \n",
       "17734  They may have survived the dalgona challenge i...   \n",
       "14265  Dont miss our new FRONTMAN song! See the music...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "4998   https://i.ytimg.com/vi/4vb085gEgPc/default.jpg   \n",
       "3995   https://i.ytimg.com/vi/sH4Y450PSVM/default.jpg   \n",
       "17479  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "17437  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "17497  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "...                                               ...   \n",
       "8334   https://i.ytimg.com/vi/gVQ-3luYckY/default.jpg   \n",
       "14354  https://i.ytimg.com/vi/qE3TiUVd1Qc/default.jpg   \n",
       "17109  https://i.ytimg.com/vi/Ww9HCin8ORs/default.jpg   \n",
       "17734  https://i.ytimg.com/vi/TYd_pT9hZrM/default.jpg   \n",
       "14265  https://i.ytimg.com/vi/qE3TiUVd1Qc/default.jpg   \n",
       "\n",
       "                             c_id c_parentId               c_author  \\\n",
       "4998   UgxEeZvLDwVE2jcneuJ4AaABAg                           _Taylo_   \n",
       "3995   UgyXDA0Vdld5b5SMG2Z4AaABAg                silver-eyedfox7713   \n",
       "17479  UgyBW8hKpZ3Tcxf0rJt4AaABAg                          jeng6786   \n",
       "17437  Ugzvskgmdrku401Z3hF4AaABAg                       ballinklong   \n",
       "17497  Ugwyddf9lv0uoE5z15t4AaABAg                        LittleCart   \n",
       "...                           ...        ...                    ...   \n",
       "8334   Ugw54W4XX6KJQrO2ZiJ4AaABAg                          soup8322   \n",
       "14354  Ugz2K8o12k26_csGpZl4AaABAg                   aaravmishra3238   \n",
       "17109  UgwFnHY3AISE6BWNAG94AaABAg             therealprotosplaat319   \n",
       "17734  UgxBOCMyahbYTMZYdf94AaABAg                    dawntotanes786   \n",
       "14265  UgzjAWVlGD17b-3cpuR4AaABAg                Your._.Sea.Tsireya   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "4998   2022-06-09T00:13:48Z  2022-06-09T00:13:48Z         10273   \n",
       "3995   2022-01-16T01:30:47Z  2022-01-16T01:30:47Z          8209   \n",
       "17479  2021-10-12T02:08:48Z  2021-10-12T02:08:48Z          6886   \n",
       "17437  2021-10-11T14:38:58Z  2021-10-11T14:38:58Z          6671   \n",
       "17497  2021-10-12T11:58:45Z  2021-10-12T11:58:45Z          6274   \n",
       "...                     ...                   ...           ...   \n",
       "8334   2022-01-13T12:11:07Z  2022-01-13T12:11:07Z             2   \n",
       "14354  2021-11-05T11:09:05Z  2021-11-05T11:09:05Z             2   \n",
       "17109  2021-12-02T21:08:49Z  2021-12-02T21:08:49Z             2   \n",
       "17734  2022-06-24T15:02:10Z  2022-06-24T15:02:50Z             1   \n",
       "14265  2021-11-08T13:43:24Z  2021-11-08T13:43:24Z             1   \n",
       "\n",
       "                                                  c_text  \n",
       "4998          Oh so the camera-man plays squid game too?  \n",
       "3995   This scene is the perfect introduction to how ...  \n",
       "17479  Most memorable character : Ali. The marble sce...  \n",
       "17437  You realize Ali's personality is the only one ...  \n",
       "17497  Considering how popular Squid Game got, it's s...  \n",
       "...                                                  ...  \n",
       "8334   Rachel dressing up as the Squid Game doll is s...  \n",
       "14354  SPOILER!!!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  \n",
       "17109            Squid game finally has no blood finally  \n",
       "17734                   Ali's Smile Tho For The Picture   \n",
       "14265  I know how to win if i am in squid game i will...  \n",
       "\n",
       "[500 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling comments using Sentiment Lexicon - VADER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lexicon = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(c_text):\n",
    "    sentiment_Score = sentiment_lexicon.polarity_scores(c_text)\n",
    "    return sentiment_Score['compound']\n",
    "\n",
    "def check_sentiment(sentiment_score):\n",
    "    if sentiment_score > 0.00:\n",
    "        return \"Positive\"\n",
    "    elif sentiment_score < 0.00:\n",
    "        return \"Negative\"\n",
    "    elif sentiment_score == 0:\n",
    "        return \"Neutral \"\n",
    "\n",
    "new_df['sentiment_score'] = new_df['c_text'].apply(get_sentiment_score)\n",
    "new_df['sentiment'] = new_df['sentiment_score'].apply(check_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Comments for each polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  Sentiment Score    Comment\n",
      "-----------  -----------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "    -0.0258  Negative           This scene is the perfect introduction to how the games are a matter of life and death. The slow build up, the sudden reveal that the dude was really shot, and the ensuing chaos make this the perfect introduction to these games.\n",
      "    -0.0258  Negative           *Obviously our hero will play the game again to find out who is behind it after the old man's death and to stop it forever ...*\n",
      "    -0.0258  Negative           If player 1 was the boss then who started the game after his death?\n",
      "                                You explanation  is amazing\n",
      "    -0.0772  Negative           ugh ali‚Äôs actor is exactly like him in the show\n",
      "    -0.1027  Negative           Squid game cast and crew working hard for years making season 1\n",
      "\n",
      "                                Us:- Finishing it in 1 day and expecting a season 2 to come soon\n",
      "    -0.1027  Negative           An American squid game with the right Director and cast would go hard\n",
      "    -0.1513  Negative           After watching the whole series I felt really sorry for Ali\n",
      "    -0.1531  Negative           Hunters Should Be Forced To Play Squid Game.\n",
      "    -0.1531  Negative           Came here cuz I miss Ali Abdul and that old man.\n",
      "    -0.1761  Negative           This game / series is hitting really hard this year shout out to Koreans for making this\n",
      "     0       Neutral            Dalgona candy makers after squid game: \"Business is Boomin\"\n",
      "     0       Neutral            Man he turned Squid Game into a real life One Piece, what a legend!\n",
      "     0       Neutral            What about the cookie game?\n",
      "     0       Neutral            I remember the hype of squid game\n",
      "     0       Neutral            Japan : Alice in Borderland\n",
      "                                Korea : Squid Game\n",
      "                                China : ????\n",
      "     0       Neutral            Squid game changed a lot in 1 year\n",
      "     0       Neutral            This has more views than the actual squid game. Let that sink in.\n",
      "     0       Neutral            Squid game slowly becomes nostalgic\n",
      "     0       Neutral            Really squid game beginning is red paper blue paper\n",
      "     0       Neutral            Mirip game benteng takeshi \"blueberry hill\"\n",
      "     0.9721  Positive           My cousin has a Roblox and I played squid game it‚Äôs very true I swear it‚Äôs very true it‚Äôs very true OK OK OK OK\n",
      "     0.9667  Positive           nobody talking about queen kim joo ryoung but she is so humble, so pretty it‚Äôs totally different from what you see from her in squid game. what a great actress she deserves everyone‚Äôs love.\n",
      "     0.9611  Positive           Hi Kaycee, the squid game was really fun, good to see you with your family and friends, thanks a lot for bringing smile in my life, lots of love from kshirja kharvi\n",
      "     0.9575  Positive           Thought this was going to be your average survival film I could just have on the in background. What I got was a 9 episode cult classic contender. Extremely well developed characters and some of the best acting I've seen in a long time. For this genre, I was not expecting to hate characters or care for others so deeply.... some scenes really hit deep. Like damn... and that's where the magic lies for Squid Game, this isn't your average Hollywood production where the spectacle is in the plot or overdramatic twists. Here the real entertainment is in watching the host's cynical world view play out on a very human level through the relationships that are created and destroyed between the characters. Make sure you watch it with subtitles, the native acting is too good to substitute.\n",
      "     0.9555  Positive           No but 102 who sacrificed himself for his best friend to continue the game is so kind\n",
      "     0.9543  Positive           I absolutely love Lee Yoomi (she‚Äôs so giggly and fun) and HoYeon Jung. Their friendship in and out of Squid Game is so stable- I also love the moment in Squid Game when Ji-yeong dropped her marble..\n",
      "     0.9337  Positive           Just finished this series last end of December and honestly speaking I just watched this trailer when I sent this comment. til now this series still hooked me with superb and excellent story. Kudos to Squid game team\n",
      "     0.9329  Positive           Well done!!!!\n",
      "                                I was literally waiting and wishing that you should post the explanation of squid game it's a bit emotional but so much interesting  please keep make these type of movie's explanation thank you\n",
      "     0.9324  Positive           The set looked amazing and that glass game looked as tense as I could ever\n",
      "                                imagine. Awesome job MrBeast. Congrats to the winner!\n",
      "     0.9323  Positive           Hi all, I just want to point out that a lot of the scenes in this concept teaser came from a Chinese survival/action film called \"Animal World\"(Dong Wu Shi Jie), with Yifeng Li and Michael Douglas. In a similar style as the Squid Game but with crazier visuals. As a Squid Game fan myself, I think you should enjoy that film too! Anyone that sees this comment, have a great day!\n"
     ]
    }
   ],
   "source": [
    "def select_top_comments(df, top_n=10):\n",
    "    top_comments = []\n",
    "    grouped = df.groupby('sentiment')\n",
    "\n",
    "    # iterate over each polarity group\n",
    "    for sentiment, group in grouped:\n",
    "        # sort comments by sentiment score pick top 10\n",
    "        top_group_comments = group.sort_values(by='sentiment_score', ascending=False).head(top_n)[['sentiment_score', 'sentiment', 'c_text']].values.tolist()\n",
    "        top_comments.extend([(sentiment_score, sentiment, comment) for sentiment_score, sentiment, comment in top_group_comments])\n",
    "\n",
    "    return top_comments\n",
    "\n",
    "top_comments = select_top_comments(new_df, top_n=10)\n",
    "\n",
    "# # top 10 comments for each polarity\n",
    "# for sentiment_score, sentiment, comment in top_comments:\n",
    "#     print(f\"Sentiment: {sentiment}, Sentiment Score: {sentiment_score}, Comment: {comment}\")\n",
    "\n",
    "# making it pretty~~~\n",
    "headers = [\"Sentiment\", \"Sentiment Score\", \"Comment\"]\n",
    "print(tabulate(top_comments, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Lexicon using TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  Sentiment Score    Comment\n",
      "-----------  -----------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "    -0.0258  Negative           This scene is the perfect introduction to how the games are a matter of life and death. The slow build up, the sudden reveal that the dude was really shot, and the ensuing chaos make this the perfect introduction to these games.\n",
      "    -0.0258  Negative           *Obviously our hero will play the game again to find out who is behind it after the old man's death and to stop it forever ...*\n",
      "    -0.0258  Negative           If player 1 was the boss then who started the game after his death?\n",
      "                                You explanation  is amazing\n",
      "    -0.0772  Negative           ugh ali‚Äôs actor is exactly like him in the show\n",
      "    -0.1027  Negative           Squid game cast and crew working hard for years making season 1\n",
      "\n",
      "                                Us:- Finishing it in 1 day and expecting a season 2 to come soon\n",
      "    -0.1027  Negative           An American squid game with the right Director and cast would go hard\n",
      "    -0.1513  Negative           After watching the whole series I felt really sorry for Ali\n",
      "    -0.1531  Negative           Hunters Should Be Forced To Play Squid Game.\n",
      "    -0.1531  Negative           Came here cuz I miss Ali Abdul and that old man.\n",
      "    -0.1761  Negative           This game / series is hitting really hard this year shout out to Koreans for making this\n",
      "     0       Neutral            Dalgona candy makers after squid game: \"Business is Boomin\"\n",
      "     0       Neutral            Man he turned Squid Game into a real life One Piece, what a legend!\n",
      "     0       Neutral            What about the cookie game?\n",
      "     0       Neutral            I remember the hype of squid game\n",
      "     0       Neutral            Japan : Alice in Borderland\n",
      "                                Korea : Squid Game\n",
      "                                China : ????\n",
      "     0       Neutral            Squid game changed a lot in 1 year\n",
      "     0       Neutral            This has more views than the actual squid game. Let that sink in.\n",
      "     0       Neutral            Squid game slowly becomes nostalgic\n",
      "     0       Neutral            Really squid game beginning is red paper blue paper\n",
      "     0       Neutral            Mirip game benteng takeshi \"blueberry hill\"\n",
      "     0.9721  Positive           My cousin has a Roblox and I played squid game it‚Äôs very true I swear it‚Äôs very true it‚Äôs very true OK OK OK OK\n",
      "     0.9667  Positive           nobody talking about queen kim joo ryoung but she is so humble, so pretty it‚Äôs totally different from what you see from her in squid game. what a great actress she deserves everyone‚Äôs love.\n",
      "     0.9611  Positive           Hi Kaycee, the squid game was really fun, good to see you with your family and friends, thanks a lot for bringing smile in my life, lots of love from kshirja kharvi\n",
      "     0.9575  Positive           Thought this was going to be your average survival film I could just have on the in background. What I got was a 9 episode cult classic contender. Extremely well developed characters and some of the best acting I've seen in a long time. For this genre, I was not expecting to hate characters or care for others so deeply.... some scenes really hit deep. Like damn... and that's where the magic lies for Squid Game, this isn't your average Hollywood production where the spectacle is in the plot or overdramatic twists. Here the real entertainment is in watching the host's cynical world view play out on a very human level through the relationships that are created and destroyed between the characters. Make sure you watch it with subtitles, the native acting is too good to substitute.\n",
      "     0.9555  Positive           No but 102 who sacrificed himself for his best friend to continue the game is so kind\n",
      "     0.9543  Positive           I absolutely love Lee Yoomi (she‚Äôs so giggly and fun) and HoYeon Jung. Their friendship in and out of Squid Game is so stable- I also love the moment in Squid Game when Ji-yeong dropped her marble..\n",
      "     0.9337  Positive           Just finished this series last end of December and honestly speaking I just watched this trailer when I sent this comment. til now this series still hooked me with superb and excellent story. Kudos to Squid game team\n",
      "     0.9329  Positive           Well done!!!!\n",
      "                                I was literally waiting and wishing that you should post the explanation of squid game it's a bit emotional but so much interesting  please keep make these type of movie's explanation thank you\n",
      "     0.9324  Positive           The set looked amazing and that glass game looked as tense as I could ever\n",
      "                                imagine. Awesome job MrBeast. Congrats to the winner!\n",
      "     0.9323  Positive           Hi all, I just want to point out that a lot of the scenes in this concept teaser came from a Chinese survival/action film called \"Animal World\"(Dong Wu Shi Jie), with Yifeng Li and Michael Douglas. In a similar style as the Squid Game but with crazier visuals. As a Squid Game fan myself, I think you should enjoy that film too! Anyone that sees this comment, have a great day!\n"
     ]
    }
   ],
   "source": [
    "def text_blob_sentiment_score(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def texblob_check_sentiment(score):\n",
    "    if score == 0:\n",
    "        return 'Neutral'\n",
    "    elif score < 0.00:\n",
    "        return 'Negative'\n",
    "    elif score > 0.00:\n",
    "        return 'Positive'\n",
    "\n",
    "new_df['textblob_score'] = new_df['c_text'].apply(text_blob_sentiment_score)\n",
    "new_df['textblob_sentiment'] = new_df['textblob_score'].apply(texblob_check_sentiment)\n",
    "\n",
    "def textblob_select_top_comments(df, top_n=10):\n",
    "    top_comments = []\n",
    "    grouped = df.groupby('textblob_sentiment')\n",
    "\n",
    "    for sentiment, group in grouped:\n",
    "        top_group_comments = group.sort_values(by='textblob_score', ascending=False).head(top_n)[['textblob_score', 'textblob_sentiment', 'c_text']].values.tolist()\n",
    "        top_comments.extend([(sentiment_score, sentiment, comment) for sentiment_score, sentiment, comment in top_group_comments])\n",
    "\n",
    "    return top_comments\n",
    "\n",
    "textblob_top_comments = select_top_comments(new_df, top_n=10)\n",
    "\n",
    "headers = [\"Sentiment\", \"Sentiment Score\", \"Comment\"]\n",
    "print(tabulate(textblob_top_comments, headers=headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998     None\n",
       "3995     None\n",
       "17479    None\n",
       "17437    None\n",
       "17497    None\n",
       "         ... \n",
       "8334     None\n",
       "14354    None\n",
       "17109    None\n",
       "17734    None\n",
       "14265    None\n",
       "Length: 500, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = ['positive', 'negative', 'neutral']\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def col_to_txt(row):\n",
    "    sentiment = row['sentiment']  \n",
    "    c_text = row['c_text']\n",
    "    file_name = f\"{sentiment}_{row.name}.txt\"  \n",
    "    folder = f\"{sentiment.strip()}\"  \n",
    "    file_path = os.path.join(folder, file_name)\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(c_text)\n",
    "\n",
    "new_df.apply(col_to_txt, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_comments_df.csv'\n",
    "files_present = glob.glob(filename)\n",
    "# will only write to disk if file doesnt exist\n",
    "if not files_present:\n",
    "    new_df.to_csv(filename, index=False)\n",
    "    new_df\n",
    "else:\n",
    "    print (f'File Already Exists. Delete {filename}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory containing the positive, negative, and neutral folders\n",
    "root_dir = ''\n",
    "\n",
    "# Define the directories for train and test sets\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "# Define the ratio for train-test split\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Iterate through each sentiment folder\n",
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    # Get the list of file paths in the current sentiment folder\n",
    "    files = os.listdir(os.path.join(root_dir, sentiment))\n",
    "    # Shuffle the file paths\n",
    "    random.shuffle(files)\n",
    "    # Calculate the split index based on the split ratio\n",
    "    split_index = int(len(files) * split_ratio)\n",
    "    # Split the files into train and test sets\n",
    "    train_files = files[:split_index]\n",
    "    test_files = files[split_index:]\n",
    "    \n",
    "    # Move train files to train directory\n",
    "    for file in train_files:\n",
    "        src = os.path.join(root_dir, sentiment, file)\n",
    "        dst = os.path.join(train_dir, sentiment, file)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.move(src, dst)\n",
    "    \n",
    "    # Move test files to test directory\n",
    "    for file in test_files:\n",
    "        src = os.path.join(root_dir, sentiment, file)\n",
    "        dst = os.path.join(test_dir, sentiment, file)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.move(src, dst)\n",
    "    \n",
    "    shutil.rmtree(os.path.join(root_dir, sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Text Analytics Pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files(train_dir)\n",
    "reviews_test = load_files(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'As a person who has watched Squid Game, I can confirm this is accurate.' 1\n",
      "b'Guys I almost cried while watching spuid game' 0\n",
      "b'Squid game is exactly what Mr. Beast would be doing in his 80s' 1\n"
     ]
    }
   ],
   "source": [
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(text_train[1],y_train[1])\n",
    "print(text_train[2],y_train[2])\n",
    "print(text_train[3],y_train[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<5x5 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect = CountVectorizer().fit(reviews_train)\n",
    "X_train = vect.transform(reviews_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tokens = ['drama', 'film', 'cinema', 'actor', 'actress', 'director', 'plot',\n",
    "                  'scene', 'genre', 'subtitles', 'k-drama', 'kdrama', 'k-movie', 'television',\n",
    "                  'episode', 'screenplay', 'script', 'cinematography', 'soundtrack',\n",
    "                  'OST', 'character', 'plot twist', 'review', 'ratings', 'premiere',\n",
    "                  'streaming', 'watchlist', 'subbed', 'dubbed', 'sequel', 'game', 'song',\n",
    "                  'season', 'trailer', 'casting', 'fanbase', 'recommendation', 'viewer', \n",
    "                  'critic', 'Korean', 'entertainment', 'watched', 'show', 'squid', 'watch', \n",
    "                  'watching', 'acting', 'netflix', 'show', 'end', 'squid game', 'gi-hun', \n",
    "                  'Sang-woo', 'Player', 'Red light', 'green light', 'Honeycomb',\n",
    "                  'Tug of war', 'Marbles', 'Front man', 'VIPs', 'Doll', 'Coffin', 'Square', 'Triangle', \n",
    "                  'Circle', 'Death game', 'death', 'Survival game', 'Money', 'prize', 'Il-nam', 'Hwang Jun-ho'\n",
    "                  'director', 'Cho Sang-woo', 'Masked man', 'Childhood', 'game', 'Pink soldier', 'Betrayal',\n",
    "                  'Seong Gi-hun', 'Survival', 'Games', 'Competition', 'Squid', 'Masks', 'ali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Define the pattern to match punctuation\n",
    "    punctuation_pattern = r'[^\\w\\s]'\n",
    "    # Replace punctuation with an empty string\n",
    "    text_without_punctuation = re.sub(punctuation_pattern, '', text)\n",
    "    return text_without_punctuation\n",
    "\n",
    "# Text Processing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # stopwords punctuation etc\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    # stemmer = PorterStemmer()\n",
    "    # split into tokens\n",
    "    tokens = word_tokenize(text)\n",
    "    # removes stopwords and numbers and stems from tokens makes sure its all lowercase too\n",
    "    tokens = [stemmer.stem(remove_punctuation(token)) for token in tokens if token.isalnum() and token.lower() not in product_tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('preprocess', \n",
    "    TfidfVectorizer(\n",
    "                    encoding=\"utf-8\",\n",
    "                    strip_accents='ascii',\n",
    "                    lowercase=True,\n",
    "                    preprocessor=preprocess_text,\n",
    "                    # tokenizer=,\n",
    "                    # analyzer=,\n",
    "                    stop_words='english',\n",
    "                    norm='l2',\n",
    "                    ngram_range=(1, 1),\n",
    "                    max_df=0.09,\n",
    "                    min_df=0.003,\n",
    "                    max_features=500,\n",
    "                    binary=True,\n",
    "                    use_idf=True,\n",
    "                    smooth_idf=True,\n",
    "                    sublinear_tf=True\n",
    "                    )\n",
    "    # CountVectorizer(preprocessor=preprocess_text,ngram_range=(1, 1))\n",
    "     ), \n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "text_clf.fit(text_train, y_train)\n",
    "y_pred = text_clf.predict(text_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vectorizer': [TfidfVectorizer()],\n",
    "    'classifier': [\n",
    "        MultinomialNB(),\n",
    "        SVC(),\n",
    "        LogisticRegression()\n",
    "    ],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vectorizer__preprocessor': [preprocess_text],\n",
    "    'vectorizer__encoding': ['utf-8'],\n",
    "    'vectorizer__binary': [False, True],\n",
    "    'vectorizer__lowercase': [False, True],\n",
    "    'vectorizer__encoding': [\"utf-8\"],\n",
    "    'vectorizer__strip_accents': ['ascii'],\n",
    "    # 'vectorizer__stop_words': ['english'],\n",
    "    'vectorizer__norm': ['l2','l1'],\n",
    "    'vectorizer__max_df': [0.1,0.09,0.08,0.07],\n",
    "    'vectorizer__min_df': [0.004,0.003,0.002],\n",
    "    # 'vectorizer__max_features': [500],\n",
    "    'vectorizer__use_idf': [True,False],\n",
    "    'vectorizer__smooth_idf': [True],\n",
    "    # 'vectorizer__sublinear_tf': [True,False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "grid_search.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(text_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vectorizer': [TfidfVectorizer()],\n",
    "    'classifier': [\n",
    "        MultinomialNB(),\n",
    "        SVC(),\n",
    "        LogisticRegression()\n",
    "    ],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vectorizer__preprocessor': [preprocess_text],\n",
    "    'vectorizer__encoding': ['utf-8'],\n",
    "    'vectorizer__binary': [False, True],\n",
    "    'vectorizer__lowercase': [False, True],\n",
    "    'vectorizer__encoding': [\"utf-8\"],\n",
    "    'vectorizer__strip_accents': ['ascii'],\n",
    "    'vectorizer__stop_words': ['english'],\n",
    "    'vectorizer__norm': ['l2','l1'],\n",
    "    'vectorizer__max_df': [0.1,0.09,0.08,0.07],\n",
    "    'vectorizer__min_df': [0.004,0.003,0.002],\n",
    "    # 'vectorizer__max_features': [500],\n",
    "    'vectorizer__use_idf': [True,False],\n",
    "    'vectorizer__smooth_idf': [True],\n",
    "    # 'vectorizer__sublinear_tf': [True,False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "grid_search.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(text_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = grid_search.cv_results_\n",
    " \n",
    "scores = results['mean_test_score']\n",
    "\n",
    "params = results['params']\n",
    "\n",
    "top_models_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:10]\n",
    " \n",
    "for i in top_models_indices:\n",
    "    print(\"Model {}: Mean Test Score - {:.4f}, Parameters - {}\".format(i+1, scores[i], params[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=stop_words)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vectorizer': [CountVectorizer()],\n",
    "    'classifier': [\n",
    "        MultinomialNB(),\n",
    "        SVC(),\n",
    "        LogisticRegression()\n",
    "    ],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vectorizer__preprocessor': [preprocess_text],\n",
    "    'vectorizer__encoding': ['utf-8'],\n",
    "    'vectorizer__binary': [False, True],\n",
    "    'vectorizer__lowercase': [False, True],\n",
    "    'vectorizer__encoding': [\"utf-8\"],\n",
    "    'vectorizer__strip_accents': ['ascii'],\n",
    "    # 'vectorizer__stop_words': ['english'],\n",
    "    # 'vectorizer__norm': ['l2','l1'],\n",
    "    'vectorizer__max_df': [0.1,0.09,0.08,0.07],\n",
    "    'vectorizer__min_df': [0.004,0.003,0.002],\n",
    "    # 'vectorizer__max_features': [500],\n",
    "    # 'vectorizer__use_idf': [True,False],\n",
    "    # 'vectorizer__smooth_idf': [True],\n",
    "    # 'vectorizer__sublinear_tf': [True,False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_2 = GridSearchCV(count_pipeline, parameters, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "grid_search_2.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search_2.best_params_)\n",
    "best_model_2 = grid_search_2.best_estimator_\n",
    "y_pred_2 = best_model_2.predict(text_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2 = grid_search_2.cv_results_\n",
    " \n",
    "scores_2 = results_2['mean_test_score']\n",
    "\n",
    "params_2 = results_2['params']\n",
    "\n",
    "top_models_indices_2 = sorted(range(len(scores_2)), key=lambda i: scores_2[i], reverse=True)[:10]\n",
    " \n",
    "for i in top_models_indices_2:\n",
    "    print(\"Model {}: Mean Test Score - {:.4f}, Parameters - {}\".format(i+1, scores_2[i], params_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Visualization and Insights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Discussion and conclusion from experiments:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
