{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/farheenfab/AppliedText_CW/blob/main/CW1-generate_dataset.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F20AA Coursework 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ishaq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishaq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk \n",
    "import os\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from langdetect import detect\n",
    "import shutil\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Collection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the api service name, version and developer key for the api call.\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "# AIzaSyC8VqY2cYxX7jOouIF076rpM8lvT1ZBJu4\n",
    "# AIzaSyAWj_uzrhZL18X32S_P79pT1wnSYGpuA4k\n",
    "DEVELOPER_KEY = \"AIzaSyC8VqY2cYxX7jOouIF076rpM8lvT1ZBJu4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/search/list#parameters\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/comments/list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a class called api_handler which contains functions such as `get_video_details()`, `get_videos()`, `get_video_df()`, `get_comments()`, `get_comment_replies()`, `get_comments_df()`, `create_video_df_from_search()`, `create_video_df()`. These functions help us by either manually retrieving the videos and comments or by automatically curating the videos and comments using the product given to the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class api_handler:\n",
    "    def __init__(self, api_service_name, api_version, developer_key):\n",
    "        self.client = googleapiclient.discovery.build(api_service_name,\n",
    "                                                    api_version,\n",
    "                                                    developerKey=developer_key)\n",
    "        \n",
    "    # Search for videos details given id\n",
    "    def get_video_details(self, videoId, part=\"snippet\"):\n",
    "        request = self.client.videos().list(\n",
    "            part=part,\n",
    "            id=videoId\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        if 'items' in response:\n",
    "            video_details = response['items'][0]\n",
    "            snippet=video_details['snippet']\n",
    "            snippet['videoId']=videoId\n",
    "            snippet['id']=videoId\n",
    "            snippet['publishTime']=video_details.get('snippet', {}).get('publishedAt', {})\n",
    "            snippet['thumbnails']=video_details.get('snippet', {}).get('thumbnails', {}).get('default', {}).get('url', '')\n",
    "            return snippet\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Search for videos given query\n",
    "    def get_videos(self,query,maxResults=5,part=\"snippet\"):\n",
    "        request = self.client.search().list(\n",
    "            part=part,\n",
    "            maxResults=maxResults,\n",
    "            # higher view count is likely to be more relevent \n",
    "            order=\"viewCount\",\n",
    "            q=query,  \n",
    "            # american region videos \n",
    "            regionCode=\"US\",\n",
    "            # english videos\n",
    "            relevanceLanguage=\"en\",\n",
    "            type=\"video\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        return response\n",
    "    \n",
    "    # Format Response from get_videos to dataframe\n",
    "    def get_video_df(response):\n",
    "        items=[]\n",
    "        for item in response['items']:\n",
    "            snippet=item.get('snippet', {})\n",
    "            items+=[{\n",
    "                'title':snippet.get('title', ''),\n",
    "                'videoId':item.get('id', {}).get('videoId', ''),\n",
    "                'channelTitle':snippet.get('channelTitle', ''),\n",
    "                'publishTime':snippet.get('publishTime', ''),\n",
    "                'description':snippet.get('description', ''),\n",
    "                'thumbnails':snippet.get('thumbnails', {}).get('default', {}).get('url', '')\n",
    "                }]\n",
    "        df=pd.DataFrame(items)\n",
    "        return df\n",
    "    \n",
    "    # Get comments from video\n",
    "    def get_comments(self,videoId,part=\"snippet\",maxResults=100,maxResultsDepth=100):\n",
    "        all_comments = []\n",
    "        f = 0\n",
    "        nextPageToken = None\n",
    "        while maxResults > 0:\n",
    "            request = self.client.commentThreads().list(\n",
    "                part=part,\n",
    "                videoId=videoId,\n",
    "                maxResults=min(maxResults, 100),\n",
    "                order='relevance',\n",
    "                moderationStatus='published',\n",
    "                textFormat='plainText',\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "            response = request.execute()\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "            if 'items' in response:\n",
    "                all_comments+=[response]\n",
    "                for item in response['items']:\n",
    "                    # extract the comment ID to get replies\n",
    "                    comment_id = item.get('snippet',{}).get('topLevelComment',{}).get('id','')\n",
    "                    if item.get('snippet',{}).get('totalReplyCount',0)>2:\n",
    "                        if f == 0:\n",
    "                            print('getting replies:',item.get('snippet',{}).get('totalReplyCount',0))\n",
    "                            f = 1\n",
    "                        replies = self.get_comment_replies(comment_id, maxResults=maxResultsDepth)\n",
    "                        all_comments += replies\n",
    "\n",
    "            maxResults -= min(maxResults, 100)\n",
    "            if nextPageToken is None:\n",
    "                break;    \n",
    "        return all_comments\n",
    "    \n",
    "    # Get replies from comment \n",
    "    def get_comment_replies(self, commentId, part=\"snippet\", maxResults=100):\n",
    "        all_comments = []\n",
    "        nextPageToken = None\n",
    "        while maxResults > 0 and (nextPageToken != None or len(all_comments)==0):\n",
    "\n",
    "            request = self.client.comments().list(\n",
    "                part=part,\n",
    "                parentId=commentId,\n",
    "                maxResults=min(maxResults, 100),\n",
    "                textFormat='plainText',\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "\n",
    "            response = request.execute()\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "\n",
    "            if 'items' in response and len(response['items'])>0:\n",
    "                for item in response['items']:\n",
    "                    modified_response = {\n",
    "                        'items': [\n",
    "                            {\n",
    "                                'id':item.get('id'),\n",
    "                                'snippet': {\n",
    "                                    'topLevelComment': {\n",
    "                                        'snippet': item.get('snippet','')\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                    all_comments += [modified_response]\n",
    "            maxResults -= min(maxResults, 100)\n",
    "            if nextPageToken is None:\n",
    "                break;    \n",
    "        return all_comments\n",
    "\n",
    "    # Format response from get_comments to dataframe\n",
    "    def get_comments_df(response, video,product):\n",
    "        comments = []\n",
    "        for pages in response:\n",
    "            for item in pages['items']:\n",
    "                comment = item.get('snippet', {}).get('topLevelComment', {}).get('snippet', {})\n",
    "                comments.append([\n",
    "                        product,\n",
    "                        video.get('title', ''),\n",
    "                        video.get('videoId', ''),\n",
    "                        video.get('channelTitle', ''),\n",
    "                        video.get('publishTime', ''),\n",
    "                        video.get('description', ''),\n",
    "                        video.get('thumbnails', ''),\n",
    "                        item.get('id', ''),  \n",
    "                        comment.get('parentId', ''),  \n",
    "                        comment.get('authorDisplayName', '')[1:],  \n",
    "                        comment.get('publishedAt', ''),\n",
    "                        comment.get('updatedAt', ''),\n",
    "                        comment.get('likeCount', ''),\n",
    "                        comment.get('textDisplay', '')\n",
    "                    ])\n",
    "\n",
    "        df = pd.DataFrame(comments,\n",
    "            columns=['product', 'v_title', 'v_videoId',\n",
    "                    'v_channelTitle', 'v_publishTime',\n",
    "                    'v_description', 'v_thumbnail',\n",
    "                    'c_id','c_parentId',\n",
    "                    'c_author', 'c_published_at',\n",
    "                    'c_updated_at', 'c_like_count',\n",
    "                    'c_text'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Search for videos related to products iteratively\n",
    "    # Collect comments from each video and place it into an array\n",
    "    def create_video_df_from_search(self, products,\n",
    "                                    number_of_videos_per_product=5,\n",
    "                                    number_of_comments_per_video=100\n",
    "                                    ,number_of_replies_per_comment=100):\n",
    "        multiple_video_comments = pd.DataFrame()\n",
    "        for product in products:\n",
    "            # get 25 first videos with the highest viewer counts \n",
    "            response = self.get_videos(query=product, maxResults=number_of_videos_per_product)\n",
    "            # Convert results to df\n",
    "            videos_df = api_handler.get_video_df(response)\n",
    "            # For each video get a maximum of 100 comments\n",
    "            # and place comments into an array\n",
    "            for _, video in videos_df.iterrows():\n",
    "                try:\n",
    "                    response = self.get_comments(video['videoId'], maxResults=number_of_comments_per_video,maxResultsDepth=number_of_replies_per_comment)\n",
    "                    comments_df = api_handler.get_comments_df(response, video, product)\n",
    "                except:\n",
    "                    # Function fails as the API returns 403 if the channel has comments disabled\n",
    "                    # place an empty entry instead it can be deleted later\n",
    "                    comments_df = pd.DataFrame(np.zeros((1, 14)),\n",
    "                                                columns=['product', 'v_title', 'v_videoId',\n",
    "                                                        'v_channelTitle', 'v_publishTime',\n",
    "                                                        'v_description', 'v_thumbnail',\n",
    "                                                        'c_id','c_parentId',\n",
    "                                                        'c_author', 'c_published_at',\n",
    "                                                        'c_updated_at', 'c_like_count',\n",
    "                                                        'c_text'])\n",
    "                    print('Unable to retrieve comments:', video.get('title', ''))\n",
    "                multiple_video_comments = pd.concat([multiple_video_comments, comments_df], ignore_index=True)\n",
    "        return multiple_video_comments\n",
    "        \n",
    "    # alternative method by explicitely specifying videos\n",
    "    def create_video_df(self,products,videos,number_of_comments_per_video=100,number_of_replies_per_comment=100):\n",
    "        count=0\n",
    "        multiple_video_comments = pd.DataFrame()\n",
    "        for product in products:\n",
    "            for video in videos[count]:\n",
    "                response = self.get_comments(video,maxResults=number_of_comments_per_video,maxResultsDepth=number_of_replies_per_comment) \n",
    "                video=self.get_video_details(video)\n",
    "                comments_df = api_handler.get_comments_df(response, video, product)\n",
    "                multiple_video_comments = pd.concat([multiple_video_comments, comments_df], ignore_index=True)\n",
    "            count+=1\n",
    "        return multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen the Korean Drama called Squid Game to perform the sentiment analysis on. We specify the product in the products list, create a `api_handler` class object, use the `create_video_df_from_search()` function to automatically curate comments using the YouTube api call, and get a pandas Dataframe in return containing details about the videos and the comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "products=[\"Squid Game Korean Drama (2021)\"]\n",
    "\n",
    "youtube=api_handler(api_service_name, api_version, DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting replies: 750\n",
      "getting replies: 16\n",
      "getting replies: 62\n",
      "getting replies: 64\n",
      "getting replies: 129\n",
      "getting replies: 14\n",
      "getting replies: 504\n",
      "getting replies: 101\n",
      "getting replies: 350\n",
      "getting replies: 16\n",
      "getting replies: 5\n",
      "getting replies: 3\n",
      "getting replies: 318\n",
      "getting replies: 25\n",
      "getting replies: 230\n",
      "getting replies: 390\n",
      "getting replies: 16\n",
      "getting replies: 154\n",
      "getting replies: 15\n",
      "getting replies: 461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzH8vliQSJKHQMGZjx4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>1008401</td>\n",
       "      <td>Like I said in the video, subscribe if you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgwDhFNTCbfck5apuUJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>DoodleChaos</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>514509</td>\n",
       "      <td>Huge props to the set designers, everything wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzVlS_nKI4aXISU_ep4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>mukul_editz</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>400</td>\n",
       "      <td>Your videos are so interesting ‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgxykcUWbPcLhlL-Gy14AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>SpamR1_2013</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>1682</td>\n",
       "      <td>that guy who sacrificed himself on purpose for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>Ugxu5B8dQ9-mZpfW-UV4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-cs9zv3gh1k</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>261</td>\n",
       "      <td>This version of the game is pretty much what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18372</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgwU9oUM-OZchm2sgCd4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>manilslat6087</td>\n",
       "      <td>2021-10-01T14:12:37Z</td>\n",
       "      <td>2021-10-01T14:12:37Z</td>\n",
       "      <td>33</td>\n",
       "      <td>I can‚Äôt believe she‚Äôs 27. I genuinely thought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18373</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgzSOIEiURAgdM1nSD94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>marcclothier1534</td>\n",
       "      <td>2021-11-03T08:42:52Z</td>\n",
       "      <td>2021-11-03T08:42:52Z</td>\n",
       "      <td>0</td>\n",
       "      <td>In the next vid can you tell us if ali and kan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugw_hEjd679F03XdPxF4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>brunopini1652</td>\n",
       "      <td>2021-11-06T03:03:07Z</td>\n",
       "      <td>2021-11-06T03:03:07Z</td>\n",
       "      <td>1</td>\n",
       "      <td>7:48 esa miradita de sabyok y el policiaüòíüòíüò≥üò≥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18375</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugy3ZMc5AoKVwFgMCgp4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>jaywawayma7765</td>\n",
       "      <td>2021-10-01T21:27:50Z</td>\n",
       "      <td>2021-10-01T21:27:50Z</td>\n",
       "      <td>86</td>\n",
       "      <td>WHERES ALIüò´also it is weird seeing them not sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18376</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugx-j7Us9OaD0hppEUt4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ThoNguyen-bb5cr</td>\n",
       "      <td>2021-11-23T11:56:37Z</td>\n",
       "      <td>2021-11-23T11:56:37Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Hay th·∫≠t ƒë·∫•y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18377 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product  \\\n",
       "0      Squid Game Korean Drama (2021)   \n",
       "1      Squid Game Korean Drama (2021)   \n",
       "2      Squid Game Korean Drama (2021)   \n",
       "3      Squid Game Korean Drama (2021)   \n",
       "4      Squid Game Korean Drama (2021)   \n",
       "...                               ...   \n",
       "18372  Squid Game Korean Drama (2021)   \n",
       "18373  Squid Game Korean Drama (2021)   \n",
       "18374  Squid Game Korean Drama (2021)   \n",
       "18375  Squid Game Korean Drama (2021)   \n",
       "18376  Squid Game Korean Drama (2021)   \n",
       "\n",
       "                                                 v_title    v_videoId  \\\n",
       "0                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "1                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "2                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "3                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "4                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "...                                                  ...          ...   \n",
       "18372  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "18373  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "18374  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "18375  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "18376  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "\n",
       "          v_channelTitle         v_publishTime  \\\n",
       "0                MrBeast  2021-11-24T21:00:01Z   \n",
       "1                MrBeast  2021-11-24T21:00:01Z   \n",
       "2                MrBeast  2021-11-24T21:00:01Z   \n",
       "3                MrBeast  2021-11-24T21:00:01Z   \n",
       "4                MrBeast  2021-11-24T21:00:01Z   \n",
       "...                  ...                   ...   \n",
       "18372  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "18373  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "18374  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "18375  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "18376  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "0      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "1      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "2      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "3      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "4      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "...                                                  ...   \n",
       "18372  The stars of SQUID GAME are faced with yet ano...   \n",
       "18373  The stars of SQUID GAME are faced with yet ano...   \n",
       "18374  The stars of SQUID GAME are faced with yet ano...   \n",
       "18375  The stars of SQUID GAME are faced with yet ano...   \n",
       "18376  The stars of SQUID GAME are faced with yet ano...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "0      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "1      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "2      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "3      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "4      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "...                                               ...   \n",
       "18372  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "18373  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "18374  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "18375  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "18376  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "\n",
       "                             c_id c_parentId          c_author  \\\n",
       "0      UgzH8vliQSJKHQMGZjx4AaABAg                      MrBeast   \n",
       "1      UgwDhFNTCbfck5apuUJ4AaABAg                  DoodleChaos   \n",
       "2      UgzVlS_nKI4aXISU_ep4AaABAg                  mukul_editz   \n",
       "3      UgxykcUWbPcLhlL-Gy14AaABAg                  SpamR1_2013   \n",
       "4      Ugxu5B8dQ9-mZpfW-UV4AaABAg              user-cs9zv3gh1k   \n",
       "...                           ...        ...               ...   \n",
       "18372  UgwU9oUM-OZchm2sgCd4AaABAg                manilslat6087   \n",
       "18373  UgzSOIEiURAgdM1nSD94AaABAg             marcclothier1534   \n",
       "18374  Ugw_hEjd679F03XdPxF4AaABAg                brunopini1652   \n",
       "18375  Ugy3ZMc5AoKVwFgMCgp4AaABAg               jaywawayma7765   \n",
       "18376  Ugx-j7Us9OaD0hppEUt4AaABAg              ThoNguyen-bb5cr   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "0      2021-11-24T21:02:45Z  2021-11-24T21:02:45Z       1008401   \n",
       "1      2021-11-24T22:07:54Z  2021-11-24T22:07:54Z        514509   \n",
       "2      2023-12-30T01:55:59Z  2023-12-30T01:55:59Z           400   \n",
       "3      2023-11-27T00:57:21Z  2023-11-27T00:57:21Z          1682   \n",
       "4      2024-01-30T20:17:02Z  2024-01-30T20:17:02Z           261   \n",
       "...                     ...                   ...           ...   \n",
       "18372  2021-10-01T14:12:37Z  2021-10-01T14:12:37Z            33   \n",
       "18373  2021-11-03T08:42:52Z  2021-11-03T08:42:52Z             0   \n",
       "18374  2021-11-06T03:03:07Z  2021-11-06T03:03:07Z             1   \n",
       "18375  2021-10-01T21:27:50Z  2021-10-01T21:27:50Z            86   \n",
       "18376  2021-11-23T11:56:37Z  2021-11-23T11:56:37Z             0   \n",
       "\n",
       "                                                  c_text  \n",
       "0      Like I said in the video, subscribe if you hav...  \n",
       "1      Huge props to the set designers, everything wa...  \n",
       "2                       Your videos are so interesting ‚ù§  \n",
       "3      that guy who sacrificed himself on purpose for...  \n",
       "4      This version of the game is pretty much what t...  \n",
       "...                                                  ...  \n",
       "18372  I can‚Äôt believe she‚Äôs 27. I genuinely thought ...  \n",
       "18373  In the next vid can you tell us if ali and kan...  \n",
       "18374       7:48 esa miradita de sabyok y el policiaüòíüòíüò≥üò≥  \n",
       "18375  WHERES ALIüò´also it is weird seeing them not sa...  \n",
       "18376                                       Hay th·∫≠t ƒë·∫•y  \n",
       "\n",
       "[18377 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_video_comments=youtube.create_video_df_from_search(products,number_of_videos_per_product=20,number_of_comments_per_video=1000,number_of_replies_per_comment=100)\n",
    "multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Analysis, Selection and Labeling:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from:\n",
    "\n",
    "https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove emojis : As emojis do not provide any helpful information they should be removed from the text strings.\n",
    "def remove_emojis(data):\n",
    "    if isinstance(data, str):\n",
    "        # Remove html tags\n",
    "        data = BeautifulSoup(data, \"html.parser\").get_text()\n",
    "        # Remove emote, etc\n",
    "        emoj = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "                        \"]+\", re.UNICODE)\n",
    "        # english_words = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "\n",
    "        return re.sub(emoj, '', data)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row containing NA values.\n",
    "multiple_video_comments.dropna(subset=['c_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaq\\AppData\\Local\\Temp\\ipykernel_17024\\2754946649.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  data = BeautifulSoup(data, \"html.parser\").get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Length Before: 18377\n",
      "DataFrame Length After: 15779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzH8vliQSJKHQMGZjx4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>1008401</td>\n",
       "      <td>Like I said in the video, subscribe if you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgwDhFNTCbfck5apuUJ4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>DoodleChaos</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>514509</td>\n",
       "      <td>Huge props to the set designers, everything wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgzVlS_nKI4aXISU_ep4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>mukul_editz</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>2023-12-30T01:55:59Z</td>\n",
       "      <td>400</td>\n",
       "      <td>Your videos are so interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>UgxykcUWbPcLhlL-Gy14AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>SpamR1_2013</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>2023-11-27T00:57:21Z</td>\n",
       "      <td>1682</td>\n",
       "      <td>that guy who sacrificed himself on purpose for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>$456,000 Squid Game In Real Life!</td>\n",
       "      <td>0e3GPea1Tyg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>2021-11-24T21:00:01Z</td>\n",
       "      <td>MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...</td>\n",
       "      <td>https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg</td>\n",
       "      <td>Ugxu5B8dQ9-mZpfW-UV4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>user-cs9zv3gh1k</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>2024-01-30T20:17:02Z</td>\n",
       "      <td>261</td>\n",
       "      <td>This version of the game is pretty much what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18372</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgwU9oUM-OZchm2sgCd4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>manilslat6087</td>\n",
       "      <td>2021-10-01T14:12:37Z</td>\n",
       "      <td>2021-10-01T14:12:37Z</td>\n",
       "      <td>33</td>\n",
       "      <td>I can‚Äôt believe she‚Äôs 27. I genuinely thought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18373</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgzSOIEiURAgdM1nSD94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>marcclothier1534</td>\n",
       "      <td>2021-11-03T08:42:52Z</td>\n",
       "      <td>2021-11-03T08:42:52Z</td>\n",
       "      <td>0</td>\n",
       "      <td>In the next vid can you tell us if ali and kan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugw_hEjd679F03XdPxF4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>brunopini1652</td>\n",
       "      <td>2021-11-06T03:03:07Z</td>\n",
       "      <td>2021-11-06T03:03:07Z</td>\n",
       "      <td>1</td>\n",
       "      <td>7:48 esa miradita de sabyok y el policia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18375</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugy3ZMc5AoKVwFgMCgp4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>jaywawayma7765</td>\n",
       "      <td>2021-10-01T21:27:50Z</td>\n",
       "      <td>2021-10-01T21:27:50Z</td>\n",
       "      <td>86</td>\n",
       "      <td>WHERES ALIalso it is weird seeing them not sad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18376</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugx-j7Us9OaD0hppEUt4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ThoNguyen-bb5cr</td>\n",
       "      <td>2021-11-23T11:56:37Z</td>\n",
       "      <td>2021-11-23T11:56:37Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Hay th·∫≠t ƒë·∫•y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15779 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product  \\\n",
       "0      Squid Game Korean Drama (2021)   \n",
       "1      Squid Game Korean Drama (2021)   \n",
       "2      Squid Game Korean Drama (2021)   \n",
       "3      Squid Game Korean Drama (2021)   \n",
       "4      Squid Game Korean Drama (2021)   \n",
       "...                               ...   \n",
       "18372  Squid Game Korean Drama (2021)   \n",
       "18373  Squid Game Korean Drama (2021)   \n",
       "18374  Squid Game Korean Drama (2021)   \n",
       "18375  Squid Game Korean Drama (2021)   \n",
       "18376  Squid Game Korean Drama (2021)   \n",
       "\n",
       "                                                 v_title    v_videoId  \\\n",
       "0                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "1                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "2                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "3                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "4                      $456,000 Squid Game In Real Life!  0e3GPea1Tyg   \n",
       "...                                                  ...          ...   \n",
       "18372  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "18373  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "18374  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "18375  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "18376  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "\n",
       "          v_channelTitle         v_publishTime  \\\n",
       "0                MrBeast  2021-11-24T21:00:01Z   \n",
       "1                MrBeast  2021-11-24T21:00:01Z   \n",
       "2                MrBeast  2021-11-24T21:00:01Z   \n",
       "3                MrBeast  2021-11-24T21:00:01Z   \n",
       "4                MrBeast  2021-11-24T21:00:01Z   \n",
       "...                  ...                   ...   \n",
       "18372  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "18373  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "18374  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "18375  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "18376  Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "0      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "1      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "2      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "3      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "4      MAKE SURE YOU WATCH UNTIL GLASS BRIDGE IT'S IN...   \n",
       "...                                                  ...   \n",
       "18372  The stars of SQUID GAME are faced with yet ano...   \n",
       "18373  The stars of SQUID GAME are faced with yet ano...   \n",
       "18374  The stars of SQUID GAME are faced with yet ano...   \n",
       "18375  The stars of SQUID GAME are faced with yet ano...   \n",
       "18376  The stars of SQUID GAME are faced with yet ano...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "0      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "1      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "2      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "3      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "4      https://i.ytimg.com/vi/0e3GPea1Tyg/default.jpg   \n",
       "...                                               ...   \n",
       "18372  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "18373  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "18374  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "18375  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "18376  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "\n",
       "                             c_id c_parentId          c_author  \\\n",
       "0      UgzH8vliQSJKHQMGZjx4AaABAg                      MrBeast   \n",
       "1      UgwDhFNTCbfck5apuUJ4AaABAg                  DoodleChaos   \n",
       "2      UgzVlS_nKI4aXISU_ep4AaABAg                  mukul_editz   \n",
       "3      UgxykcUWbPcLhlL-Gy14AaABAg                  SpamR1_2013   \n",
       "4      Ugxu5B8dQ9-mZpfW-UV4AaABAg              user-cs9zv3gh1k   \n",
       "...                           ...        ...               ...   \n",
       "18372  UgwU9oUM-OZchm2sgCd4AaABAg                manilslat6087   \n",
       "18373  UgzSOIEiURAgdM1nSD94AaABAg             marcclothier1534   \n",
       "18374  Ugw_hEjd679F03XdPxF4AaABAg                brunopini1652   \n",
       "18375  Ugy3ZMc5AoKVwFgMCgp4AaABAg               jaywawayma7765   \n",
       "18376  Ugx-j7Us9OaD0hppEUt4AaABAg              ThoNguyen-bb5cr   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "0      2021-11-24T21:02:45Z  2021-11-24T21:02:45Z       1008401   \n",
       "1      2021-11-24T22:07:54Z  2021-11-24T22:07:54Z        514509   \n",
       "2      2023-12-30T01:55:59Z  2023-12-30T01:55:59Z           400   \n",
       "3      2023-11-27T00:57:21Z  2023-11-27T00:57:21Z          1682   \n",
       "4      2024-01-30T20:17:02Z  2024-01-30T20:17:02Z           261   \n",
       "...                     ...                   ...           ...   \n",
       "18372  2021-10-01T14:12:37Z  2021-10-01T14:12:37Z            33   \n",
       "18373  2021-11-03T08:42:52Z  2021-11-03T08:42:52Z             0   \n",
       "18374  2021-11-06T03:03:07Z  2021-11-06T03:03:07Z             1   \n",
       "18375  2021-10-01T21:27:50Z  2021-10-01T21:27:50Z            86   \n",
       "18376  2021-11-23T11:56:37Z  2021-11-23T11:56:37Z             0   \n",
       "\n",
       "                                                  c_text  \n",
       "0      Like I said in the video, subscribe if you hav...  \n",
       "1      Huge props to the set designers, everything wa...  \n",
       "2                        Your videos are so interesting   \n",
       "3      that guy who sacrificed himself on purpose for...  \n",
       "4      This version of the game is pretty much what t...  \n",
       "...                                                  ...  \n",
       "18372  I can‚Äôt believe she‚Äôs 27. I genuinely thought ...  \n",
       "18373  In the next vid can you tell us if ali and kan...  \n",
       "18374           7:48 esa miradita de sabyok y el policia  \n",
       "18375  WHERES ALIalso it is weird seeing them not sad...  \n",
       "18376                                       Hay th·∫≠t ƒë·∫•y  \n",
       "\n",
       "[15779 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove emojis from the text to be analyzed\n",
    "multiple_video_comments['c_text']=multiple_video_comments['c_text'].apply(remove_emojis)\n",
    "\n",
    "df_length_before = len(multiple_video_comments)\n",
    "print(\"DataFrame Length Before:\", df_length_before)\n",
    "\n",
    "# Drop duplicates\n",
    "multiple_video_comments.drop_duplicates(inplace=True)\n",
    "multiple_video_comments.dropna(subset=['c_text'],inplace=True)\n",
    "# Drop rows with empty or text length <= 2 comments\n",
    "multiple_video_comments = multiple_video_comments[multiple_video_comments['c_text'].apply(lambda x: len(x) > 2)]\n",
    "\n",
    "df_length_after = len(multiple_video_comments)\n",
    "print(\"DataFrame Length After:\", df_length_after)\n",
    "\n",
    "multiple_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://stackoverflow.com/questions/40375366/pandas-to-csv-checking-for-overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing:\n",
    "    def __init__(self):\n",
    "        # Define keywords related to the TV show\n",
    "        self.tv_show_keywords = ['Squid Game', 'Gi-hun', 'Sang-woo', 'Player', 'Red light, green light', 'Honeycomb',\n",
    "                            'Tug of war', 'Marbles', 'Front man', 'VIPs', 'Doll', 'Coffin', 'Square', 'Triangle', \n",
    "                            'Circle', 'Death game', 'death', 'Survival game', 'Money', 'prize', 'Il-nam', 'Hwang Jun-ho'\n",
    "                            'director', 'Cho Sang-woo', 'Masked man', 'Childhood', 'game', 'Pink soldier', 'Betrayal',\n",
    "                            'Seong Gi-hun', 'Survival', 'Games', 'Competition', 'Squid', 'Masks', 'ali', ]\n",
    "        # Setting threshold value for validating the relevance of the comment\n",
    "        self.threshold = 1\n",
    "\n",
    "    # Tokenize text and remove stop words\n",
    "    def preprocess_text(self, text):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "        return filtered_tokens\n",
    "\n",
    "    # Matching function to check relevance of the comments\n",
    "    def match_keywords(self, tokens):\n",
    "        return [token for token in tokens if token in self.tv_show_keywords]\n",
    "\n",
    "    # Scoring function to calculate how many tokens matched\n",
    "    def calculate_score(self, tokens):\n",
    "        return len(tokens)\n",
    "\n",
    "    # Validate function to validate the relevance based on threshold\n",
    "    def validate_relevance(self, score):\n",
    "        return score >= self.threshold\n",
    "\n",
    "    def filter_comments(self, df):\n",
    "        c = 0\n",
    "        comments = []\n",
    "        irrelevant_keywords = ['HYVE', 'crypto', 'promotion', 'ad', 'spam', 'advertisement', 'spoiler', 'leak', 'promo', 'off-topic', 'clickbait',\n",
    "                            'self-promotion', '0:', '1:', '2:', '3:', '4:', '5:', '6:', '7:',\n",
    "                            '8:', '9:', '10:', '11:', '12:', '13:', '14:', '15:']\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                if detect(row['c_text']) == 'en' and not any(keyword in row['c_text'] for keyword in irrelevant_keywords):\n",
    "                    comments.append(row)\n",
    "                    c += 1\n",
    "            except Exception as e:  # Catch any exception\n",
    "                pass\n",
    "        print(\"Number of Filtered Comments: \", c)\n",
    "        new_df = pd.DataFrame(comments, \n",
    "                    columns=['product', 'v_title', 'v_videoId',\n",
    "                        'v_channelTitle', 'v_publishTime',\n",
    "                        'v_description', 'v_thumbnail',\n",
    "                        'c_id','c_parentId',\n",
    "                        'c_author', 'c_published_at',\n",
    "                        'c_updated_at', 'c_like_count',\n",
    "                        'c_text'])  # Create a new DataFrame from the list of rows\n",
    "        new_df = new_df.sort_values(by = ['c_like_count'], ascending = False)\n",
    "        new_df.drop_duplicates(inplace=True)\n",
    "        new_df = new_df[:4000]\n",
    "        return new_df\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        c = 0\n",
    "        comments = []\n",
    "        for index, row in df.iterrows():\n",
    "            processed_text = self.preprocess_text(row['c_text'])\n",
    "            matched_keywords = self.match_keywords(processed_text)\n",
    "            score = self.calculate_score(matched_keywords)\n",
    "            is_relevant = self.validate_relevance(score)\n",
    "            if is_relevant == 1:\n",
    "                comments.append(row)\n",
    "                c += 1\n",
    "\n",
    "        new_df = pd.DataFrame(comments, \n",
    "                    columns=['product', 'v_title', 'v_videoId',\n",
    "                        'v_channelTitle', 'v_publishTime',\n",
    "                        'v_description', 'v_thumbnail',\n",
    "                        'c_id','c_parentId',\n",
    "                        'c_author', 'c_published_at',\n",
    "                        'c_updated_at', 'c_like_count',\n",
    "                        'c_text'])\n",
    "        print(\"Number of Processed Comments: \", c)\n",
    "        new_df = self.filter_comments(new_df)\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Processed Comments:  1890\n",
      "Number of Filtered Comments:  1162\n"
     ]
    }
   ],
   "source": [
    "p = preprocessing()\n",
    "new_df = p.preprocess(multiple_video_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_videoId</th>\n",
       "      <th>v_channelTitle</th>\n",
       "      <th>v_publishTime</th>\n",
       "      <th>v_description</th>\n",
       "      <th>v_thumbnail</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_parentId</th>\n",
       "      <th>c_author</th>\n",
       "      <th>c_published_at</th>\n",
       "      <th>c_updated_at</th>\n",
       "      <th>c_like_count</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17419</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugy5u7EHRR6IRod2vxN4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>MaisieTheUnicorn</td>\n",
       "      <td>2021-09-27T15:53:33Z</td>\n",
       "      <td>2021-09-27T15:53:33Z</td>\n",
       "      <td>33371</td>\n",
       "      <td>Hoyeon in Squid Game:\\nHoyeon in RL:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17395</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgxlkxXiNXjyjJcOcel4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>esophagus3319</td>\n",
       "      <td>2021-09-25T02:58:15Z</td>\n",
       "      <td>2021-09-25T02:58:15Z</td>\n",
       "      <td>21223</td>\n",
       "      <td>the way her real personality is totally differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17401</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>Ugy5Vw4Hlzj-ZHpMgjN4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>Jk-bp4nu</td>\n",
       "      <td>2021-09-25T18:37:02Z</td>\n",
       "      <td>2021-09-25T18:37:02Z</td>\n",
       "      <td>17518</td>\n",
       "      <td>Even if Squid Game was Ho Yeon's first drama, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17791</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgxtKW6yi_uSmDXvAzt4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>ChristineWang19</td>\n",
       "      <td>2021-09-25T01:02:12Z</td>\n",
       "      <td>2021-09-25T01:52:09Z</td>\n",
       "      <td>14895</td>\n",
       "      <td>OMG I CLICKED SO FAST!!\\nLITERALLY THIRSTY FOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17379</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgyMnV8PjtgP5-d2RfF4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>brooke4608</td>\n",
       "      <td>2021-10-09T00:22:59Z</td>\n",
       "      <td>2021-10-09T00:22:59Z</td>\n",
       "      <td>14598</td>\n",
       "      <td>It‚Äôs so nice seeing them play a game that won‚Äô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game (2021) Explained in Hindi / Urdu | ...</td>\n",
       "      <td>UMZv8M6_wHU</td>\n",
       "      <td>Movies Insight Hindi</td>\n",
       "      <td>2021-10-07T02:15:00Z</td>\n",
       "      <td>Squid Game (2021) Survival drama explained in ...</td>\n",
       "      <td>https://i.ytimg.com/vi/UMZv8M6_wHU/default.jpg</td>\n",
       "      <td>UgyCgeQrYDNUFsX7Deh4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>chocobeansgamingzone5894</td>\n",
       "      <td>2021-10-10T04:24:10Z</td>\n",
       "      <td>2021-10-10T04:24:10Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Squid game is the best series ever.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11140</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game (2021) Explained in Hindi / Urdu | ...</td>\n",
       "      <td>UMZv8M6_wHU</td>\n",
       "      <td>Movies Insight Hindi</td>\n",
       "      <td>2021-10-07T02:15:00Z</td>\n",
       "      <td>Squid Game (2021) Survival drama explained in ...</td>\n",
       "      <td>https://i.ytimg.com/vi/UMZv8M6_wHU/default.jpg</td>\n",
       "      <td>UgzZbVIiuxghD7unf_x4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>gamingwithmonika5243</td>\n",
       "      <td>2021-12-06T12:52:55Z</td>\n",
       "      <td>2021-12-06T12:52:55Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Hmmm so many people died in the game if I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11182</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game (2021) Explained in Hindi / Urdu | ...</td>\n",
       "      <td>UMZv8M6_wHU</td>\n",
       "      <td>Movies Insight Hindi</td>\n",
       "      <td>2021-10-07T02:15:00Z</td>\n",
       "      <td>Squid Game (2021) Survival drama explained in ...</td>\n",
       "      <td>https://i.ytimg.com/vi/UMZv8M6_wHU/default.jpg</td>\n",
       "      <td>UgyOI9cxiaGYjH3lcTN4AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>vivanchohan8762</td>\n",
       "      <td>2023-04-04T10:02:10Z</td>\n",
       "      <td>2023-04-04T10:02:10Z</td>\n",
       "      <td>0</td>\n",
       "      <td>There has to be another part of squid game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11190</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Squid Game (2021) Explained in Hindi / Urdu | ...</td>\n",
       "      <td>UMZv8M6_wHU</td>\n",
       "      <td>Movies Insight Hindi</td>\n",
       "      <td>2021-10-07T02:15:00Z</td>\n",
       "      <td>Squid Game (2021) Survival drama explained in ...</td>\n",
       "      <td>https://i.ytimg.com/vi/UMZv8M6_wHU/default.jpg</td>\n",
       "      <td>UgxlnjmAdI4PecmyxQ14AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>harbhajansinghbhajan679</td>\n",
       "      <td>2022-05-07T13:13:15Z</td>\n",
       "      <td>2022-05-07T13:13:15Z</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favourite game but I don't play rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18373</th>\n",
       "      <td>Squid Game Korean Drama (2021)</td>\n",
       "      <td>Cast of Squid Game ditches tracksuits for suit...</td>\n",
       "      <td>o4EF1NG_xks</td>\n",
       "      <td>Netflix K-Content</td>\n",
       "      <td>2021-09-25T01:00:08Z</td>\n",
       "      <td>The stars of SQUID GAME are faced with yet ano...</td>\n",
       "      <td>https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg</td>\n",
       "      <td>UgzSOIEiURAgdM1nSD94AaABAg</td>\n",
       "      <td></td>\n",
       "      <td>marcclothier1534</td>\n",
       "      <td>2021-11-03T08:42:52Z</td>\n",
       "      <td>2021-11-03T08:42:52Z</td>\n",
       "      <td>0</td>\n",
       "      <td>In the next vid can you tell us if ali and kan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1162 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              product  \\\n",
       "17419  Squid Game Korean Drama (2021)   \n",
       "17395  Squid Game Korean Drama (2021)   \n",
       "17401  Squid Game Korean Drama (2021)   \n",
       "17791  Squid Game Korean Drama (2021)   \n",
       "17379  Squid Game Korean Drama (2021)   \n",
       "...                               ...   \n",
       "11139  Squid Game Korean Drama (2021)   \n",
       "11140  Squid Game Korean Drama (2021)   \n",
       "11182  Squid Game Korean Drama (2021)   \n",
       "11190  Squid Game Korean Drama (2021)   \n",
       "18373  Squid Game Korean Drama (2021)   \n",
       "\n",
       "                                                 v_title    v_videoId  \\\n",
       "17419  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "17395  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "17401  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "17791  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "17379  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "...                                                  ...          ...   \n",
       "11139  Squid Game (2021) Explained in Hindi / Urdu | ...  UMZv8M6_wHU   \n",
       "11140  Squid Game (2021) Explained in Hindi / Urdu | ...  UMZv8M6_wHU   \n",
       "11182  Squid Game (2021) Explained in Hindi / Urdu | ...  UMZv8M6_wHU   \n",
       "11190  Squid Game (2021) Explained in Hindi / Urdu | ...  UMZv8M6_wHU   \n",
       "18373  Cast of Squid Game ditches tracksuits for suit...  o4EF1NG_xks   \n",
       "\n",
       "             v_channelTitle         v_publishTime  \\\n",
       "17419     Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "17395     Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "17401     Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "17791     Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "17379     Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "...                     ...                   ...   \n",
       "11139  Movies Insight Hindi  2021-10-07T02:15:00Z   \n",
       "11140  Movies Insight Hindi  2021-10-07T02:15:00Z   \n",
       "11182  Movies Insight Hindi  2021-10-07T02:15:00Z   \n",
       "11190  Movies Insight Hindi  2021-10-07T02:15:00Z   \n",
       "18373     Netflix K-Content  2021-09-25T01:00:08Z   \n",
       "\n",
       "                                           v_description  \\\n",
       "17419  The stars of SQUID GAME are faced with yet ano...   \n",
       "17395  The stars of SQUID GAME are faced with yet ano...   \n",
       "17401  The stars of SQUID GAME are faced with yet ano...   \n",
       "17791  The stars of SQUID GAME are faced with yet ano...   \n",
       "17379  The stars of SQUID GAME are faced with yet ano...   \n",
       "...                                                  ...   \n",
       "11139  Squid Game (2021) Survival drama explained in ...   \n",
       "11140  Squid Game (2021) Survival drama explained in ...   \n",
       "11182  Squid Game (2021) Survival drama explained in ...   \n",
       "11190  Squid Game (2021) Survival drama explained in ...   \n",
       "18373  The stars of SQUID GAME are faced with yet ano...   \n",
       "\n",
       "                                          v_thumbnail  \\\n",
       "17419  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "17395  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "17401  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "17791  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "17379  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "...                                               ...   \n",
       "11139  https://i.ytimg.com/vi/UMZv8M6_wHU/default.jpg   \n",
       "11140  https://i.ytimg.com/vi/UMZv8M6_wHU/default.jpg   \n",
       "11182  https://i.ytimg.com/vi/UMZv8M6_wHU/default.jpg   \n",
       "11190  https://i.ytimg.com/vi/UMZv8M6_wHU/default.jpg   \n",
       "18373  https://i.ytimg.com/vi/o4EF1NG_xks/default.jpg   \n",
       "\n",
       "                             c_id c_parentId                  c_author  \\\n",
       "17419  Ugy5u7EHRR6IRod2vxN4AaABAg                     MaisieTheUnicorn   \n",
       "17395  UgxlkxXiNXjyjJcOcel4AaABAg                        esophagus3319   \n",
       "17401  Ugy5Vw4Hlzj-ZHpMgjN4AaABAg                             Jk-bp4nu   \n",
       "17791  UgxtKW6yi_uSmDXvAzt4AaABAg                      ChristineWang19   \n",
       "17379  UgyMnV8PjtgP5-d2RfF4AaABAg                           brooke4608   \n",
       "...                           ...        ...                       ...   \n",
       "11139  UgyCgeQrYDNUFsX7Deh4AaABAg             chocobeansgamingzone5894   \n",
       "11140  UgzZbVIiuxghD7unf_x4AaABAg                 gamingwithmonika5243   \n",
       "11182  UgyOI9cxiaGYjH3lcTN4AaABAg                      vivanchohan8762   \n",
       "11190  UgxlnjmAdI4PecmyxQ14AaABAg              harbhajansinghbhajan679   \n",
       "18373  UgzSOIEiURAgdM1nSD94AaABAg                     marcclothier1534   \n",
       "\n",
       "             c_published_at          c_updated_at  c_like_count  \\\n",
       "17419  2021-09-27T15:53:33Z  2021-09-27T15:53:33Z         33371   \n",
       "17395  2021-09-25T02:58:15Z  2021-09-25T02:58:15Z         21223   \n",
       "17401  2021-09-25T18:37:02Z  2021-09-25T18:37:02Z         17518   \n",
       "17791  2021-09-25T01:02:12Z  2021-09-25T01:52:09Z         14895   \n",
       "17379  2021-10-09T00:22:59Z  2021-10-09T00:22:59Z         14598   \n",
       "...                     ...                   ...           ...   \n",
       "11139  2021-10-10T04:24:10Z  2021-10-10T04:24:10Z             0   \n",
       "11140  2021-12-06T12:52:55Z  2021-12-06T12:52:55Z             0   \n",
       "11182  2023-04-04T10:02:10Z  2023-04-04T10:02:10Z             0   \n",
       "11190  2022-05-07T13:13:15Z  2022-05-07T13:13:15Z             0   \n",
       "18373  2021-11-03T08:42:52Z  2021-11-03T08:42:52Z             0   \n",
       "\n",
       "                                                  c_text  \n",
       "17419               Hoyeon in Squid Game:\\nHoyeon in RL:  \n",
       "17395  the way her real personality is totally differ...  \n",
       "17401  Even if Squid Game was Ho Yeon's first drama, ...  \n",
       "17791  OMG I CLICKED SO FAST!!\\nLITERALLY THIRSTY FOR...  \n",
       "17379  It‚Äôs so nice seeing them play a game that won‚Äô...  \n",
       "...                                                  ...  \n",
       "11139                Squid game is the best series ever.  \n",
       "11140  Hmmm so many people died in the game if I woul...  \n",
       "11182         There has to be another part of squid game  \n",
       "11190  This is my favourite game but I don't play rea...  \n",
       "18373  In the next vid can you tell us if ali and kan...  \n",
       "\n",
       "[1162 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling comments using Sentiment Lexicon - VADER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lexicon = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(c_text):\n",
    "    sentiment_Score = sentiment_lexicon.polarity_scores(c_text)\n",
    "    return sentiment_Score['compound']\n",
    "\n",
    "def check_sentiment(sentiment_score):\n",
    "    if sentiment_score > 0.00:\n",
    "        return \"Positive\"\n",
    "    elif sentiment_score < 0.00:\n",
    "        return \"Negative\"\n",
    "    elif sentiment_score == 0:\n",
    "        return \"Neutral \"\n",
    "\n",
    "new_df['sentiment_score'] = new_df['c_text'].apply(get_sentiment_score)\n",
    "new_df['sentiment'] = new_df['sentiment_score'].apply(check_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Comments for each polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  Sentiment Score    Comment\n",
      "-----------  -----------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "    -0.0164  Negative           Hmmm so many people died in the game if I would be in their place I would know how to play it and then play the game .papa people .\n",
      "    -0.0258  Negative           This scene is the perfect introduction to how the games are a matter of life and death. The slow build up, the sudden reveal that the dude was really shot, and the ensuing chaos make this the perfect introduction to these games.\n",
      "    -0.0258  Negative           Lol my two Squid Game crushes, Lee Jung-Jae and Park Hae Soo.\n",
      "    -0.0258  Negative           Game of Death- Bruce Lee would win\n",
      "    -0.0258  Negative           Squid game occurs to some extent in boxing, wrestling etc where normal people including vip's enjoy the pain of others\n",
      "    -0.0258  Negative           If player 1 was the boss then who started the game after his death?\n",
      "                                You explanation  is amazing\n",
      "    -0.0258  Negative           *Obviously our hero will play the game again to find out who is behind it after the old man's death and to stop it forever ...*\n",
      "    -0.0387  Negative           No, there is not blood in there .but old woman is given me a langh.oh who death and who alive.this is best .\n",
      "    -0.0488  Negative           So basically hunger games but different, some faction or person becomes to powerful and makes the peasants play death games. Seems legit.\n",
      "    -0.0516  Negative           Good thing the game isn,t unfair. Imagine getting shot on green light\n",
      "     0       Neutral            Hoyeon in Squid Game:\n",
      "                                Hoyeon in RL:\n",
      "     0       Neutral            Squid game has so much blood it is not a kids show!!\n",
      "     0       Neutral            ali's face is priceless\n",
      "     0       Neutral            Square Game season 3 TV show\n",
      "     0       Neutral            I have to go back and squid game\n",
      "     0       Neutral            The squid game scerd\n",
      "     0       Neutral            It's just a game.\n",
      "     0       Neutral            Ali Abdul in the back: ‚ÄúWHAT ABOUT ME HUH? WHEN U GONNA RECORD ME IN THIS? HUH? UGH-‚Äú\n",
      "     0       Neutral            So this is the reason why we have an actual Android \"squid game\" Now\n",
      "     0       Neutral            so the blood in squid game is ketchup?!?!\n",
      "     0.9878  Positive           After watching Squid Game, Idk how to explain if I like that ending but overall the drama is my type and I'm super in love with this concept survival game. The cast acting were brilliant, the filming set and filmography were excellent. And CAMEO(s), YES chef kiss!\n",
      "     0.9858  Positive           When i saw 240 i was like \"WOW MY FAVORITE\" because she looks like me!! I don't know why? I'm still happy i love squid game! It's the best! And by the way... MERRY CHRISTMAS!!\n",
      "     0.9842  Positive           WOW! THAT'S SO EPIC I ENJOYED SO AMAZING THAT'S THE AMAZING SQUID GAME VIDEO OMG I LOVE IT AND THE END IS SO AWESOME AND AMAZING\n",
      "     0.9807  Positive           I love how the actors are so happy and such good friends in real life and nothing like the show love them and love squid game best netflix show\n",
      "     0.979   Positive           This was such an amazing show! I loved every bit of it. It was so gripping, so emotional, and very well executed! I can't wait for a second season. He didn't get on the plane and acted as if he was looking for revenge. I loved the marble game the most. As soon as they said they were to be in teams of 2, I knew they were going to play against each other where one in each pair would be eliminated. They of course thought to pair up with their friend and be teammates. Everything about the show was playing on all the different social dynamics within human interactions, and it was done perfectly!\n",
      "     0.9741  Positive           this movie is amazing i love it!!\n",
      "                                and their acting's are great!\n",
      "                                love squid game!\n",
      "                                love the characters!\n",
      "     0.9736  Positive           park haesoo is so good at acting that it feels weird seeing his character in squid game and his character in prison playbook  they're completely opposites lol he's awesome and cool i'm so proud of him\n",
      "\n",
      "                                edit: yo thanks for the 1.3k likes everyone! happy that a lot of people shares the same sentiment\n",
      "     0.9726  Positive           Wi Hajoon is finally getting the recognition he deserves  He is such a versatile actor and highly underrated but I'm soo happy to see him being famous from Squid Game. He's done many supporting roles and main roles as well. His recently released thriller movie Midnight is amazing, I hope y'all can watch it.\n",
      "     0.9721  Positive           My cousin has a Roblox and I played squid game it‚Äôs very true I swear it‚Äôs very true it‚Äôs very true OK OK OK OK\n",
      "     0.9721  Positive           Hahaahhahahaa it was  so  funny  to watch  this video and I love this video so much and i will  give it a thumbs up I love you Kaycee and Rachel l hope you enjoyed  this game you are the only girl s that mekes me happy\n"
     ]
    }
   ],
   "source": [
    "def select_top_comments(df, top_n=10):\n",
    "    top_comments = []\n",
    "    grouped = df.groupby('sentiment')\n",
    "\n",
    "    # iterate over each polarity group\n",
    "    for sentiment, group in grouped:\n",
    "        # sort comments by sentiment score pick top 10\n",
    "        top_group_comments = group.sort_values(by='sentiment_score', ascending=False).head(top_n)[['sentiment_score', 'sentiment', 'c_text']].values.tolist()\n",
    "        top_comments.extend([(sentiment_score, sentiment, comment) for sentiment_score, sentiment, comment in top_group_comments])\n",
    "\n",
    "    return top_comments\n",
    "\n",
    "top_comments = select_top_comments(new_df, top_n=10)\n",
    "\n",
    "# # top 10 comments for each polarity\n",
    "# for sentiment_score, sentiment, comment in top_comments:\n",
    "#     print(f\"Sentiment: {sentiment}, Sentiment Score: {sentiment_score}, Comment: {comment}\")\n",
    "\n",
    "# making it pretty~~~\n",
    "headers = [\"Sentiment\", \"Sentiment Score\", \"Comment\"]\n",
    "print(tabulate(top_comments, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Lexicon using TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  Sentiment Score    Comment\n",
      "-----------  -----------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "    -0.0164  Negative           Hmmm so many people died in the game if I would be in their place I would know how to play it and then play the game .papa people .\n",
      "    -0.0258  Negative           This scene is the perfect introduction to how the games are a matter of life and death. The slow build up, the sudden reveal that the dude was really shot, and the ensuing chaos make this the perfect introduction to these games.\n",
      "    -0.0258  Negative           Lol my two Squid Game crushes, Lee Jung-Jae and Park Hae Soo.\n",
      "    -0.0258  Negative           Game of Death- Bruce Lee would win\n",
      "    -0.0258  Negative           Squid game occurs to some extent in boxing, wrestling etc where normal people including vip's enjoy the pain of others\n",
      "    -0.0258  Negative           If player 1 was the boss then who started the game after his death?\n",
      "                                You explanation  is amazing\n",
      "    -0.0258  Negative           *Obviously our hero will play the game again to find out who is behind it after the old man's death and to stop it forever ...*\n",
      "    -0.0387  Negative           No, there is not blood in there .but old woman is given me a langh.oh who death and who alive.this is best .\n",
      "    -0.0488  Negative           So basically hunger games but different, some faction or person becomes to powerful and makes the peasants play death games. Seems legit.\n",
      "    -0.0516  Negative           Good thing the game isn,t unfair. Imagine getting shot on green light\n",
      "     0       Neutral            Hoyeon in Squid Game:\n",
      "                                Hoyeon in RL:\n",
      "     0       Neutral            Squid game has so much blood it is not a kids show!!\n",
      "     0       Neutral            ali's face is priceless\n",
      "     0       Neutral            Square Game season 3 TV show\n",
      "     0       Neutral            I have to go back and squid game\n",
      "     0       Neutral            The squid game scerd\n",
      "     0       Neutral            It's just a game.\n",
      "     0       Neutral            Ali Abdul in the back: ‚ÄúWHAT ABOUT ME HUH? WHEN U GONNA RECORD ME IN THIS? HUH? UGH-‚Äú\n",
      "     0       Neutral            So this is the reason why we have an actual Android \"squid game\" Now\n",
      "     0       Neutral            so the blood in squid game is ketchup?!?!\n",
      "     0.9878  Positive           After watching Squid Game, Idk how to explain if I like that ending but overall the drama is my type and I'm super in love with this concept survival game. The cast acting were brilliant, the filming set and filmography were excellent. And CAMEO(s), YES chef kiss!\n",
      "     0.9858  Positive           When i saw 240 i was like \"WOW MY FAVORITE\" because she looks like me!! I don't know why? I'm still happy i love squid game! It's the best! And by the way... MERRY CHRISTMAS!!\n",
      "     0.9842  Positive           WOW! THAT'S SO EPIC I ENJOYED SO AMAZING THAT'S THE AMAZING SQUID GAME VIDEO OMG I LOVE IT AND THE END IS SO AWESOME AND AMAZING\n",
      "     0.9807  Positive           I love how the actors are so happy and such good friends in real life and nothing like the show love them and love squid game best netflix show\n",
      "     0.979   Positive           This was such an amazing show! I loved every bit of it. It was so gripping, so emotional, and very well executed! I can't wait for a second season. He didn't get on the plane and acted as if he was looking for revenge. I loved the marble game the most. As soon as they said they were to be in teams of 2, I knew they were going to play against each other where one in each pair would be eliminated. They of course thought to pair up with their friend and be teammates. Everything about the show was playing on all the different social dynamics within human interactions, and it was done perfectly!\n",
      "     0.9741  Positive           this movie is amazing i love it!!\n",
      "                                and their acting's are great!\n",
      "                                love squid game!\n",
      "                                love the characters!\n",
      "     0.9736  Positive           park haesoo is so good at acting that it feels weird seeing his character in squid game and his character in prison playbook  they're completely opposites lol he's awesome and cool i'm so proud of him\n",
      "\n",
      "                                edit: yo thanks for the 1.3k likes everyone! happy that a lot of people shares the same sentiment\n",
      "     0.9726  Positive           Wi Hajoon is finally getting the recognition he deserves  He is such a versatile actor and highly underrated but I'm soo happy to see him being famous from Squid Game. He's done many supporting roles and main roles as well. His recently released thriller movie Midnight is amazing, I hope y'all can watch it.\n",
      "     0.9721  Positive           My cousin has a Roblox and I played squid game it‚Äôs very true I swear it‚Äôs very true it‚Äôs very true OK OK OK OK\n",
      "     0.9721  Positive           Hahaahhahahaa it was  so  funny  to watch  this video and I love this video so much and i will  give it a thumbs up I love you Kaycee and Rachel l hope you enjoyed  this game you are the only girl s that mekes me happy\n"
     ]
    }
   ],
   "source": [
    "def text_blob_sentiment_score(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def texblob_check_sentiment(score):\n",
    "    if score == 0:\n",
    "        return 'Neutral'\n",
    "    elif score < 0.00:\n",
    "        return 'Negative'\n",
    "    elif score > 0.00:\n",
    "        return 'Positive'\n",
    "\n",
    "new_df['textblob_score'] = new_df['c_text'].apply(text_blob_sentiment_score)\n",
    "new_df['textblob_sentiment'] = new_df['textblob_score'].apply(texblob_check_sentiment)\n",
    "\n",
    "def textblob_select_top_comments(df, top_n=10):\n",
    "    top_comments = []\n",
    "    grouped = df.groupby('textblob_sentiment')\n",
    "\n",
    "    for sentiment, group in grouped:\n",
    "        top_group_comments = group.sort_values(by='textblob_score', ascending=False).head(top_n)[['textblob_score', 'textblob_sentiment', 'c_text']].values.tolist()\n",
    "        top_comments.extend([(sentiment_score, sentiment, comment) for sentiment_score, sentiment, comment in top_group_comments])\n",
    "\n",
    "    return top_comments\n",
    "\n",
    "textblob_top_comments = select_top_comments(new_df, top_n=10)\n",
    "\n",
    "headers = [\"Sentiment\", \"Sentiment Score\", \"Comment\"]\n",
    "print(tabulate(textblob_top_comments, headers=headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17419    None\n",
       "17395    None\n",
       "17401    None\n",
       "17791    None\n",
       "17379    None\n",
       "         ... \n",
       "11139    None\n",
       "11140    None\n",
       "11182    None\n",
       "11190    None\n",
       "18373    None\n",
       "Length: 1162, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = ['positive', 'negative', 'neutral']\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def col_to_txt(row):\n",
    "    sentiment = row['sentiment']  \n",
    "    c_text = row['c_text']\n",
    "    file_name = f\"{sentiment}_{row.c_id}.txt\"  \n",
    "    folder = f\"{sentiment.strip()}\"  \n",
    "    file_path = os.path.join(folder, file_name)\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(c_text)\n",
    "\n",
    "new_df.apply(col_to_txt, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'final_comments_df.csv'\n",
    "# files_present = glob.glob(filename)\n",
    "# # will only write to disk if file doesnt exist\n",
    "# if not files_present:\n",
    "#     new_df.to_csv(filename, index=False)\n",
    "#     new_df\n",
    "# else:\n",
    "#     print (f'File Already Exists. Delete {filename}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define the root directory containing the positive, negative, and neutral folders\n",
    "root_dir = ''\n",
    "\n",
    "# Define the directories for train and test sets\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "try:\n",
    "    shutil.rmtree(os.path.join(root_dir, train_dir))\n",
    "    shutil.rmtree(os.path.join(root_dir, test_dir))\n",
    "except:\n",
    "    pass\n",
    "# Define the ratio for train-test split\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Iterate through each sentiment folder\n",
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    # Get the list of file paths in the current sentiment folder\n",
    "    files = os.listdir(os.path.join(root_dir, sentiment))\n",
    "    # Shuffle the file paths\n",
    "    random.shuffle(files)\n",
    "    # Calculate the split index based on the split ratio\n",
    "    split_index = int(len(files) * split_ratio)\n",
    "    # Split the files into train and test sets\n",
    "    train_files = files[:split_index]\n",
    "    test_files = files[split_index:]\n",
    "    \n",
    "    # Move train files to train directory\n",
    "    for file in train_files:\n",
    "        src = os.path.join(root_dir, sentiment, file)\n",
    "        dst = os.path.join(train_dir, sentiment, file)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        # Check if the file already exists in the destination directory\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.move(src, dst)\n",
    "    \n",
    "    # Move test files to test directory\n",
    "    for file in test_files:\n",
    "        src = os.path.join(root_dir, sentiment, file)\n",
    "        dst = os.path.join(test_dir, sentiment, file)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        # Check if the file already exists in the destination directory\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "# Remove the sentiment folders\n",
    "try:\n",
    "    shutil.rmtree('negative')\n",
    "    shutil.rmtree('neutral')\n",
    "    shutil.rmtree('positive')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Text Analytics Pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files(train_dir)\n",
    "reviews_test = load_files(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Squid game in china ' 1\n",
      "b'omg finally a media show game with an actual prize!' 2\n",
      "b'Ugh this show is something else. Everyone needs to see this masterpiece! Finished yesterday and dont know what to do with no more squid game *cries*' 2\n"
     ]
    }
   ],
   "source": [
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(text_train[1],y_train[1])\n",
    "print(text_train[2],y_train[2])\n",
    "print(text_train[3],y_train[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<5x5 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect = CountVectorizer().fit(reviews_train)\n",
    "X_train = vect.transform(reviews_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tokens = ['drama', 'film', 'cinema', 'actor', 'actress', 'director', 'plot',\n",
    "                         'scene', 'genre', 'subtitles', 'k-drama', 'kdrama', 'k-movie', 'television',\n",
    "                         'episode', 'screenplay', 'script', 'cinematography', 'soundtrack',\n",
    "                         'OST', 'character', 'plot twist', 'review', 'ratings', 'premiere',\n",
    "                         'streaming', 'watchlist', 'subbed', 'dubbed', 'sequel', 'game', 'song',\n",
    "                         'season', 'trailer', 'casting', 'fanbase', 'recommendation', 'goblin',\n",
    "                         'viewer', 'critic', 'Korean', 'entertainment', 'watched', 'guardian',\n",
    "                         'show', 'squid', 'watch', 'watching', 'acting', 'netflix', 'show',\n",
    "                         'end',\n",
    "                          'squid game', 'gi-hun', 'Sang-woo', 'Player', 'Red light', 'green light', 'Honeycomb',\n",
    "                            'Tug of war', 'Marbles', 'Front man', 'VIPs', 'Doll', 'Coffin', 'Square', 'Triangle', \n",
    "                            'Circle', 'Death game', 'death', 'Survival game', 'Money', 'prize', 'Il-nam', 'Hwang Jun-ho'\n",
    "                            'director', 'Cho Sang-woo', 'Masked man', 'Childhood', 'game', 'Pink soldier', 'Betrayal',\n",
    "                            'Seong Gi-hun', 'Survival', 'Games', 'Competition', 'Squid', 'Masks', 'ali', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Define the pattern to match punctuation\n",
    "    punctuation_pattern = r'[^\\w\\s]'\n",
    "    # Replace punctuation with an empty string\n",
    "    text_without_punctuation = re.sub(punctuation_pattern, '', text)\n",
    "    return text_without_punctuation\n",
    "\n",
    "# Text Processing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # stopwords punctuation etc\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    # stemmer = PorterStemmer()\n",
    "    # split into tokens\n",
    "    tokens = word_tokenize(text)\n",
    "    # removes stopwords and numbers and stems from tokens makes sure its all lowercase too\n",
    "    tokens = [stemmer.stem(remove_punctuation(token)) for token in tokens if token.isalnum() and token.lower() not in product_tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ishaq\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.65      0.37        20\n",
      "           1       0.33      0.64      0.44        28\n",
      "           2       0.92      0.65      0.76       186\n",
      "\n",
      "    accuracy                           0.65       234\n",
      "   macro avg       0.51      0.65      0.52       234\n",
      "weighted avg       0.80      0.65      0.69       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('preprocess', \n",
    "    TfidfVectorizer(\n",
    "                    encoding=\"utf-8\",\n",
    "                    strip_accents='ascii',\n",
    "                    lowercase=True,\n",
    "                    preprocessor=preprocess_text,\n",
    "                    # tokenizer=,\n",
    "                    # analyzer=,\n",
    "                    stop_words='english',\n",
    "                    norm='l2',\n",
    "                    ngram_range=(1, 1),\n",
    "                    max_df=0.09,\n",
    "                    min_df=0.003,\n",
    "                    max_features=500,\n",
    "                    binary=True,\n",
    "                    use_idf=True,\n",
    "                    smooth_idf=True,\n",
    "                    sublinear_tf=True\n",
    "                    )\n",
    "    # CountVectorizer(preprocessor=preprocess_text,ngram_range=(1, 1))\n",
    "     ), \n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "text_clf.fit(text_train, y_train)\n",
    "y_pred = text_clf.predict(text_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Run only till here and check coz the grid search would take long so better to adjust by looking at this only ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vectorizer': [TfidfVectorizer()],\n",
    "    'classifier': [\n",
    "        MultinomialNB(),\n",
    "        SVC(),\n",
    "        LogisticRegression()\n",
    "    ],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vectorizer__preprocessor': [preprocess_text],\n",
    "    'vectorizer__encoding': ['utf-8'],\n",
    "    'vectorizer__binary': [False, True],\n",
    "    'vectorizer__lowercase': [False, True],\n",
    "    'vectorizer__encoding': [\"utf-8\"],\n",
    "    'vectorizer__strip_accents': ['ascii'],\n",
    "    'vectorizer__stop_words': ['english'],\n",
    "    'vectorizer__norm': ['l2','l1'],\n",
    "    'vectorizer__max_df': [0.1,0.09,0.08,0.07],\n",
    "    'vectorizer__min_df': [0.004,0.003,0.002],\n",
    "    # 'vectorizer__max_features': [500],\n",
    "    'vectorizer__use_idf': [True,False],\n",
    "    'vectorizer__smooth_idf': [True],\n",
    "    # 'vectorizer__sublinear_tf': [True,False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "grid_search.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(text_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 889: Mean Test Score - 0.9204, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 925: Mean Test Score - 0.9204, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 1033: Mean Test Score - 0.9204, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': True, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 1069: Mean Test Score - 0.9204, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': True, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 893: Mean Test Score - 0.9169, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 929: Mean Test Score - 0.9169, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 1037: Mean Test Score - 0.9169, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': True, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 1073: Mean Test Score - 0.9169, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': True, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 897: Mean Test Score - 0.9143, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 3), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n",
      "Model 933: Mean Test Score - 0.9143, Parameters - {'classifier': SVC(), 'vectorizer': TfidfVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 3), 'vectorizer__norm': 'l2', 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__smooth_idf': True, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii', 'vectorizer__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "results = grid_search.cv_results_\n",
    " \n",
    "scores = results['mean_test_score']\n",
    "\n",
    "params = results['params']\n",
    "\n",
    "top_models_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:10]\n",
    " \n",
    "for i in top_models_indices:\n",
    "    print(\"Model {}: Mean Test Score - {:.4f}, Parameters - {}\".format(i+1, scores[i], params[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ishaq\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        79\n",
      "           1       0.96      0.95      0.95        74\n",
      "           2       0.97      1.00      0.98       217\n",
      "\n",
      "    accuracy                           0.97       370\n",
      "   macro avg       0.97      0.95      0.96       370\n",
      "weighted avg       0.97      0.97      0.97       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_ct = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "parameters_ct = {\n",
    "    'vectorizer': [CountVectorizer()],\n",
    "    'classifier': [\n",
    "        MultinomialNB(),\n",
    "        SVC(),\n",
    "        LogisticRegression()\n",
    "    ],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vectorizer__preprocessor': [preprocess_text],\n",
    "    'vectorizer__encoding': ['utf-8'],\n",
    "    'vectorizer__binary': [False, True],\n",
    "    'vectorizer__lowercase': [False, True],\n",
    "    'vectorizer__encoding': [\"utf-8\"],\n",
    "    'vectorizer__strip_accents': ['ascii'],\n",
    "    'vectorizer__stop_words': ['english'],\n",
    "    'vectorizer__max_df': [0.1,0.09,0.08,0.07],\n",
    "    'vectorizer__min_df': [0.004,0.003,0.002],\n",
    "    'tfidf__norm': ['l2','l1'],\n",
    "    # 'vectorizer__max_features': [500],\n",
    "    'tfidf__use_idf': [True,False],\n",
    "    'tfidf__smooth_idf': [True],\n",
    "    # 'vectorizer__sublinear_tf': [True,False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_ct = GridSearchCV(pipeline_ct, parameters_ct, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "grid_search_ct.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search_ct.best_params_)\n",
    "best_model_ct = grid_search_ct.best_estimator_\n",
    "y_pred_ct = best_model_ct.predict(text_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 655: Mean Test Score - 0.9204, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 664: Mean Test Score - 0.9204, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 691: Mean Test Score - 0.9204, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': True, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 700: Mean Test Score - 0.9204, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': True, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 656: Mean Test Score - 0.9169, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 2), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 665: Mean Test Score - 0.9169, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 2), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 692: Mean Test Score - 0.9169, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': True, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 2), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 701: Mean Test Score - 0.9169, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': True, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 2), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 657: Mean Test Score - 0.9143, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.1, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 3), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n",
      "Model 666: Mean Test Score - 0.9143, Parameters - {'classifier': SVC(), 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__use_idf': True, 'vectorizer': CountVectorizer(), 'vectorizer__binary': True, 'vectorizer__encoding': 'utf-8', 'vectorizer__lowercase': False, 'vectorizer__max_df': 0.09, 'vectorizer__min_df': 0.002, 'vectorizer__ngram_range': (1, 3), 'vectorizer__preprocessor': <function preprocess_text at 0x0000025C8002BDC0>, 'vectorizer__stop_words': 'english', 'vectorizer__strip_accents': 'ascii'}\n"
     ]
    }
   ],
   "source": [
    "results_ct = grid_search_ct.cv_results_\n",
    " \n",
    "scores_ct = results_ct['mean_test_score']\n",
    "\n",
    "params_ct = results_ct['params']\n",
    "\n",
    "top_models_indices_ct = sorted(range(len(scores_ct)), key=lambda i: scores_ct[i], reverse=True)[:10]\n",
    " \n",
    "for i in top_models_indices_ct:\n",
    "    print(\"Model {}: Mean Test Score - {:.4f}, Parameters - {}\".format(i+1, scores_ct[i], params_ct[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Visualization and Insights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Discussion and conclusion from experiments:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
